[
  {
    "objectID": "index.html#préface",
    "href": "index.html#préface",
    "title": "guide-R",
    "section": "Préface",
    "text": "Préface\n\n\n\n\n\n\nGuide en cours d’écriture\n\n\n\nCe guide est encore incomplet. Le plan prévu est visible à cette adresse : https://github.com/larmarange/guide-R/issues/12.\nEn attendant, nous vous conseillons de compléter votre lecture par le site analyse-R.\n\n\nCe guide porte sur l’analyse de données d’enquêtes avec le logiciel R, un logiciel libre de statitistiques et de traitement de données. Les exemples présentés ici relèvent principalement du champs des sciences sociales quantitatives et des sciences de santé. Ils peuvent néanmoins s’appliquer à d’autre champs disciplinaires. Cependant, comme tout ouvrage, ce guide ne peut être exhaustif.\nCe guide présente comment réaliser des analyses statistiques et diverses opérations courantes (comme la manipulation de données ou la production de graphiques) avec R. Il ne s’agit pas d’un cours de statistiques : les différents chapitres présupposent donc que vous avez déjà une connaissance des différentes techniques présentées. Si vous souhaitez des précisions théoriques / méthodologiques à propos d’un certain type d’analyses, nous vous conseillons d’utiliser votre moteur de recherche préféré. En effet, on trouve sur internet de très nombreux supports de cours (sans compter les nombreux ouvrages spécialisés disponibles en librairie).\nDe même, il ne s’agit pas d’une introduction ou d’un guide pour les utilisatrices et utilisateurs débutant·es. Si vous découvrez R, nous vous conseillons la lecture de l’Introduction à R et au tidyverse de Julien Barnier (https://juba.github.io/tidyverse/). Vous pouvez également lire les chapitres introductifs d’analyse-R : Introduction à l’analyse d’enquêtes avec R et RStudio (https://larmarange.github.io/analyse-R/). Néanmoins, quelques rappels sur les bases du langage sont fournis dans la section Bases du langage. Une bonne compréhension de ces dernières, bien qu’un peu ardue de prime abord, permet de comprendre le sens des commandes qu’on utilise et de pleinement exploiter la puissance que R offre en matière de manipulation de données.\nR disposent de nombreuses extensions ou packages (plus de 16 000) et il existe souvent plusieurs manières de procéder pour arriver au même résultat. En particulier, en matière de manipulation de données, on oppose1 souvent base R qui repose sur les fonctions disponibles en standard dans R, la majorité étant fournies dans les packages {base}, {utils} ou encore {stats}, qui sont toujours chargés par défaut, et le tidyverse qui est une collection de packages comprenant, entre autres, dplyr, tibble, tidyr, forcats ou encore ggplot2. Il y a un débat ouvert, parfois passionné, sur le fait de privilégier l’une ou l’autre approche, et les avantages et inconvénients de chacune dépendent de nombreux facteurs, comme la lisibilité du code ou bien les performances en temps de calcul. Dans ce guide, nous avons adopté un point de vue pragmatique et utiliserons, le plus souvent mais pas exclusivement, les fonctions du tidyverse, de même que nous avons privilégié d’autres packages, comme gtsummary ou questionr par exemple pour la statistique descriptive. Cela ne signifie pas, pour chaque point abordé, qu’il s’agit de l’unique manière de procéder. Dans certains cas, il s’agit simplement de préférences personnelles.1 Une comparaison des deux syntaxes est illustrée par une vignette dédiée de dplyr.\nBien qu’il en reprenne de nombreux contenus, ce guide ne se substitue pas au site analyse-R. Il s’agit plutôt d’une version complémentaire qui a vocation à être plus structurée et parfois plus sélective dans les contenus présentés.\nEn complément, on pourra également se référer aux webin-R, une série de vidéos avec partage d’écran, librement accessibles sur Youtube : https://www.youtube.com/c/webinR.\nCette version du guide a utilisé R version 4.2.2 (2022-10-31 ucrt). Ce document est généré avec quarto et le code source est disponible sur GitHub. Pour toute suggestion ou correction, vous pouvez ouvrir un ticket GitHub. Pour d’autres questions, vous pouvez utiliser les forums de discussion disponibles en bas de chaque page sur la version web du guide. Ce document est régulièrement mis à jour. La dernière version est consultable sur https://larmarange.github.io/guide-R/."
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "guide-R",
    "section": "Remerciements",
    "text": "Remerciements\nCe document a bénéficié de différents apports provenant notamment de l’Introduction à R et de l’Introduction à R et au tidyverse de Julien Barnier et d’analyse-R : introduction à l’analyse d’enquêtes avec R et RStudio.\nMerci donc à Julien Barnier, Julien Biaudet, François Briatte, Milan Bouchet-Valat, Ewen Gallic, Frédérique Giraud, Joël Gombin, Mayeul Kauffmann, Christophe Lalanne & Nicolas Robette."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "guide-R",
    "section": "Licence",
    "text": "Licence\nCe document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International."
  },
  {
    "objectID": "bases/packages.html#installation-cran",
    "href": "bases/packages.html#installation-cran",
    "title": "1  Packages",
    "section": "\n1.1 Installation (CRAN)",
    "text": "1.1 Installation (CRAN)\nL’installation d’une extension se fait par la fonction install.packages(), à qui on fournit le nom de l’extension. Par exemple, si on souhaite installer l’extension gtsummary :\n\ninstall.packages(\"gtsummary\")\n\nSous RStudio, on pourra également cliquer sur Install dans l’onglet Packages du quadrant inférieur droit.\nAlternativement, on pourra avoir recours au package remotes et à sa fonction remotes::install_cran() :\n\nremotes::install_cran(\"gtsummary\")\n\n\n\n\n\n\n\nNote\n\n\n\nLe package remotes n’est pas disponible par défaut sous R et devra donc être installé classiquement avec install.packages(\"remotes\"). À la différence de install.packages(), remotes::install_cran() vérifie si le package est déjà installé et, si oui, si la version installée est déjà la dernière version, avant de procéder à une installation complète si et seulement si cela est nécessaire."
  },
  {
    "objectID": "bases/packages.html#chargement",
    "href": "bases/packages.html#chargement",
    "title": "1  Packages",
    "section": "\n1.2 Chargement",
    "text": "1.2 Chargement\nUne fois un package installé (c’est-à-dire que ses fichiers ont eté téléchargés et copiés sur votre ordinateur), ses fonctions et objets ne sont pas directement accessibles. Pour pouvoir les utiliser, il faut, à chaque session de travail, charger le package en mémoire avec la fonction library() ou la fonction require() :\n\nlibrary(gtsummary)\n\nÀ partir de là, on peut utiliser les fonctions de l’extension, consulter leur page d’aide en ligne, accéder aux jeux de données qu’elle contient, etc.\nAlternativement, pour accéder à un objet ou une fonction d’un package sans avoir à le charger en mémoire, on pourra avoir recours à l’opérateur ::. Ainsi, l’écriture p::f() signifie la fonction f() du package p. Cette écriture sera notamment utilisée tout au long de ce guide pour indiquer à quel package appartient telle fonction : remotes::install_cran() indique que la fonction install_cran() provient du packages remotes.\n\n\n\n\n\n\nImportant\n\n\n\nIl est important de bien comprendre la différence entre install.packages() et library(). La première va chercher un package sur internet et l’installe en local sur le disque dur de l’ordinateur. On n’a besoin d’effectuer cette opération qu’une seule fois. La seconde lit les informations de l’extension sur le disque dur et les met à disposition de R. On a besoin de l’exécuter à chaque début de session ou de script."
  },
  {
    "objectID": "bases/packages.html#mise-à-jour",
    "href": "bases/packages.html#mise-à-jour",
    "title": "1  Packages",
    "section": "\n1.3 Mise à jour",
    "text": "1.3 Mise à jour\nPour mettre à jour l’ensemble des pacakges installés, il suffit d’exécuter la fonction update.packages() :\n\nupdate.packages()\n\nSous RStudio, on pourra alternativement cliquer sur Update dans l’onglet Packages du quadrant inférieur droit.\nSi on souhaite désinstaller une extension précédemment installée, on peut utiliser la fonction remove.packages() :\n\nremove.packages(\"gtsummary\")\n\n\n\n\n\n\n\nInstaller / Mettre à jour les packages utilisés par un projet\n\n\n\nAprès une mise à jour majeure de R, il est souvent nécessaire de réinstaller tous les packages utilisés. De même, on peut parfois souhaiter mettre à jour uniquement les packages utilisés par un projet donné sans avoir à mettre à jour tous les autres packages présents sur son PC.\nUne astuce consiste à avoir recours à la fonction renv::dependencies() qui examine le code du projet courant pour identifier les packages utilisés, puis à passer cette liste de packages à remotes::install_cran() qui installera les packages manquants ou pour lesquels une mise à jour est disponible.\nIl vous suffit d’exécuter la commande ci-dessous :\n\nrenv::dependencies() |> \n  purrr::pluck(\"Package\") |> \n  remotes::install_cran()"
  },
  {
    "objectID": "bases/packages.html#installation-depuis-github",
    "href": "bases/packages.html#installation-depuis-github",
    "title": "1  Packages",
    "section": "\n1.4 Installation depuis GitHub",
    "text": "1.4 Installation depuis GitHub\nCertains packages ne sont pas disponibles sur CRAN mais seulement sur GitHub, une plateforme de développement informatique. Il s’agit le plus souvent de packages qui ne sont pas encore suffisament matures pour être diffusés sur CRAN (sachant que des vérifications strictes sont effectués avant qu’un package ne soit référencés sur CRAN).\nDans d’autres cas de figure, la dernière version stable d’un package est disponible sur CRAN tandis que la version en cours de développement est, elle, disponible sur GitHub. Il fuat être vigilant avec les versions de développement. Parfois, elle corrige un bug ou introduit une nouvelle fonctionnalité qui n’est pas encore dans la version stable. Mais les versions de développement peuvent aussi contenir de nouveaux bugs ou des fonctionnalités instables.\n\n\n\n\n\n\nSous Windows\n\n\n\nPour les utilisatrices et utilisateurs sous Windows, il faut être conscient que le code source d’un package doit être compilé afin de pouvoir être utilisé. CRAN fournit une version des packages déjà compilée pour Windows ce qui facilite l’installation.\nPar contre, lorsque l’on installe un package depuis GitHub, R ne récupère que le code source et il est donc nécessaire de compiler localement le package. Pour cela, il est nécessaire que soit installé sur le PC un outil complémentaire appelé RTools. Il est téléchargeable à l’adresse https://cran.r-project.org/bin/windows/Rtools/.\n\n\nLe code source du package labelled est disponible sur GitHub à l’adresse https://github.com/larmarange/labelled. Pour installer la version de développement de labelled,on aura recours à la fonction remotes::install_github() à laquelle on passera la partie située à droite de https://github.com/ dans l’URL du package, à savoir :\n\nremotes::install_github(\"larmarange/labelled\")"
  },
  {
    "objectID": "bases/packages.html#le-tidyverse",
    "href": "bases/packages.html#le-tidyverse",
    "title": "1  Packages",
    "section": "\n1.5 Le tidyverse",
    "text": "1.5 Le tidyverse\nLe terme tidyverse est une contraction de tidy (qu’on pourrait traduire par bien rangé) et de universe. Il s’agit en fait d’une collection de packages conçus pour travailler ensemble et basés sur une philosophie commune.\nIls abordent un très grand nombre d’opérations courantes dans R (la liste n’est pas exhaustive) :\n\nvisualisation (ggplot2)\nmanipulation des tableaux de données (dplyr, tidyr)\nimport/export de données (readr, readxl, haven)\nmanipulation de variables (forcats, stringr, lubridate)\nprogrammation (purrr, magrittr, glue)\n\nUn des objectifs de ces extensions est de fournir des fonctions avec une syntaxe cohérente, qui fonctionnent bien ensemble, et qui retournent des résultats prévisibles. Elles sont en grande partie issues du travail d’Hadley Wickham, qui travaille désormais pour RStudio.\ntidyverse est également le nom d’une extension générique qui permets d’installer en une seule commande l’ensemble des packages constituant le tidyverse :\n\ninstall.packages(\"tidyverse\")\n\nLorsque l’on charge le package tidyverse avec library(), cela charge également en mémoire les principaux packages du tidyverse1.1 Si on a besoin d’un autre package du tidyverse comme lubridate, il faudra donc le charger individuellement.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\nFigure 1.1: Packages chargés avec library(tidyverse)"
  },
  {
    "objectID": "bases/vecteurs.html#types-et-classes",
    "href": "bases/vecteurs.html#types-et-classes",
    "title": "2  Vecteurs",
    "section": "\n2.1 Types et classes",
    "text": "2.1 Types et classes\nDans R, il existe plusieurs types fondamentaux de vecteurs et, en particulier, :\n\nles nombres réels (c’est-à-dire les nombres décimaux1), par exemple 5.23 ;\nles nombres entiers, que l’on saisi en ajoutant le suffixe L2, par exemple 4L ;\nles chaînes de caractères (qui correspondent à du texte), que l’on saisit avec des guillemets doubles (\") ou simples ('), par exemple \"abc\" ;\nles valeurs logiques ou valeurs booléennes, à savoir vrai ou faux, que l’on représente avec les mots TRUE et FALSE (en majuscules3).\n\n1 Pour rappel, R étant anglophone, le caractère utilisé pour indiqué les chiffres après la virgule est le point (.).2 R utilise 32 bits pour représenter des nombres entiers, ce qui correspond en informatique à des entiers longs ou long integers en anglais, d’où la lettre L utilisée pour indiquer un nombre entier.3 On peut également utiliser les raccourcis T et F. Cependant, pour une meilleure lisibilité du code, il est préférable d’utiliser les versions longues TRUE et FALSE.En plus de ces types de base, il existe de nombreux autres types de vecteurs utilisés pour représenter toutes sortes de données, comme les facteurs (voir Chapitre 9) ou les dates (voir Chapitre 25).\nLa fonction class() renvoie la nature d’un vecteur tandis que la fonction typeof() indique la manière dont un vecteur est stocké de manière interne par R.\n\n\n\n\n\n\n\n\n\nx\nclass(x)\ntypeof(x)\n\n\n\n3L\ninteger\ninteger\n\n\n5.3\nnumeric\ndouble\n\n\nTRUE\nlogical\nlogical\n\n\n\"abc\"\ncharacter\ncharacter\n\n\nfactor(\"a\")\nfactor\ninteger\n\n\nas.Date(\"2020-01-01\")\nDate\ndouble\n\n\n\nTable 2.1: Le type et la classe des principaux types de vecteurs\n\n\n\n\n\n\nAstuce\n\n\n\nPour un vecteur numérique, le type est \"double\" car R utilise une double précision pour stocker informatiquement les nombres réels.\nEn interne, les facteurs sont représentés par un nombre entier auquel est attaché une étiquette, c’est pourquoi typeof() renvoie \"integer\".\nQuand aux dates, elles sont stockées en interne sous la forme d’un nombre réel représentant le nombre de jours depuis le 1er janvier 1970, d’où le fait que typeof() renvoie \"double\"."
  },
  {
    "objectID": "bases/vecteurs.html#création-dun-vecteur",
    "href": "bases/vecteurs.html#création-dun-vecteur",
    "title": "2  Vecteurs",
    "section": "\n2.2 Création d’un vecteur",
    "text": "2.2 Création d’un vecteur\nPour créer un vecteur, on utilisera la fonction c() en lui passant la liste des valeurs à combiner4.4 La lettre c est un raccourci du mot anglais combine, puisque cette fonction permet de combiner des valeurs individuelles dans un vecteur unique.\n\ntaille <- c(1.88, 1.65, 1.92, 1.76, NA, 1.72)\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\nsexe <- c(\"h\", \"f\", \"h\", \"f\", \"f\", \"f\")\nsexe\n\n[1] \"h\" \"f\" \"h\" \"f\" \"f\" \"f\"\n\nurbain <- c(TRUE, TRUE, FALSE, FALSE, FALSE, TRUE)\nurbain\n\n[1]  TRUE  TRUE FALSE FALSE FALSE  TRUE\n\n\nNous l’avons vu, toutes les valeurs d’un vecteur doivent obligatoirement être du même type. Dès lors, si on essaie de combiner des valeurs de différents types, R essaiera de les convertir au mieux. Par exemple :\n\nx <- c(2L, 3.14, \"a\")\nx\n\n[1] \"2\"    \"3.14\" \"a\"   \n\nclass(x)\n\n[1] \"character\"\n\n\nDans le cas présent, toutes les valeurs ont été converties en chaînes de caractères.\nDans certaines situations, on peut avoir besoin de créer un vecteur d’une certaine longueur mais dont toutes les valeurs sont identiques. Cela se réalise facilement avec rep() à qui on indiquera la valeur à répéter puis le nombre de répétitions :\n\nrep(2, 10)\n\n [1] 2 2 2 2 2 2 2 2 2 2\n\n\nOn peut aussi lui indiquer plusieurs valeurs qui seront alors répétées en boucle :\n\nrep(c(\"a\", \"b\"), 3)\n\n[1] \"a\" \"b\" \"a\" \"b\" \"a\" \"b\"\n\n\nDans d’autres situations, on peut avoir besoin de créer un vecteur contenant une suite de valeurs, ce qui se réalise aisément avec seq() à qui on précisera les arguments from (point de départ), to (point d’arrivée) et by (pas). Quelques exemples valent mieux qu’un long discours :\n\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nseq(5, 17, by = 2)\n\n[1]  5  7  9 11 13 15 17\n\nseq(10, 0)\n\n [1] 10  9  8  7  6  5  4  3  2  1  0\n\nseq(100, 10, by = -10)\n\n [1] 100  90  80  70  60  50  40  30  20  10\n\nseq(1.23, 5.67, by = 0.33) \n\n [1] 1.23 1.56 1.89 2.22 2.55 2.88 3.21 3.54 3.87 4.20 4.53 4.86 5.19 5.52\n\n\nL’opérateur : est un raccourci de la fonction seq() pour créer une suite de nombres entiers. Il s’utilise ainsi :\n\n1:5\n\n[1] 1 2 3 4 5\n\n24:32\n\n[1] 24 25 26 27 28 29 30 31 32\n\n55:43\n\n [1] 55 54 53 52 51 50 49 48 47 46 45 44 43"
  },
  {
    "objectID": "bases/vecteurs.html#longueur-dun-vecteur",
    "href": "bases/vecteurs.html#longueur-dun-vecteur",
    "title": "2  Vecteurs",
    "section": "\n2.3 Longueur d’un vecteur",
    "text": "2.3 Longueur d’un vecteur\nLa longueur d’un vecteur correspond au nombre de valeurs qui le composent. Elle s’obtient avec length() :\n\nlength(taille)\n\n[1] 6\n\nlength(c(\"a\", \"b\"))\n\n[1] 2\n\n\nLa longueur d’un vecteur vide (NULL) est zéro.\n\nlength(NULL)\n\n[1] 0"
  },
  {
    "objectID": "bases/vecteurs.html#combiner-des-vecteurs",
    "href": "bases/vecteurs.html#combiner-des-vecteurs",
    "title": "2  Vecteurs",
    "section": "\n2.4 Combiner des vecteurs",
    "text": "2.4 Combiner des vecteurs\nPour combiner des vecteurs, rien de plus simple. Il suffit d’utiliser c() ! Les valeurs des différents vecteurs seront mises bout à bout pour créer un unique vecteur.\n\nx <- c(2, 1, 3, 4)\nlength(x)\n\n[1] 4\n\ny <- c(9, 1, 2, 6, 3, 0)\nlength(y)\n\n[1] 6\n\nz <- c(x, y)\nz\n\n [1] 2 1 3 4 9 1 2 6 3 0\n\nlength(z)\n\n[1] 10"
  },
  {
    "objectID": "bases/vecteurs.html#vecteurs-nommés",
    "href": "bases/vecteurs.html#vecteurs-nommés",
    "title": "2  Vecteurs",
    "section": "\n2.5 Vecteurs nommés",
    "text": "2.5 Vecteurs nommés\nLes différentes valeurs d’un vecteur peuvent être nommées. Une première manière de nommer les éléments d’un vecteur est de le faire à sa création :\n\nsexe <- c(\n  Michel = \"h\", Anne = \"f\", \n  Dominique = NA, Jean = \"h\", \n  Claude = NA, Marie = \"f\"\n)\n\nLorsqu’on affiche le vecteur, la présentation change quelque peu.\n\nsexe\n\n   Michel      Anne Dominique      Jean    Claude     Marie \n      \"h\"       \"f\"        NA       \"h\"        NA       \"f\" \n\n\nLa liste des noms s’obtient avec names().\n\nnames(sexe)\n\n[1] \"Michel\"    \"Anne\"      \"Dominique\" \"Jean\"      \"Claude\"    \"Marie\"    \n\n\nPour ajouter ou modifier les noms d’un vecteur, on doit attribuer un nouveau vecteur de noms :\n\nnames(sexe) <- c(\"Michael\", \"Anna\", \"Dom\", \"John\", \"Alex\", \"Mary\")\nsexe\n\nMichael    Anna     Dom    John    Alex    Mary \n    \"h\"     \"f\"      NA     \"h\"      NA     \"f\" \n\n\nPour supprimer tous les noms, il y a la fonction unname() :\n\nanonyme <- unname(sexe)\nanonyme\n\n[1] \"h\" \"f\" NA  \"h\" NA  \"f\""
  },
  {
    "objectID": "bases/vecteurs.html#indexation-par-position",
    "href": "bases/vecteurs.html#indexation-par-position",
    "title": "2  Vecteurs",
    "section": "\n2.6 Indexation par position",
    "text": "2.6 Indexation par position\nL’indexation est l’une des fonctionnalités les plus puissantes mais aussi les plus difficiles à maîtriser de R. Il s’agit d’opérations permettant de sélectionner des sous-ensembles de valeurs en fonction de différents critères. Il existe trois types d’indexation : (i) l’indexation par position, (ii) l’indexation par nom et (iii) l’indexation par condition. Le principe est toujours le même : on indique entre crochets5 ([]) ce qu’on souhaite garder ou non.5 Pour rappel, les crochets s’obtiennent sur un clavier français de type PC en appuyant sur la touche Alt Gr et la touche ( ou ).\nCommençons par l’indexation par position encore appelée indexation directe. Ce mode le plus simple d’indexation consiste à indiquer la position des éléments à conserver.\nReprenons notre vecteur taille :\n\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\n\nSi on souhaite le premier élément du vecteur, on peut faire :\n\ntaille[1]\n\n[1] 1.88\n\n\nSi on souhaite les trois premiers éléments ou les éléments 2, 5 et 6 :\n\ntaille[1:3]\n\n[1] 1.88 1.65 1.92\n\ntaille[c(2, 5, 6)]\n\n[1] 1.65   NA 1.72\n\n\nSi on veut le dernier élément :\n\ntaille[length(taille)]\n\n[1] 1.72\n\n\nIl est tout à fait possible de sélectionner les valeurs dans le désordre :\n\ntaille[c(5, 1, 4, 3)]\n\n[1]   NA 1.88 1.76 1.92\n\n\nDans le cadre de l’indexation par position, il est également possible de spécifier des nombres négatifs, auquel cas cela signifiera toutes les valeurs sauf celles-là. Par exemple :\n\ntaille[c(-1, -5)]\n\n[1] 1.65 1.92 1.76 1.72\n\n\nÀ noter, si on indique une position au-delà de la longueur du vecteur, R renverra NA. Par exemple :\n\ntaille[23:25]\n\n[1] NA NA NA"
  },
  {
    "objectID": "bases/vecteurs.html#indexation-par-nom",
    "href": "bases/vecteurs.html#indexation-par-nom",
    "title": "2  Vecteurs",
    "section": "\n2.7 Indexation par nom",
    "text": "2.7 Indexation par nom\nLorsqu’un vecteur est nommé, il est dès lors possible d’accéder à ses valeurs à partir de leur nom. Il s’agit de l’indexation par nom.\n\nsexe[\"Anna\"]\n\nAnna \n \"f\" \n\nsexe[c(\"Mary\", \"Michael\", \"John\")]\n\n   Mary Michael    John \n    \"f\"     \"h\"     \"h\" \n\n\nPar contre il n’est pas possible d’utiliser l’opérateur - comme pour l’indexation directe. Pour exclure un élément en fonction de son nom, on doit utiliser une autre forme d’indexation, l’indexation par condition, expliquée dans la section suivante. On peut ainsi faire…\n\nsexe[names(sexe) != \"Dom\"]\n\n… pour sélectionner tous les éléments sauf celui qui s’appelle Dom."
  },
  {
    "objectID": "bases/vecteurs.html#indexation-par-condition",
    "href": "bases/vecteurs.html#indexation-par-condition",
    "title": "2  Vecteurs",
    "section": "\n2.8 Indexation par condition",
    "text": "2.8 Indexation par condition\nL’indexation par condition consiste à fournir un vecteur logique indiquant si chaque élément doit être inclus (si TRUE) ou exclu (si FALSE). Par exemple :\n\nsexe\n\nMichael    Anna     Dom    John    Alex    Mary \n    \"h\"     \"f\"      NA     \"h\"      NA     \"f\" \n\nsexe[c(TRUE, FALSE, FALSE, TRUE, FALSE, FALSE)]\n\nMichael    John \n    \"h\"     \"h\" \n\n\nÉcrire manuellement une telle condition n’est pas très pratique à l’usage. Mais supposons que nous ayons également à notre disposition les deux vecteurs suivants, également de longueur 6.\n\nurbain <- c(TRUE, TRUE, FALSE, FALSE, FALSE, TRUE)\npoids <- c(80, 63, 75, 87, 82, 67)\n\nLe vecteur urbain est un vecteur logique. On peut directement l’utiliser pour avoir le sexe des enquêtés habitant en milieu urbain :\n\nsexe[urbain]\n\nMichael    Anna    Mary \n    \"h\"     \"f\"     \"f\" \n\n\nSupposons qu’on souhaite maintenant avoir la taille des individus pesant 80 kilogrammes ou plus. Nous pouvons effectuer une comparaison à l’aide des opérateurs de comparaison suivants :\n\n\n\n\nOpérateur de comparaison\nSignification\n\n\n\n==\négal à\n\n\n%in%\nappartient à\n\n\n!=\ndifférent de\n\n\n>\nstrictement supérieur à\n\n\n<\nstrictement inférieur à\n\n\n>=\nsupérieur ou égal à\n\n\n<=\ninférieur ou égal à\n\n\n\nTable 2.2: Opérateurs de comparaison\nVoyons tout de suite un exemple :\n\npoids >= 80\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE FALSE\n\n\nQue s’est-il passé ? Nous avons fourni à R une condition et il nous a renvoyé un vecteur logique avec autant d’éléments qu’il y a d’observations et dont la valeur est TRUE si la condition est remplie et FALSE dans les autres cas. Nous pouvons alors utiliser ce vecteur logique pour obtenir la taille des participants pesant 80 kilogrammes ou plus :\n\ntaille[poids >= 80]\n\n[1] 1.88 1.76   NA\n\n\nOn peut combiner ou modifier des conditions à l’aide des opérateurs logiques habituels :\n\n\n\n\nOpérateur logique\nSignification\n\n\n\n&\net logique\n\n\n|\nou logique\n\n\n!\nnégation logique\n\n\n\nTable 2.3: Opérateurs logiques\nSupposons que je veuille identifier les personnes pesant 80 kilogrammes ou plus et vivant en milieu urbain :\n\npoids >= 80 & urbain\n\n[1]  TRUE FALSE FALSE FALSE FALSE FALSE\n\n\nLes résultats sont différents si je souhaite isoler les personnes pesant 80 kilogrammes ou plus ou vivant milieu urbain :\n\npoids >= 80 | urbain\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\n\n\n\n\n\n\nComparaison et valeur manquante\n\n\n\nUne remarque importante : quand l’un des termes d’une condition comporte une valeur manquante (NA), le résultat de cette condition n’est pas toujours TRUE ou FALSE, il peut aussi être à son tour une valeur manquante.\n\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\ntaille > 1.8\n\n[1]  TRUE FALSE  TRUE FALSE    NA FALSE\n\n\nOn voit que le test NA > 1.8 ne renvoie ni vrai ni faux, mais NA.\nUne autre conséquence importante de ce comportement est qu’on ne peut pas utiliser l’opérateur l’expression == NA pour tester la présence de valeurs manquantes. On utilisera à la place la fonction ad hoc is.na() :\n\nis.na(taille > 1.8)\n\n[1] FALSE FALSE FALSE FALSE  TRUE FALSE\n\n\nPour compliquer encore un peu le tout, lorsqu’on utilise une condition pour l’indexation, si la condition renvoie NA, R ne sélectionne pas l’élément mais retourne quand même la valeur NA. Ceci a donc des conséquences sur le résultat d’une indexation par comparaison.\nPar exemple si je cherche à connaître le poids des personnes mesurant 1,80 mètre ou plus :\n\ntaille\n\n[1] 1.88 1.65 1.92 1.76   NA 1.72\n\npoids\n\n[1] 80 63 75 87 82 67\n\npoids[taille > 1.8]\n\n[1] 80 75 NA\n\n\nLes éléments pour lesquels la taille n’est pas connue ont été transformés en NA, ce qui n’influera pas le calcul d’une moyenne. Par contre, lorsqu’on utilisera assignation et indexation ensemble, cela peut créer des problèmes. Il est donc préférable lorsqu’on a des valeurs manquantes de les exclure ainsi :\n\npoids[taille > 1.8 & !is.na(taille)]\n\n[1] 80 75"
  },
  {
    "objectID": "bases/vecteurs.html#assignation-par-indexation",
    "href": "bases/vecteurs.html#assignation-par-indexation",
    "title": "2  Vecteurs",
    "section": "\n2.9 Assignation par indexation",
    "text": "2.9 Assignation par indexation\nL’indexation peut être combinée avec l’assignation (opérateur <-) pour modifier seulement certaines parties d’un vecteur. Ceci fonctionne pour les différents types d’indexation évoqués précédemment.\n\nv <- 1:5\nv\n\n[1] 1 2 3 4 5\n\nv[1] <- 3\nv\n\n[1] 3 2 3 4 5\n\nsexe[\"Alex\"] <- \"non-binaire\"\nsexe\n\n      Michael          Anna           Dom          John          Alex \n          \"h\"           \"f\"            NA           \"h\" \"non-binaire\" \n         Mary \n          \"f\" \n\n\nEnfin on peut modifier plusieurs éléments d’un seul coup soit en fournissant un vecteur, soit en profitant du mécanisme de recyclage. Les deux commandes suivantes sont ainsi rigoureusement équivalentes :\n\nsexe[c(1,3,4)] <- c(\"Homme\", \"Homme\", \"Homme\")\nsexe[c(1,3,4)] <- \"Homme\"\n\nL’assignation par indexation peut aussi être utilisée pour ajouter une ou plusieurs valeurs à un vecteur :\n\nlength(sexe)\n\n[1] 6\n\nsexe[7] <- \"f\"\nsexe\n\n      Michael          Anna           Dom          John          Alex \n      \"Homme\"           \"f\"       \"Homme\"       \"Homme\" \"non-binaire\" \n         Mary               \n          \"f\"           \"f\" \n\nlength(sexe)\n\n[1] 7"
  },
  {
    "objectID": "bases/vecteurs.html#en-résumé",
    "href": "bases/vecteurs.html#en-résumé",
    "title": "2  Vecteurs",
    "section": "\n2.10 En résumé",
    "text": "2.10 En résumé\n\nUn vecteur est un objet unidimensionnel contenant une liste de valeurs qui sont toutes du même type (entières, numériques, textuelles ou logiques).\nLa fonction class() permet de connaître le type du vecteur et la fonction length() sa longueur, c’est-à-dire son nombre d’éléments.\nLa fonction c() sert à créer et à combiner des vecteurs.\nLes valeurs manquantes sont représentées avec NA.\nUn vecteur peut être nommé, c’est-à-dire qu’un nom textuel a été associé à chaque élément. Cela peut se faire lors de sa création ou avec la fonction names().\nL’indexation consiste à extraire certains éléments d’un vecteur. Pour cela, on indique ce qu’on souhaite extraire entre crochets ([]) juste après le nom du vecteur. Le type d’indexation dépend du type d’information transmise.\nS’il s’agit de nombres entiers, c’est l’indexation par position : les nombres représentent la position dans le vecteur des éléments qu’on souhaite extraire. Un nombre négatif s’interprète comme tous les éléments sauf celui-là.\nSi on indique des chaînes de caractères, c’est l’indexation par nom : on indique le nom des éléments qu’on souhaite extraire. Cette forme d’indexation ne fonctionne que si le vecteur est nommé.\nSi on transmet des valeurs logiques, le plus souvent sous la forme d’une condition, c’est l’indexation par condition : TRUE indique les éléments à extraire et FALSE les éléments à exclure. Il faut être vigilant aux valeurs manquantes (NA) dans ce cas précis.\nEnfin, il est possible de ne modifier que certains éléments d’un vecteur en ayant recours à la fois à l’indexation ([]) et à l’assignation (<-)."
  },
  {
    "objectID": "bases/vecteurs.html#webin-r",
    "href": "bases/vecteurs.html#webin-r",
    "title": "2  Vecteurs",
    "section": "\n2.11 webin-R",
    "text": "2.11 webin-R\nOn pourra également se référer au webin-R #02 (les bases du langage R) sur YouTube."
  },
  {
    "objectID": "bases/listes.html#propriétés-et-création",
    "href": "bases/listes.html#propriétés-et-création",
    "title": "3  Listes",
    "section": "\n3.1 Propriétés et création",
    "text": "3.1 Propriétés et création\nUne liste se crée tout simplement avec la fonction list() :\n\nl1 <- list(1:5, \"abc\")\nl1\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[1] \"abc\"\n\n\nUne liste est un ensemble d’objets, quels qu’ils soient, chaque élément d’une liste pouvant avoir ses propres dimensions. Dans notre exemple précédent, nous avons créé une liste l1 composée de deux éléments : un vecteur d’entiers de longueur 5 et un vecteur textuel de longueur 1. La longueur d’une liste correspond aux nombres d’éléments qu’elle contient et s’obtient avec length() :\n\nlength(l1)\n\n[1] 2\n\n\nComme les vecteurs, une liste peut être nommée et les noms des éléments d’une liste sont accessibles avec names() :\n\nl2 <- list(\n  minuscules = letters, \n  majuscules = LETTERS, \n  mois = month.name\n)\nl2\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$mois\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\nlength(l2)\n\n[1] 3\n\nnames(l2)\n\n[1] \"minuscules\" \"majuscules\" \"mois\"      \n\n\nQue se passe-t-il maintenant si on effectue la commande suivante ?\n\nl <- list(l1, l2)\n\nÀ votre avis, quelle est la longueur de cette nouvelle liste l ? 5 ?\n\nlength(l)\n\n[1] 2\n\n\nEh bien non ! Elle est de longueur 2 car nous avons créé une liste composée de deux éléments qui sont eux-mêmes des listes. Cela est plus lisible si on fait appel à la fonction str() qui permet de visualiser la structure d’un objet.\n\nstr(l)\n\nList of 2\n $ :List of 2\n  ..$ : int [1:5] 1 2 3 4 5\n  ..$ : chr \"abc\"\n $ :List of 3\n  ..$ minuscules: chr [1:26] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ majuscules: chr [1:26] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ mois      : chr [1:12] \"January\" \"February\" \"March\" \"April\" ...\n\n\nUne liste peut contenir tous types d’objets, y compris d’autres listes. Pour combiner les éléments d’une liste, il faut utiliser la fonction append() :\n\nl <- append(l1, l2)\nlength(l)\n\n[1] 5\n\nstr(l)\n\nList of 5\n $           : int [1:5] 1 2 3 4 5\n $           : chr \"abc\"\n $ minuscules: chr [1:26] \"a\" \"b\" \"c\" \"d\" ...\n $ majuscules: chr [1:26] \"A\" \"B\" \"C\" \"D\" ...\n $ mois      : chr [1:12] \"January\" \"February\" \"March\" \"April\" ...\n\n\n\n\n\n\n\n\nNote\n\n\n\nOn peut noter en passant qu’une liste peut tout à fait n’être que partiellement nommée."
  },
  {
    "objectID": "bases/listes.html#indexation",
    "href": "bases/listes.html#indexation",
    "title": "3  Listes",
    "section": "\n3.2 Indexation",
    "text": "3.2 Indexation\nLes crochets simples ([]) fonctionnent comme pour les vecteurs. On peut utiliser à la fois l’indexation par position, l’indexation par nom et l’indexation par condition.\n\nl\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[1] \"abc\"\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$mois\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\nl[c(1,3,4)]\n\n[[1]]\n[1] 1 2 3 4 5\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\nl[c(\"majuscules\", \"minuscules\")]\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nl[c(TRUE, TRUE, FALSE, FALSE, TRUE)]\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[1] \"abc\"\n\n$mois\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\nMême si on extrait un seul élément, l’extraction obtenue avec les crochets simples renvoie toujours une liste, ici composée d’un seul élément :\n\nstr(l[1])\n\nList of 1\n $ : int [1:5] 1 2 3 4 5\n\n\nSupposons que je souhaite calculer la moyenne des valeurs du premier élément de ma liste. Essayons la commande suivante :\n\nmean(l[1])\n\nWarning in mean.default(l[1]): l'argument n'est ni numérique, ni logique :\nrenvoi de NA\n\n\n[1] NA\n\n\nNous obtenons un message d’erreur. En effet, R ne sait pas calculer une moyenne à partir d’une liste. Ce qu’il lui faut, c’est un vecteur de valeurs numériques. Autrement dit, ce que nous cherchons à obtenir c’est le contenu même du premier élément de notre liste et non une liste à un seul élément.\nC’est ici que les doubles crochets ([[]]) vont rentrer en jeu. Pour ces derniers, nous pourrons utiliser l’indexation par position ou l’indexation par nom, mais pas l’indexation par condition. De plus, le critère qu’on indiquera doit indiquer un et un seul élément de notre liste. Au lieu de renvoyer une liste à un élément, les doubles crochets vont renvoyer l’élément désigné.\n\nstr(l[1])\n\nList of 1\n $ : int [1:5] 1 2 3 4 5\n\nstr(l[[1]])\n\n int [1:5] 1 2 3 4 5\n\n\nMaintenant, nous pouvons calculer notre moyenne :\n\nmean(l[[1]])\n\n[1] 3\n\n\nNous pouvons aussi utiliser l’indexation par nom.\n\nl[[\"mois\"]]\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\nMais il faut avouer que cette écriture avec doubles crochets et guillemets est un peu lourde. Heureusement, un nouvel acteur entre en scène : le symbole dollar ($). C’est un raccourci des doubles crochets pour l’indexation par nom qu’on utilise ainsi :\n\nl$mois\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\nLes écritures l$mois et l[[\"mois\"]] sont équivalentes. Attention ! Cela ne fonctionne que pour l’indexation par nom.\n\nl$1\n\n\nError: unexpected numeric constant in \"l$1\"\n\nL’assignation par indexation fonctionne également avec les doubles crochets ou le signe dollar :\n\nl[[2]] <- list(c(\"un\", \"vecteur\", \"textuel\"))\nl$mois <- c(\"Janvier\", \"Février\", \"Mars\")\nl\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n[[2]][[1]]\n[1] \"un\"      \"vecteur\" \"textuel\"\n\n\n$minuscules\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n$majuscules\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n$mois\n[1] \"Janvier\" \"Février\" \"Mars\""
  },
  {
    "objectID": "bases/listes.html#en-résumé",
    "href": "bases/listes.html#en-résumé",
    "title": "3  Listes",
    "section": "\n3.3 En résumé",
    "text": "3.3 En résumé\n\nLes listes sont des objets unidimensionnels pouvant contenir tout type d’objet, y compris d’autres listes.\nElles ont une longueur qu’on obtient avec length().\nOn crée une liste avec list() et on peut fusionner des listes avec append().\nTout comme les vecteurs, les listes peuvent être nommées et les noms des éléments s’obtiennent avec base::names().\nLes crochets simples ([]) permettent de sélectionner les éléments d’une liste, en utilisant l’indexation par position, l’indexation par nom ou l’indexation par condition. Cela renvoie toujours une autre liste.\nLes doubles crochets ([[]]) renvoient directement le contenu d’un élément de la liste qu’on aura sélectionné par position ou par nom.\nLe symbole $ est un raccourci pour facilement sélectionner un élément par son nom, liste$nom étant équivalent à liste[[\"nom\"]]."
  },
  {
    "objectID": "bases/listes.html#webin-r",
    "href": "bases/listes.html#webin-r",
    "title": "3  Listes",
    "section": "\n3.4 webin-R",
    "text": "3.4 webin-R\nOn pourra également se référer au webin-R #02 (les bases du langage R) sur YouTube."
  },
  {
    "objectID": "bases/tableaux_donnees.html#propriétés-et-création",
    "href": "bases/tableaux_donnees.html#propriétés-et-création",
    "title": "4  Tableaux de données",
    "section": "\n4.1 Propriétés et création",
    "text": "4.1 Propriétés et création\nDans R, les tableaux de données sont tout simplement des listes (voir Chapitre 3) avec quelques propriétés spécifiques :\n\nles tableaux de données ne peuvent contenir que des vecteurs ;\ntous les vecteurs d’un tableau de données ont la même longueur ;\ntous les éléments d’un tableau de données sont nommés et ont chacun un nom unique.\n\nDès lors, un tableau de données correspond aux fichiers de données qu’on a l’habitude de manipuler dans d’autres logiciels de statistiques comme SPSS ou Stata. Les variables sont organisées en colonnes et les observations en lignes.\nOn peut créer un tableau de données avec la fonction data.frame() :\n\ndf <- data.frame(\n  sexe =  c(\"f\", \"f\", \"h\", \"h\"), \n  age = c(52, 31, 29, 35), \n  blond = c(FALSE, TRUE, TRUE, FALSE)\n)\ndf\n\n  sexe age blond\n1    f  52 FALSE\n2    f  31  TRUE\n3    h  29  TRUE\n4    h  35 FALSE\n\nstr(df)\n\n'data.frame':   4 obs. of  3 variables:\n $ sexe : chr  \"f\" \"f\" \"h\" \"h\"\n $ age  : num  52 31 29 35\n $ blond: logi  FALSE TRUE TRUE FALSE\n\n\nUn tableau de données étant une liste, la fonction length() renverra le nombre d’éléments de la liste, donc dans le cas présent le nombre de variables, et names() leurs noms :\n\nlength(df)\n\n[1] 3\n\nnames(df)\n\n[1] \"sexe\"  \"age\"   \"blond\"\n\n\nComme tous les éléments d’un tableau de données ont la même longueur, cet objet peut être vu comme bidimensionnel. Les fonctions nrow(), ncol() et dim() donnent respectivement le nombre de lignes, le nombre de colonnes et les dimensions de notre tableau.\n\nnrow(df)\n\n[1] 4\n\nncol(df)\n\n[1] 3\n\ndim(df)\n\n[1] 4 3\n\n\nDe plus, tout comme les colonnes ont un nom, il est aussi possible de nommer les lignes avec row.names() :\n\nrow.names(df) <- c(\"Anna\", \"Mary-Ann\", \"Michael\", \"John\")\ndf\n\n         sexe age blond\nAnna        f  52 FALSE\nMary-Ann    f  31  TRUE\nMichael     h  29  TRUE\nJohn        h  35 FALSE"
  },
  {
    "objectID": "bases/tableaux_donnees.html#indexation",
    "href": "bases/tableaux_donnees.html#indexation",
    "title": "4  Tableaux de données",
    "section": "\n4.2 Indexation",
    "text": "4.2 Indexation\nLes tableaux de données étant des listes, nous pouvons donc utiliser les crochets simples ([]), les crochets doubles ([[]]) et le symbole dollar ($) pour extraire des parties de notre tableau, de la même manière que pour n’importe quelle liste.\n\ndf[1]\n\n         sexe\nAnna        f\nMary-Ann    f\nMichael     h\nJohn        h\n\ndf[[1]]\n\n[1] \"f\" \"f\" \"h\" \"h\"\n\ndf$sexe\n\n[1] \"f\" \"f\" \"h\" \"h\"\n\n\nCependant, un tableau de données étant un objet bidimensionnel, il est également possible d’extraire des données sur deux dimensions, à savoir un premier critère portant sur les lignes et un second portant sur les colonnes. Pour cela, nous utiliserons les crochets simples ([]) en séparant nos deux critères par une virgule (,).\nUn premier exemple :\n\ndf\n\n         sexe age blond\nAnna        f  52 FALSE\nMary-Ann    f  31  TRUE\nMichael     h  29  TRUE\nJohn        h  35 FALSE\n\ndf[3, 2]\n\n[1] 29\n\n\nCette première commande indique que nous souhaitons la troisième ligne de la seconde colonne, autrement dit l’âge de Michael. Le même résultat peut être obtenu avec l’indexation par nom, l’indexation par condition, ou un mélange de tout ça.\n\ndf[\"Michael\", \"age\"]\n\n[1] 29\n\ndf[c(F, F, T, F), c(F, T, F)]\n\n[1] 29\n\ndf[3, \"age\"]\n\n[1] 29\n\ndf[\"Michael\", 2]\n\n[1] 29\n\n\nIl est également possible de préciser un seul critère. Par exemple, si je souhaite les deux premières observations, ou les variables sexe et blond :\n\ndf[1:2,]\n\n         sexe age blond\nAnna        f  52 FALSE\nMary-Ann    f  31  TRUE\n\ndf[,c(\"sexe\", \"blond\")]\n\n         sexe blond\nAnna        f FALSE\nMary-Ann    f  TRUE\nMichael     h  TRUE\nJohn        h FALSE\n\n\nIl a suffi de laisser un espace vide avant ou après la virgule.\n\n\n\n\n\n\nAvertissement\n\n\n\nATTENTION ! Il est cependant impératif de laisser la virgule pour indiquer à R qu’on souhaite effectuer une indexation à deux dimensions. Si on oublie la virgule, cela nous ramène au mode de fonctionnement des listes. Et le résultat n’est pas forcément le même :\n\ndf[2, ]\n\n         sexe age blond\nMary-Ann    f  31  TRUE\n\ndf[, 2]\n\n[1] 52 31 29 35\n\ndf[2]\n\n         age\nAnna      52\nMary-Ann  31\nMichael   29\nJohn      35\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAu passage, on pourra noter quelques subtilités sur le résultat renvoyé.\n\nstr(df[2, ])\n\n'data.frame':   1 obs. of  3 variables:\n $ sexe : chr \"f\"\n $ age  : num 31\n $ blond: logi TRUE\n\nstr(df[, 2])\n\n num [1:4] 52 31 29 35\n\nstr(df[2])\n\n'data.frame':   4 obs. of  1 variable:\n $ age: num  52 31 29 35\n\nstr(df[[2]])\n\n num [1:4] 52 31 29 35\n\n\ndf[2, ] signifie qu’on veut toutes les variables pour le second individu. Le résultat est un tableau de données à une ligne et trois colonnes. df[2] correspond au mode d’extraction des listes et renvoie donc une liste à un élément, en l’occurrence un tableau de données à quatre observations et une variable. df[[2]] quant à lui renvoie le contenu de cette variable, soit un vecteur numérique de longueur quatre. Reste df[, 2] qui renvoie toutes les observations pour la seconde colonne. Or l’indexation bidimensionnelle a un fonctionnement un peu particulier : par défaut elle renvoie un tableau de données mais s’il y a une seule variable dans l’extraction, c’est un vecteur qui est renvoyé. Pour plus de détails, on pourra consulter l’entrée d’aide help(\"[.data.frame\")."
  },
  {
    "objectID": "bases/tableaux_donnees.html#afficher-les-données",
    "href": "bases/tableaux_donnees.html#afficher-les-données",
    "title": "4  Tableaux de données",
    "section": "\n4.3 Afficher les données",
    "text": "4.3 Afficher les données\nPrenons un tableau de données un peu plus conséquent, en l’occurrence le jeu de données ?questionr::hdv2003 disponible dans l’extension questionr et correspondant à un extrait de l’enquête Histoire de vie réalisée par l’INSEE en 2003. Il contient 2000 individus et 20 variables.\n\nlibrary(questionr)\ndata(hdv2003)\n\nSi on demande d’afficher l’objet hdv2003 dans la console (résultat non reproduit ici), R va afficher l’ensemble du contenu de hdv2003 à l’écran ce qui, sur un tableau de cette taille, ne sera pas très lisible. Pour une exploration visuelle, le plus simple est souvent d’utiliser la visionneuse intégrée à RStudio et qu’on peut appeler avec la fonction View().\n\nView(hdv2003)\n\n\n\nFigure 4.1: Interface View() de R RStudio\n\n\nLes fonctions head() et tail(), qui marchent également sur les vecteurs, permettent d’afficher seulement les premières (respectivement les dernières) lignes d’un tableau de données :\n\nhead(hdv2003)\n\n  id age  sexe                                              nivetud    poids\n1  1  28 Femme Enseignement superieur y compris technique superieur 2634.398\n2  2  23 Femme                                                 <NA> 9738.396\n3  3  59 Homme                    Derniere annee d'etudes primaires 3994.102\n4  4  34 Homme Enseignement superieur y compris technique superieur 5731.662\n5  5  71 Femme                    Derniere annee d'etudes primaires 4329.094\n6  6  35 Femme        Enseignement technique ou professionnel court 8674.699\n                  occup     qualif freres.soeurs clso\n1 Exerce une profession    Employe             8  Oui\n2       Etudiant, eleve       <NA>             2  Oui\n3 Exerce une profession Technicien             2  Non\n4 Exerce une profession Technicien             1  Non\n5              Retraite    Employe             0  Oui\n6 Exerce une profession    Employe             5  Non\n                        relig                     trav.imp    trav.satisf\n1 Ni croyance ni appartenance                Peu important Insatisfaction\n2 Ni croyance ni appartenance                         <NA>           <NA>\n3 Ni croyance ni appartenance Aussi important que le reste      Equilibre\n4  Appartenance sans pratique Moins important que le reste   Satisfaction\n5         Pratiquant regulier                         <NA>           <NA>\n6 Ni croyance ni appartenance            Le plus important      Equilibre\n  hard.rock lecture.bd peche.chasse cuisine bricol cinema sport heures.tv\n1       Non        Non          Non     Oui    Non    Non   Non         0\n2       Non        Non          Non     Non    Non    Oui   Oui         1\n3       Non        Non          Non     Non    Non    Non   Oui         0\n4       Non        Non          Non     Oui    Oui    Oui   Oui         2\n5       Non        Non          Non     Non    Non    Non   Non         3\n6       Non        Non          Non     Non    Non    Oui   Oui         2\n\ntail(hdv2003, 2)\n\n       id age  sexe                                       nivetud     poids\n1999 1999  24 Femme Enseignement technique ou professionnel court 13740.810\n2000 2000  66 Femme  Enseignement technique ou professionnel long  7709.513\n                     occup  qualif freres.soeurs clso\n1999 Exerce une profession Employe             2  Non\n2000              Au foyer Employe             3  Non\n                          relig                     trav.imp trav.satisf\n1999 Appartenance sans pratique Moins important que le reste   Equilibre\n2000 Appartenance sans pratique                         <NA>        <NA>\n     hard.rock lecture.bd peche.chasse cuisine bricol cinema sport heures.tv\n1999       Non        Non          Non     Non    Non    Oui   Non       0.3\n2000       Non        Oui          Non     Oui    Non    Non   Non       0.0\n\n\nL’extension dplyr propose une fonction dplyr::glimpse() (ce qui signifie aperçu en anglais) qui permet de visualiser rapidement et de manière condensée le contenu d’un tableau de données.\n\nlibrary(dplyr)\nglimpse(hdv2003)\n\nRows: 2,000\nColumns: 20\n$ id            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ age           <int> 28, 23, 59, 34, 71, 35, 60, 47, 20, 28, 65, 47, 63, 67, …\n$ sexe          <fct> Femme, Femme, Homme, Homme, Femme, Femme, Femme, Homme, …\n$ nivetud       <fct> \"Enseignement superieur y compris technique superieur\", …\n$ poids         <dbl> 2634.3982, 9738.3958, 3994.1025, 5731.6615, 4329.0940, 8…\n$ occup         <fct> \"Exerce une profession\", \"Etudiant, eleve\", \"Exerce une …\n$ qualif        <fct> Employe, NA, Technicien, Technicien, Employe, Employe, O…\n$ freres.soeurs <int> 8, 2, 2, 1, 0, 5, 1, 5, 4, 2, 3, 4, 1, 5, 2, 3, 4, 0, 2,…\n$ clso          <fct> Oui, Oui, Non, Non, Oui, Non, Oui, Non, Oui, Non, Oui, O…\n$ relig         <fct> Ni croyance ni appartenance, Ni croyance ni appartenance…\n$ trav.imp      <fct> Peu important, NA, Aussi important que le reste, Moins i…\n$ trav.satisf   <fct> Insatisfaction, NA, Equilibre, Satisfaction, NA, Equilib…\n$ hard.rock     <fct> Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, N…\n$ lecture.bd    <fct> Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, Non, N…\n$ peche.chasse  <fct> Non, Non, Non, Non, Non, Non, Oui, Oui, Non, Non, Non, N…\n$ cuisine       <fct> Oui, Non, Non, Oui, Non, Non, Oui, Oui, Non, Non, Oui, N…\n$ bricol        <fct> Non, Non, Non, Oui, Non, Non, Non, Oui, Non, Non, Oui, O…\n$ cinema        <fct> Non, Oui, Non, Oui, Non, Oui, Non, Non, Oui, Oui, Oui, N…\n$ sport         <fct> Non, Oui, Oui, Oui, Non, Oui, Non, Non, Non, Oui, Non, O…\n$ heures.tv     <dbl> 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.9, 1.0, 2.0, 2.0, 1.0, 0…\n\n\nL’extension labelled propose une fonction labelled::look_for() qui permet de lister les différentes variables d’un fichier de données :\n\nlibrary(labelled)\nlook_for(hdv2003)\n\n pos variable      label col_type values                                     \n 1   id            —     int                                                 \n 2   age           —     int                                                 \n 3   sexe          —     fct      Homme                                      \n                                  Femme                                      \n 4   nivetud       —     fct      N'a jamais fait d'etudes                   \n                                  A arrete ses etudes, avant la derniere ann~\n                                  Derniere annee d'etudes primaires          \n                                  1er cycle                                  \n                                  2eme cycle                                 \n                                  Enseignement technique ou professionnel co~\n                                  Enseignement technique ou professionnel lo~\n                                  Enseignement superieur y compris technique~\n 5   poids         —     dbl                                                 \n 6   occup         —     fct      Exerce une profession                      \n                                  Chomeur                                    \n                                  Etudiant, eleve                            \n                                  Retraite                                   \n                                  Retire des affaires                        \n                                  Au foyer                                   \n                                  Autre inactif                              \n 7   qualif        —     fct      Ouvrier specialise                         \n                                  Ouvrier qualifie                           \n                                  Technicien                                 \n                                  Profession intermediaire                   \n                                  Cadre                                      \n                                  Employe                                    \n                                  Autre                                      \n 8   freres.soeurs —     int                                                 \n 9   clso          —     fct      Oui                                        \n                                  Non                                        \n                                  Ne sait pas                                \n 10  relig         —     fct      Pratiquant regulier                        \n                                  Pratiquant occasionnel                     \n                                  Appartenance sans pratique                 \n                                  Ni croyance ni appartenance                \n                                  Rejet                                      \n                                  NSP ou NVPR                                \n 11  trav.imp      —     fct      Le plus important                          \n                                  Aussi important que le reste               \n                                  Moins important que le reste               \n                                  Peu important                              \n 12  trav.satisf   —     fct      Satisfaction                               \n                                  Insatisfaction                             \n                                  Equilibre                                  \n 13  hard.rock     —     fct      Non                                        \n                                  Oui                                        \n 14  lecture.bd    —     fct      Non                                        \n                                  Oui                                        \n 15  peche.chasse  —     fct      Non                                        \n                                  Oui                                        \n 16  cuisine       —     fct      Non                                        \n                                  Oui                                        \n 17  bricol        —     fct      Non                                        \n                                  Oui                                        \n 18  cinema        —     fct      Non                                        \n                                  Oui                                        \n 19  sport         —     fct      Non                                        \n                                  Oui                                        \n 20  heures.tv     —     dbl                                                 \n\n\nLorsqu’on a un gros tableau de données avec de nombreuses variables, il peut être difficile de retrouver la ou les variables d’intérêt. Il est possible d’indiquer à labelled::look_for() un mot-clé pour limiter la recherche. Par exemple :\n\nlook_for(hdv2003, \"trav\")\n\n pos variable    label col_type values                      \n 11  trav.imp    —     fct      Le plus important           \n                                Aussi important que le reste\n                                Moins important que le reste\n                                Peu important               \n 12  trav.satisf —     fct      Satisfaction                \n                                Insatisfaction              \n                                Equilibre                   \n\n\nIl est à noter que si la recherche n’est pas sensible à la casse (i.e. aux majuscules et aux minuscules), elle est sensible aux accents.\nLa méthode summary() qui fonctionne sur tout type d’objet permet d’avoir quelques statistiques de base sur les différentes variables de notre tableau, les statistiques affichées dépendant du type de variable.\n\nsummary(hdv2003)\n\n       id              age           sexe     \n Min.   :   1.0   Min.   :18.00   Homme: 899  \n 1st Qu.: 500.8   1st Qu.:35.00   Femme:1101  \n Median :1000.5   Median :48.00               \n Mean   :1000.5   Mean   :48.16               \n 3rd Qu.:1500.2   3rd Qu.:60.00               \n Max.   :2000.0   Max.   :97.00               \n                                              \n                                                 nivetud        poids         \n Enseignement technique ou professionnel court       :463   Min.   :   78.08  \n Enseignement superieur y compris technique superieur:441   1st Qu.: 2221.82  \n Derniere annee d'etudes primaires                   :341   Median : 4631.19  \n 1er cycle                                           :204   Mean   : 5535.61  \n 2eme cycle                                          :183   3rd Qu.: 7626.53  \n (Other)                                             :256   Max.   :31092.14  \n NA's                                                :112                     \n                   occup                           qualif    freres.soeurs   \n Exerce une profession:1049   Employe                 :594   Min.   : 0.000  \n Chomeur              : 134   Ouvrier qualifie        :292   1st Qu.: 1.000  \n Etudiant, eleve      :  94   Cadre                   :260   Median : 2.000  \n Retraite             : 392   Ouvrier specialise      :203   Mean   : 3.283  \n Retire des affaires  :  77   Profession intermediaire:160   3rd Qu.: 5.000  \n Au foyer             : 171   (Other)                 :144   Max.   :22.000  \n Autre inactif        :  83   NA's                    :347                   \n          clso                              relig    \n Oui        : 936   Pratiquant regulier        :266  \n Non        :1037   Pratiquant occasionnel     :442  \n Ne sait pas:  27   Appartenance sans pratique :760  \n                    Ni croyance ni appartenance:399  \n                    Rejet                      : 93  \n                    NSP ou NVPR                : 40  \n                                                     \n                         trav.imp           trav.satisf  hard.rock  lecture.bd\n Le plus important           : 29   Satisfaction  :480   Non:1986   Non:1953  \n Aussi important que le reste:259   Insatisfaction:117   Oui:  14   Oui:  47  \n Moins important que le reste:708   Equilibre     :451                        \n Peu important               : 52   NA's          :952                        \n NA's                        :952                                             \n                                                                              \n                                                                              \n peche.chasse cuisine    bricol     cinema     sport        heures.tv     \n Non:1776     Non:1119   Non:1147   Non:1174   Non:1277   Min.   : 0.000  \n Oui: 224     Oui: 881   Oui: 853   Oui: 826   Oui: 723   1st Qu.: 1.000  \n                                                          Median : 2.000  \n                                                          Mean   : 2.247  \n                                                          3rd Qu.: 3.000  \n                                                          Max.   :12.000  \n                                                          NA's   :5       \n\n\nOn peut également appliquer summary() à une variable particulière.\n\nsummary(hdv2003$sexe)\n\nHomme Femme \n  899  1101 \n\nsummary(hdv2003$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   35.00   48.00   48.16   60.00   97.00"
  },
  {
    "objectID": "bases/tableaux_donnees.html#en-résumé",
    "href": "bases/tableaux_donnees.html#en-résumé",
    "title": "4  Tableaux de données",
    "section": "\n4.4 En résumé",
    "text": "4.4 En résumé\n\nLes tableaux de données sont des listes avec des propriétés particulières :\n\ntous les éléments sont des vecteurs ;\ntous les vecteurs ont la même longueur ;\ntous les vecteurs ont un nom et ce nom est unique.\n\n\nOn peut créer un tableau de données avec data.frame().\nLes tableaux de données correspondent aux fichiers de données qu’on utilise usuellement dans d’autres logiciels de statistiques : les variables sont représentées en colonnes et les observations en lignes.\nCe sont des objets bidimensionnels : ncol() renvoie le nombre de colonnes et nrow() le nombre de lignes.\nLes doubles crochets ([[]]) et le symbole dollar ($) fonctionnent comme pour les listes et permettent d’accéder aux variables.\nIl est possible d’utiliser des coordonnées bidimensionnelles avec les crochets simples ([]) en indiquant un critère sur les lignes puis un critère sur les colonnes, séparés par une virgule (,)."
  },
  {
    "objectID": "bases/tableaux_donnees.html#webin-r",
    "href": "bases/tableaux_donnees.html#webin-r",
    "title": "4  Tableaux de données",
    "section": "\n4.5 webin-R",
    "text": "4.5 webin-R\nOn pourra également se référer au webin-R #02 (les bases du langage R) sur YouTube."
  },
  {
    "objectID": "bases/tibbles.html#sec-tidy-data",
    "href": "bases/tibbles.html#sec-tidy-data",
    "title": "5  Tibbles",
    "section": "\n5.1 Le concept de tidy data",
    "text": "5.1 Le concept de tidy data\nLe tidyverse est en partie fondé sur le concept de tidy data, développé à l’origine par Hadley Wickham dans un article de 2014 du Journal of Statistical Software.\nIl s’agit d’un modèle d’organisation des données qui vise à faciliter le travail souvent long et fastidieux de nettoyage et de préparation préalable à la mise en oeuvre de méthodes d’analyse.\nLes principes d’un jeu de données tidy sont les suivants :\n\nchaque variable est une colonne\nchaque observation est une ligne\nchaque type d’observation est dans une table différente\n\nUn chapitre dédié à tidyr (voir Chapitre 26) présente comment définir et rendre des données tidy avec ce package.\nLes extensions du tidyverse, notamment ggplot2 et dplyr, sont prévues pour fonctionner avec des données tidy."
  },
  {
    "objectID": "bases/tibbles.html#tibbles",
    "href": "bases/tibbles.html#tibbles",
    "title": "5  Tibbles",
    "section": "\n5.2 tibbles : des tableaux de données améliorés",
    "text": "5.2 tibbles : des tableaux de données améliorés\nUne autre particularité du tidyverse est que ces extensions travaillent avec des tableaux de données au format tibble::tibble(), qui est une évolution plus moderne du classique data.frame de R de base.\nCe format est fourni est géré par l’extension du même nom (tibble), qui fait partie du coeur du tidyverse. La plupart des fonctions des extensions du tidyverse acceptent des data.frames en entrée, mais retournent un tibble.\nContrairement aux data frames, les tibbles :\n\nn’ont pas de noms de lignes (rownames)\nautorisent des noms de colonnes invalides pour les data frames (espaces, caractères spéciaux, nombres…) 1\n\ns’affichent plus intelligemment que les data frames : seules les premières lignes sont affichées, ainsi que quelques informations supplémentaires utiles (dimensions, types des colonnes…)\nne font pas de partial matching sur les noms de colonnes 2\n\naffichent un avertissement si on essaie d’accéder à une colonne qui n’existe pas\n\n1 Quand on veut utiliser des noms de ce type, on doit les entourer avec des backticks (`)2 Dans R base, si une table d contient une colonne qualif, d$qual retournera cette colonne.Pour autant, les tibbles restent compatibles avec les data frames.\nIl est possible de créer un tibble manuellement avec tibble::tibble().\n\n\n\n\nlibrary(tidyverse)\ntibble(\n  x = c(1.2345, 12.345, 123.45, 1234.5, 12345),\n  y = c(\"a\", \"b\", \"c\", \"d\", \"e\")\n)\n\n# A tibble: 5 × 2\n         x y    \n     <dbl> <chr>\n1     1.23 a    \n2    12.3  b    \n3   123.   c    \n4  1234.   d    \n5 12345    e    \n\n\nOn peut ainsi facilement convertir un data frame en tibble avec tibble::as_tibble() :\n\nd <- as_tibble(mtcars)\nd\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# … with 22 more rows\n\n\nD’ailleurs, quand on regarde la classe d’un tibble, on peut s’apercevoir qu’un tibble hérite de la classe data.frame mais possède en plus la classe tbl_df. Cela traduit bien le fait que les tibbles restent des data frames.\n\nclass(d)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nSi le data frame d’origine a des rownames, on peut d’abord les convertir en colonnes avec tibble::rownames_to_columns() :\n\nd <- as_tibble(rownames_to_column(mtcars))\nd\n\n# A tibble: 32 × 12\n   rowname       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <chr>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# … with 22 more rows\n\n\nÀ l’inverse, on peut à tout moment convertir un tibble en data frame avec tibble::as.data.frame() :\n\nas.data.frame(d)\n\n               rowname  mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n1            Mazda RX4 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n2        Mazda RX4 Wag 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n3           Datsun 710 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n4       Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n5    Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n6              Valiant 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n7           Duster 360 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n8            Merc 240D 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n9             Merc 230 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n10            Merc 280 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n11           Merc 280C 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n12          Merc 450SE 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n13          Merc 450SL 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n14         Merc 450SLC 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n15  Cadillac Fleetwood 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n16 Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n17   Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n18            Fiat 128 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n19         Honda Civic 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n20      Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n21       Toyota Corona 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n22    Dodge Challenger 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n23         AMC Javelin 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n24          Camaro Z28 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n25    Pontiac Firebird 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n26           Fiat X1-9 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n27       Porsche 914-2 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n28        Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n29      Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n30        Ferrari Dino 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n31       Maserati Bora 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n32          Volvo 142E 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nLà encore, on peut convertir la colonne rowname en “vrais” rownames avec tibble::column_to_rownames() :\n\ncolumn_to_rownames(as.data.frame(d))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\n\n\n\n\n\nNote\n\n\n\nLes deux fonctions tibble::column_to_rownames() et tibble::rownames_to_column() acceptent un argument supplémentaire var qui permet d’indiquer un nom de colonne autre que le nom rowname utilisé par défaut pour créer ou identifier la colonne contenant les noms de lignes."
  },
  {
    "objectID": "bases/tibbles.html#données-et-tableaux-imbriqués",
    "href": "bases/tibbles.html#données-et-tableaux-imbriqués",
    "title": "5  Tibbles",
    "section": "\n5.3 Données et tableaux imbriqués",
    "text": "5.3 Données et tableaux imbriqués\nUne des particularités des tibbles est qu’ils acceptent, à la différence des data frames, des colonnes composées de listes et, par extension, d’autres tibbles (qui sont des listes)  !\n\nd <- tibble(\n  g = c(1, 2, 3),\n  data = list(\n    tibble(x = 1, y = 2),\n    tibble(x = 4:5, y = 6:7),\n    tibble(x = 10)\n  )\n)\nd\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 1]>\n\nd$data[[2]]\n\n# A tibble: 2 × 2\n      x     y\n  <int> <int>\n1     4     6\n2     5     7\n\n\nCette fonctionalité, combinée avec les fonctions de tidyr et de purrr, s’avère très puissante pour réaliser des opérations multiples en peu de ligne de code.\nDans l’exemple ci-dessous, nous réalisons des régressions linéaires par sous-groupe et les présentons dans un même tableau. Pour le moment, le code présenté doit vous sembler complexe et un peu obscur. Pas de panique : tout cela sera clarifié dans les differents chapitres de ce guide. Ce qu’il y a à retenir pour le moment, c’est la possibilité de stocker, dans les colonnes d’un tibble, différent types de données, y compris des sous-tableaux, des résultats de modèles et même des tableaux mis en forme.\n\nreg <-\n  iris |> \n  group_by(Species) |> \n  nest() |> \n  mutate(\n    model = map(\n      data, \n      ~ lm(Sepal.Length ~ Petal.Length + Petal.Width, data = .)\n    ),\n    tbl = map(model, gtsummary::tbl_regression)\n  )\nreg\n\n# A tibble: 3 × 4\n# Groups:   Species [3]\n  Species    data              model  tbl       \n  <fct>      <list>            <list> <list>    \n1 setosa     <tibble [50 × 4]> <lm>   <tbl_rgrs>\n2 versicolor <tibble [50 × 4]> <lm>   <tbl_rgrs>\n3 virginica  <tibble [50 × 4]> <lm>   <tbl_rgrs>\n\ngtsummary::tbl_merge(\n  reg$tbl,\n  tab_spanner = paste0(\"**\", reg$Species, \"**\")\n)\n\n\n\n\n\n\n\nCharacteristic\n      \n        setosa\n      \n      \n        versicolor\n      \n      \n        virginica\n      \n    \n\nBeta\n      \n95% CI1\n\n      p-value\n      Beta\n      \n95% CI1\n\n      p-value\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n\nPetal.Length\n0.40\n-0.20, 1.0\n0.2\n0.93\n0.59, 1.3\n<0.001\n1.0\n0.81, 1.2\n<0.001\n\n\nPetal.Width\n0.71\n-0.27, 1.7\n0.2\n-0.32\n-1.1, 0.49\n0.4\n0.01\n-0.35, 0.37\n>0.9\n\n\n\n\n1 CI = Confidence Interval"
  },
  {
    "objectID": "bases/attributs.html",
    "href": "bases/attributs.html",
    "title": "6  Attributs",
    "section": "",
    "text": "Les objets R peuvent avoir des attributs qui correspondent en quelque sorte à des métadonnées associées à l’objet en question. Techniquement, un attribut peut être tout type d’objet R (un vecteur, une liste, une fonction…).\nParmi les attributs les plus courants, on retrouve nottament :\n\n\nclass : la classe de l’objet\n\nlenghth : sa longueur\n\nnames : les noms donnés aux éléments de l’objet\n\nlevels : pour les facteurs, les étiquettes des différents niveaux\n\nlabel : une étiquette de variable\n\nLa fonction attributes() permet de lister tous les attributs associés à un objet.\n\nattributes(iris)\n\n$names\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n$class\n[1] \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150\n\n\nPour accéder à un attribut spécifique, on aura recours à attr() en spéficiant à la fois l’objet considéré et le nom de l’attribut souhaité.\n\niris |> attr(\"names\")\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\nPour les attributs les plus courants de R, il faut noter qu’il existe le plus souvent des fonctions spécifiques, comme class(), names() ou row.names().\n\nclass(iris)\n\n[1] \"data.frame\"\n\nnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\nLa fonction attr(), associée à l’opérateur d’assignation (<-) permet également de définir ses propres attributs.\n\nattr(iris, \"perso\") <- \"Des notes personnelles\"\nattributes(iris)\n\n$names\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n$class\n[1] \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150\n\n$perso\n[1] \"Des notes personnelles\"\n\nattr(iris, \"perso\")\n\n[1] \"Des notes personnelles\""
  },
  {
    "objectID": "manipulation/pipe.html#le-pipe-natif-de-r",
    "href": "manipulation/pipe.html#le-pipe-natif-de-r",
    "title": "7  Le pipe",
    "section": "\n7.1 Le pipe natif de R : |>\n",
    "text": "7.1 Le pipe natif de R : |>\n\nDepuis la version 4.1, R a introduit ce que l’on nomme un pipe (tuyau en anglais), un nouvel opérateur noté |>.\nLe principe de cet opérateur est de passer l’élément situé à sa gauche comme premier argument de la fonction située à sa droite. Ainsi, l’écriture x |> f() est équivalente à f(x) et l’écriture x |> f(y) à f(x, y).\nParfois, on souhaite passer l’objet x à un autre endroit de la fonction f() que le premier argument. Depuis la version 4.2, R a introduit l’opérateur _,que l’on nomme un placeholder, pour indiquer où passer l’objet de gauche. Ainsi, x |> f(y, a = _) devient équivalent à f(y, a = x). ATTENTION : le placeholder doit impérativement être transmis à un argument nommé !\nTout cela semble encore un peu abstrait ? Reprenons notre exemple précédent et réécrivons le code avec le pipe.\n\nv |> \n  mean() |> \n  round(digits = 1) |> \n  format(decimal.mark = \",\") |> \n  paste0(\"La moyenne est de \", m = _, \".\") |> \n  message()\n\nLa moyenne est de 6,7.\n\n\nLe code n’est-il pas plus lisible ?\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code."
  },
  {
    "objectID": "manipulation/pipe.html#le-pipe-du-tidyverse",
    "href": "manipulation/pipe.html#le-pipe-du-tidyverse",
    "title": "7  Le pipe",
    "section": "\n7.2 Le pipe du tidyverse : %>%\n",
    "text": "7.2 Le pipe du tidyverse : %>%\n\nCe n’est qu’à partir de la version 4.1 sortie en 2021 que R a proposé de manière native un pipe, en l’occurence l’opérateur |>.\nEn cela, R s’est notamment inspiré d’un opérateur similaire introduit dès 2014 dans le tidyverse. Le pipe du tidyverse fonctionne de manière similaire. Il est implémenté dans le package magrittr qui doit donc être chargé en mémoire. Le pipe est également disponible lorsque l’on effecture library(tidyverse).\nCet opérateur s’écrit %>% et il dispose lui aussi d’un placeholder qui est le .. La syntaxe du placeholder est un peu plus souple puisqu’il peut être passé à tout type d’argument, y compris un argument sans nom. Si l’on reprend notre exemple précédent.\n\nlibrary(magrittr)\nv %>% \n  mean() %>%\n  round(digits = 1) %>%\n  format(decimal.mark = \",\") %>%\n  paste0(\"La moyenne est de \", ., \".\") %>%\n  message()\n\nLa moyenne est de 6,7."
  },
  {
    "objectID": "manipulation/pipe.html#vaut-il-mieux-utiliser-ou",
    "href": "manipulation/pipe.html#vaut-il-mieux-utiliser-ou",
    "title": "7  Le pipe",
    "section": "\n7.3 Vaut-il mieux utiliser |> ou %>% ?",
    "text": "7.3 Vaut-il mieux utiliser |> ou %>% ?\n\n\n\n\nBonne question. Si vous utilisez une version récente de R (≥ 4.2), il est préférable d’avoir recours au pipe natif de R dans la mesure où il est plus efficient en termes de temps de calcul car il fait partie intégrante du langage. Dans ce guide, nous privilégeons d’ailleurs l’utilisation de |>.\nSi votre code nécessite de fonctionner avec différentes versions de R, par exemple dans le cadre d’un package, il est alors préférable, pour le moment, d’utiliser celui fourni par magrittr (%>%)."
  },
  {
    "objectID": "manipulation/pipe.html#sec-pluck-chuck",
    "href": "manipulation/pipe.html#sec-pluck-chuck",
    "title": "7  Le pipe",
    "section": "\n7.4 Accéder à un élément avec purrr::pluck() et purrr::chuck()\n",
    "text": "7.4 Accéder à un élément avec purrr::pluck() et purrr::chuck()\n\nIl est fréquent d’avoir besoin d’accéder à un élément précis d’une liste, d’un tableau ou d’un vecteur, ce que l’on fait d’ordinaire avec la syntaxe [[]] ou $ pour les listes ou [] pour les vecteurs. Cependant, cette syntaxe se combine souvent mal avec un enchaînement d’opérations utilisant le pipe.\nLe package purrr, chargé par défaut avec library(tidyverse), fournit une fonction purrr::pluck() qui, est l’équivalent de [[]], et qui permet de récupérer un élément par son nom ou sa position. Ainsi, si l’on considère le tableau de données iris, pluck(iris, \"Petal.Witdh\") est équivalent à iris$Petal.Width. Voyons un example d’utilisation dans le cadre d’un enchaînement d’opérations.\n\niris |> \n  purrr::pluck(\"Petal.Width\") |> \n  mean()\n\n[1] 1.199333\n\n\nCette écriture est équivalente à :\n\nmean(iris$Petal.Width)\n\n[1] 1.199333\n\n\npurrr::pluck() fonctionne également sur des vecteurs (et dans ce cas opère comme []).\n\nv <- c(\"a\", \"b\", \"c\", \"d\")\nv |> purrr::pluck(2)\n\n[1] \"b\"\n\nv[2]\n\n[1] \"b\"\n\n\nOn peut également, dans un même appel à purrr::pluck(), enchaîner plusieurs niveaux. Les trois syntaxes ci-après sont ainsi équivalents :\n\niris |> \n  purrr::pluck(\"Sepal.Width\", 3)\n\n[1] 3.2\n\niris |> \n  purrr::pluck(\"Sepal.Width\") |> \n  purrr::pluck(3)\n\n[1] 3.2\n\niris[[\"Sepal.Width\"]][3]\n\n[1] 3.2\n\n\nSi l’on demande un élément qui n’existe pas, purrr:pluck() renverra l’élement vide (NULL). Si l’on souhaite plutôt que cela génère une erreur, on aura alors recours à purrr::chuck().\n\niris |> purrr::pluck(\"inconnu\")\n\nNULL\n\niris |> purrr::chuck(\"inconnu\")\n\nError in `purrr::chuck()`:\n! Can't find name `inconnu` in vector.\n\nv |> purrr::pluck(10)\n\nNULL\n\nv |> purrr::chuck(10)\n\nError in `purrr::chuck()`:\n! Index 1 exceeds the length of plucked object (10 > 4)."
  },
  {
    "objectID": "manipulation/dplyr.html#opérations-sur-les-lignes",
    "href": "manipulation/dplyr.html#opérations-sur-les-lignes",
    "title": "8  dplyr",
    "section": "\n8.1 Opérations sur les lignes",
    "text": "8.1 Opérations sur les lignes\n\n8.1.1 filter()\ndplyr::filter() sélectionne des lignes d’un tableau de données selon une condition. On lui passe en paramètre un test, et seules les lignes pour lesquelles ce test renvoit TRUE (vrai) sont conservées2.2 Si le test renvoie faux (FALSE) ou une valeur manquante (NA), les lignes correspondantes ne seront donc pas sélectionnées.\nPar exemple, si on veut sélectionner les vols du mois de janvier, on peut filtrer sur la variable month de la manière suivante :\n\nfilter(flights, month == 1)\n\n# A tibble: 27,004 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     1      533        529       4     850     830      20 UA     \n 3  2013     1     1      542        540       2     923     850      33 AA     \n 4  2013     1     1      544        545      -1    1004    1022     -18 B6     \n 5  2013     1     1      554        600      -6     812     837     -25 DL     \n 6  2013     1     1      554        558      -4     740     728      12 UA     \n 7  2013     1     1      555        600      -5     913     854      19 B6     \n 8  2013     1     1      557        600      -3     709     723     -14 EV     \n 9  2013     1     1      557        600      -3     838     846      -8 B6     \n10  2013     1     1      558        600      -2     753     745       8 AA     \n# … with 26,994 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nCela peut s’écrire plus simplement avec un pipe :\n\nflights |> filter(month == 1)\n\n# A tibble: 27,004 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     1      533        529       4     850     830      20 UA     \n 3  2013     1     1      542        540       2     923     850      33 AA     \n 4  2013     1     1      544        545      -1    1004    1022     -18 B6     \n 5  2013     1     1      554        600      -6     812     837     -25 DL     \n 6  2013     1     1      554        558      -4     740     728      12 UA     \n 7  2013     1     1      555        600      -5     913     854      19 B6     \n 8  2013     1     1      557        600      -3     709     723     -14 EV     \n 9  2013     1     1      557        600      -3     838     846      -8 B6     \n10  2013     1     1      558        600      -2     753     745       8 AA     \n# … with 26,994 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nSi l’on veut uniquement les vols avec un retard au départ (variable dep_delay) compris entre 10 et 15 minutes :\n\nflights |> \n  filter(dep_delay >= 10 & dep_delay <= 15)\n\n# A tibble: 14,919 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      611        600      11     945     931      14 UA     \n 2  2013     1     1      623        610      13     920     915       5 AA     \n 3  2013     1     1      743        730      13    1107    1100       7 AA     \n 4  2013     1     1      743        730      13    1059    1056       3 DL     \n 5  2013     1     1      851        840      11    1215    1206       9 UA     \n 6  2013     1     1      912        900      12    1241    1220      21 AA     \n 7  2013     1     1      914        900      14    1058    1043      15 UA     \n 8  2013     1     1      920        905      15    1039    1025      14 B6     \n 9  2013     1     1     1011       1001      10    1133    1128       5 EV     \n10  2013     1     1     1112       1100      12    1440    1438       2 UA     \n# … with 14,909 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nSi l’on passe plusieurs arguments à dplyr::filter(), celui-ci rajoute automatiquement une condition ET. La ligne ci-dessus peut donc également être écrite de la manière suivante, avec le même résultat :\n\nflights |> \n  filter(dep_delay >= 10, dep_delay <= 15)\n\nEnfin, on peut également placer des fonctions dans les tests, qui nous permettent par exemple de sélectionner les vols avec la plus grande distance :\n\nflights |> \n  filter(distance == max(distance))\n\n# A tibble: 342 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      857        900      -3    1516    1530     -14 HA     \n 2  2013     1     2      909        900       9    1525    1530      -5 HA     \n 3  2013     1     3      914        900      14    1504    1530     -26 HA     \n 4  2013     1     4      900        900       0    1516    1530     -14 HA     \n 5  2013     1     5      858        900      -2    1519    1530     -11 HA     \n 6  2013     1     6     1019        900      79    1558    1530      28 HA     \n 7  2013     1     7     1042        900     102    1620    1530      50 HA     \n 8  2013     1     8      901        900       1    1504    1530     -26 HA     \n 9  2013     1     9      641        900    1301    1242    1530    1272 HA     \n10  2013     1    10      859        900      -1    1449    1530     -41 HA     \n# … with 332 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\n\n\n\n\n\nÉvaluation contextuelle\n\n\n\nIl est important de noter que dplyr procède à une évaluation contextuelle des expressions qui lui sont passées. Ainsi, on peut indiquer directement le nom d’une variable et dplyr l’interprétera dans le contexte du tableau de données, c’est-à-dire regardera s’il existe une colonne portant ce nom dans le tableau.\nDans l’expression flights |> filter(month == 1), month est interprété comme la colonne month du tableau flights, à savoir flights$month.\nIl est également possible d’indiquer des objets extérieurs au tableau :\n\nm <- 2\nflights |> \n  filter(month == m)\n\n# A tibble: 24,951 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     2     1      456        500      -4     652     648       4 US     \n 2  2013     2     1      520        525      -5     816     820      -4 UA     \n 3  2013     2     1      527        530      -3     837     829       8 UA     \n 4  2013     2     1      532        540      -8    1007    1017     -10 B6     \n 5  2013     2     1      540        540       0     859     850       9 AA     \n 6  2013     2     1      552        600      -8     714     715      -1 EV     \n 7  2013     2     1      552        600      -8     919     910       9 AA     \n 8  2013     2     1      552        600      -8     655     709     -14 B6     \n 9  2013     2     1      553        600      -7     833     815      18 FL     \n10  2013     2     1      553        600      -7     821     825      -4 MQ     \n# … with 24,941 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nCela fonctionne car il n’y a pas de colonne m dans flights. Dès lors, dplyr regarde s’il existe un objet m dans l’environnement de travail.\nPar contre, si une colonne existe dans le tableau, elle aura priorité sur les objets du même nom dans l’environnement. Dans l’exemple ci-dessous, le résultat obtenu n’est pas celui voulu. Il est interprété comme sélectionner toutes les lignes où la colonne mois est égale à elle-même et donc cela sélectionne toutes les lignes du tableau.\n\nmonth <- 3\nflights |> \n  filter(month == month)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     1      533        529       4     850     830      20 UA     \n 3  2013     1     1      542        540       2     923     850      33 AA     \n 4  2013     1     1      544        545      -1    1004    1022     -18 B6     \n 5  2013     1     1      554        600      -6     812     837     -25 DL     \n 6  2013     1     1      554        558      -4     740     728      12 UA     \n 7  2013     1     1      555        600      -5     913     854      19 B6     \n 8  2013     1     1      557        600      -3     709     723     -14 EV     \n 9  2013     1     1      557        600      -3     838     846      -8 B6     \n10  2013     1     1      558        600      -2     753     745       8 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nAfin de distinguer ce qui correspond à une colonne du tableau et à un objet de l’environnement, on pourra avoir recours à .data et .env (voir help(\".env\", package = \"rlang\")).\n\nmonth <- 3\nflights |> \n  filter(.data$month == .env$month)\n\n# A tibble: 28,834 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     3     1        4       2159     125     318      56     142 B6     \n 2  2013     3     1       50       2358      52     526     438      48 B6     \n 3  2013     3     1      117       2245     152     223    2354     149 B6     \n 4  2013     3     1      454        500      -6     633     648     -15 US     \n 5  2013     3     1      505        515     -10     746     810     -24 UA     \n 6  2013     3     1      521        530      -9     813     827     -14 UA     \n 7  2013     3     1      537        540      -3     856     850       6 AA     \n 8  2013     3     1      541        545      -4    1014    1023      -9 B6     \n 9  2013     3     1      549        600     -11     639     703     -24 US     \n10  2013     3     1      550        600     -10     747     801     -14 EV     \n# … with 28,824 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\n\n\n8.1.2 slice()\nLe verbe dplyr::slice() sélectionne des lignes du tableau selon leur position. On lui passe un chiffre ou un vecteur de chiffres.\nSi l’on souhaite sélectionner la 345e ligne du tableau airports :\n\nairports |> \n  slice(345)\n\n# A tibble: 1 × 8\n  faa   name                lat   lon   alt    tz dst   tzone            \n  <chr> <chr>             <dbl> <dbl> <dbl> <dbl> <chr> <chr>            \n1 CYF   Chefornak Airport  60.1 -164.    40    -9 A     America/Anchorage\n\n\nSi l’on veut sélectionner les 5 premières lignes :\n\nairports |> \n  slice(1:5)\n\n# A tibble: 5 × 8\n  faa   name                            lat   lon   alt    tz dst   tzone       \n  <chr> <chr>                         <dbl> <dbl> <dbl> <dbl> <chr> <chr>       \n1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A     America/New…\n2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A     America/Chi…\n3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A     America/Chi…\n4 06N   Randall Airport                41.4 -74.4   523    -5 A     America/New…\n5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A     America/New…\n\n\n\n8.1.3 arrange()\ndplyr::arrange() réordonne les lignes d’un tableau selon une ou plusieurs colonnes.\nAinsi, si l’on veut trier le tableau flights selon le retard au départ, dans l’ordre croissant :\n\nflights |> \n  arrange(dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013    12     7     2040       2123     -43      40    2352      48 B6     \n 2  2013     2     3     2022       2055     -33    2240    2338     -58 DL     \n 3  2013    11    10     1408       1440     -32    1549    1559     -10 EV     \n 4  2013     1    11     1900       1930     -30    2233    2243     -10 DL     \n 5  2013     1    29     1703       1730     -27    1947    1957     -10 F9     \n 6  2013     8     9      729        755     -26    1002     955       7 MQ     \n 7  2013    10    23     1907       1932     -25    2143    2143       0 EV     \n 8  2013     3    30     2030       2055     -25    2213    2250     -37 MQ     \n 9  2013     3     2     1431       1455     -24    1601    1631     -30 9E     \n10  2013     5     5      934        958     -24    1225    1309     -44 B6     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nOn peut trier selon plusieurs colonnes. Par exemple selon le mois, puis selon le retard au départ :\n\nflights |> \n  arrange(month, dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1    11     1900       1930     -30    2233    2243     -10 DL     \n 2  2013     1    29     1703       1730     -27    1947    1957     -10 F9     \n 3  2013     1    12     1354       1416     -22    1606    1650     -44 FL     \n 4  2013     1    21     2137       2159     -22    2232    2316     -44 DL     \n 5  2013     1    20      704        725     -21    1025    1035     -10 AS     \n 6  2013     1    12     2050       2110     -20    2310    2355     -45 B6     \n 7  2013     1    12     2134       2154     -20       4      50     -46 B6     \n 8  2013     1    14     2050       2110     -20    2329    2355     -26 B6     \n 9  2013     1     4     2140       2159     -19    2241    2316     -35 DL     \n10  2013     1    11     1947       2005     -18    2209    2230     -21 9E     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nSi l’on veut trier selon une colonne par ordre décroissant, on lui applique la fonction dplyr::desc() :\n\nflights |> \n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     9      641        900    1301    1242    1530    1272 HA     \n 2  2013     6    15     1432       1935    1137    1607    2120    1127 MQ     \n 3  2013     1    10     1121       1635    1126    1239    1810    1109 MQ     \n 4  2013     9    20     1139       1845    1014    1457    2210    1007 AA     \n 5  2013     7    22      845       1600    1005    1044    1815     989 MQ     \n 6  2013     4    10     1100       1900     960    1342    2211     931 DL     \n 7  2013     3    17     2321        810     911     135    1020     915 DL     \n 8  2013     6    27      959       1900     899    1236    2226     850 DL     \n 9  2013     7    22     2257        759     898     121    1026     895 DL     \n10  2013    12     5      756       1700     896    1058    2020     878 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nCombiné avec dplyr::slice(), dplyr::arrange() permet par exemple de sélectionner les trois vols ayant eu le plus de retard :\n\nflights |> \n  arrange(desc(dep_delay)) |> \n  slice(1:3)\n\n# A tibble: 3 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     1     9      641         900    1301    1242    1530    1272 HA     \n2  2013     6    15     1432        1935    1137    1607    2120    1127 MQ     \n3  2013     1    10     1121        1635    1126    1239    1810    1109 MQ     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\n8.1.4 slice_sample()\ndplyr::slice_sample() permet de sélectionner aléatoirement un nombre de lignes ou une fraction des lignes d’un tableau. Ainsi si l’on veut choisir 5 lignes au hasard dans le tableau airports :\n\nairports |> \n  slice_sample(n = 5)\n\n# A tibble: 5 × 8\n  faa   name                           lat   lon   alt    tz dst   tzone        \n  <chr> <chr>                        <dbl> <dbl> <dbl> <dbl> <chr> <chr>        \n1 DBQ   Dubuque Rgnl                  42.4 -90.7  1076    -6 A     America/Chic…\n2 HBR   Hobart Muni                   35.0 -99.1  1564    -6 A     America/Chic…\n3 AIK   Municipal Airport             33.6 -81.7   529    -5 A     America/New_…\n4 TVI   Thomasville Regional Airport  30.9 -83.9   264    -5 A     America/New_…\n5 ACT   Waco Rgnl                     31.6 -97.2   516    -6 A     America/Chic…\n\n\nSi l’on veut tirer au hasard 10% des lignes de flights :\n\nflights |> \n  slice_sample(prop = .1)\n\n# A tibble: 33,677 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     7    12     1312       1200      72    1424    1318      66 EV     \n 2  2013    12     7     1549       1555      -6    1735    1747     -12 9E     \n 3  2013     3     4      714        720      -6     837     848     -11 FL     \n 4  2013     1    22     2237       2245      -8    2348    2357      -9 B6     \n 5  2013     5    25     1729       1729       0    2036    2110     -34 VX     \n 6  2013    10    16     1734       1735      -1    2026    2055     -29 AA     \n 7  2013     8    10     2151       2119      32    2307    2259       8 UA     \n 8  2013     8     7      811        810       1    1124    1020      64 FL     \n 9  2013    11    22      803        750      13     942     912      30 EV     \n10  2013     8    22     1531       1455      36    1755    1645      70 MQ     \n# … with 33,667 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nCes fonctions sont utiles notamment pour faire de l’“échantillonnage” en tirant au hasard un certain nombre d’observations du tableau.\n\n8.1.5 distinct()\ndplyr::distinct() filtre les lignes du tableau pour ne conserver que les lignes distinctes, en supprimant toutes les lignes en double.\n\nflights |>\n  select(day, month) |>\n  distinct()\n\n# A tibble: 365 × 2\n     day month\n   <int> <int>\n 1     1     1\n 2     2     1\n 3     3     1\n 4     4     1\n 5     5     1\n 6     6     1\n 7     7     1\n 8     8     1\n 9     9     1\n10    10     1\n# … with 355 more rows\n\n\nOn peut lui spécifier une liste de variables : dans ce cas, pour toutes les observations ayant des valeurs identiques pour les variables en question, dplyr::distinct() ne conservera que la première d’entre elles.\n\nflights |>\n  distinct(month, day)\n\n# A tibble: 365 × 2\n   month   day\n   <int> <int>\n 1     1     1\n 2     1     2\n 3     1     3\n 4     1     4\n 5     1     5\n 6     1     6\n 7     1     7\n 8     1     8\n 9     1     9\n10     1    10\n# … with 355 more rows\n\n\nL’option .keep_all permet, dans l’opération précédente, de conserver l’ensemble des colonnes du tableau :\n\nflights |>\n  distinct(month, day, .keep_all = TRUE) \n\n# A tibble: 365 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     2       42       2359      43     518     442      36 B6     \n 3  2013     1     3       32       2359      33     504     442      22 B6     \n 4  2013     1     4       25       2359      26     505     442      23 B6     \n 5  2013     1     5       14       2359      15     503     445      18 B6     \n 6  2013     1     6       16       2359      17     451     442       9 B6     \n 7  2013     1     7       49       2359      50     531     444      47 B6     \n 8  2013     1     8      454        500      -6     625     648     -23 US     \n 9  2013     1     9        2       2359       3     432     444     -12 B6     \n10  2013     1    10        3       2359       4     426     437     -11 B6     \n# … with 355 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay"
  },
  {
    "objectID": "manipulation/dplyr.html#opérations-sur-les-colonnes",
    "href": "manipulation/dplyr.html#opérations-sur-les-colonnes",
    "title": "8  dplyr",
    "section": "\n8.2 Opérations sur les colonnes",
    "text": "8.2 Opérations sur les colonnes\n\n8.2.1 select()\ndplyr::select() permet de sélectionner des colonnes d’un tableau de données. Ainsi, si l’on veut extraire les colonnes lat et lon du tableau airports :\n\nairports |> \n  select(lat, lon)\n\n# A tibble: 1,458 × 2\n     lat    lon\n   <dbl>  <dbl>\n 1  41.1  -80.6\n 2  32.5  -85.7\n 3  42.0  -88.1\n 4  41.4  -74.4\n 5  31.1  -81.4\n 6  36.4  -82.2\n 7  41.5  -84.5\n 8  42.9  -76.8\n 9  39.8  -76.6\n10  48.1 -123. \n# … with 1,448 more rows\n\n\nSi on fait précéder le nom d’un -, la colonne est éliminée plutôt que sélectionnée :\n\nairports |> \n  select(-lat, -lon)\n\n# A tibble: 1,458 × 6\n   faa   name                             alt    tz dst   tzone              \n   <chr> <chr>                          <dbl> <dbl> <chr> <chr>              \n 1 04G   Lansdowne Airport               1044    -5 A     America/New_York   \n 2 06A   Moton Field Municipal Airport    264    -6 A     America/Chicago    \n 3 06C   Schaumburg Regional              801    -6 A     America/Chicago    \n 4 06N   Randall Airport                  523    -5 A     America/New_York   \n 5 09J   Jekyll Island Airport             11    -5 A     America/New_York   \n 6 0A9   Elizabethton Municipal Airport  1593    -5 A     America/New_York   \n 7 0G6   Williams County Airport          730    -5 A     America/New_York   \n 8 0G7   Finger Lakes Regional Airport    492    -5 A     America/New_York   \n 9 0P2   Shoestring Aviation Airfield    1000    -5 U     America/New_York   \n10 0S9   Jefferson County Intl            108    -8 A     America/Los_Angeles\n# … with 1,448 more rows\n\n\ndplyr::select() comprend toute une série de fonctions facilitant la sélection de multiples colonnes. Par exemple, dplyr::starts_with(), dplyr::ends_width(), dplyr::contains() ou dplyr::matches() permettent d’exprimer des conditions sur les noms de variables :\n\nflights |> \n  select(starts_with(\"dep_\"))\n\n# A tibble: 336,776 × 2\n   dep_time dep_delay\n      <int>     <dbl>\n 1      517         2\n 2      533         4\n 3      542         2\n 4      544        -1\n 5      554        -6\n 6      554        -4\n 7      555        -5\n 8      557        -3\n 9      557        -3\n10      558        -2\n# … with 336,766 more rows\n\n\nLa syntaxe colonne1:colonne2 permet de sélectionner toutes les colonnes situées entre colonne1 et colonne2 incluses3 :3 À noter que cette opération est un peu plus “fragile” que les autres, car si l’ordre des colonnes change elle peut renvoyer un résultat différent.\n\nflights |> \n  select(year:day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   <int> <int> <int>\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# … with 336,766 more rows\n\n\ndplyr::all_of() et dplyr::any_of() permettent de fournir une liste de variables à extraire sous forme de vecteur textuel. Alors que dplyr::all_of() renverra une erreur si une variable n’est pas trouvée dans le tableau de départ, dplyr::any_of() sera moins stricte.\n\nflights |> \n  select(all_of(c(\"year\", \"month\", \"day\")))\n\n# A tibble: 336,776 × 3\n    year month   day\n   <int> <int> <int>\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# … with 336,766 more rows\n\n\n\nflights |> \n  select(all_of(c(\"century\", \"year\", \"month\", \"day\")))\n\nError in `select()`:\n! Can't subset columns that don't exist.\n✖ Column `century` doesn't exist.\n\n\nErreur : Can't subset columns that don't exist. \nx Column `century` doesn't exist.\n\nflights |> \n  select(any_of(c(\"century\", \"year\", \"month\", \"day\")))\n\n# A tibble: 336,776 × 3\n    year month   day\n   <int> <int> <int>\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# … with 336,766 more rows\n\n\ndplyr::where() permets de sélectionner des variables à partir d’une fonction qui renvoie une valeur logique. Par exemple, pour sélectionner seulement les variables textuelles :\n\nflights |> \n  select(where(is.character))\n\n# A tibble: 336,776 × 4\n   carrier tailnum origin dest \n   <chr>   <chr>   <chr>  <chr>\n 1 UA      N14228  EWR    IAH  \n 2 UA      N24211  LGA    IAH  \n 3 AA      N619AA  JFK    MIA  \n 4 B6      N804JB  JFK    BQN  \n 5 DL      N668DN  LGA    ATL  \n 6 UA      N39463  EWR    ORD  \n 7 B6      N516JB  EWR    FLL  \n 8 EV      N829AS  LGA    IAD  \n 9 B6      N593JB  JFK    MCO  \n10 AA      N3ALAA  LGA    ORD  \n# … with 336,766 more rows\n\n\ndplyr::select() peut être utilisée pour réordonner les colonnes d’une table en utilisant la fonction dplyr::everything(), qui sélectionne l’ensemble des colonnes non encore sélectionnées. Ainsi, si l’on souhaite faire passer la colonne name en première position de la table airports, on peut faire :\n\nairports |> \n  select(name, everything())\n\n# A tibble: 1,458 × 8\n   name                           faa     lat    lon   alt    tz dst   tzone    \n   <chr>                          <chr> <dbl>  <dbl> <dbl> <dbl> <chr> <chr>    \n 1 Lansdowne Airport              04G    41.1  -80.6  1044    -5 A     America/…\n 2 Moton Field Municipal Airport  06A    32.5  -85.7   264    -6 A     America/…\n 3 Schaumburg Regional            06C    42.0  -88.1   801    -6 A     America/…\n 4 Randall Airport                06N    41.4  -74.4   523    -5 A     America/…\n 5 Jekyll Island Airport          09J    31.1  -81.4    11    -5 A     America/…\n 6 Elizabethton Municipal Airport 0A9    36.4  -82.2  1593    -5 A     America/…\n 7 Williams County Airport        0G6    41.5  -84.5   730    -5 A     America/…\n 8 Finger Lakes Regional Airport  0G7    42.9  -76.8   492    -5 A     America/…\n 9 Shoestring Aviation Airfield   0P2    39.8  -76.6  1000    -5 U     America/…\n10 Jefferson County Intl          0S9    48.1 -123.    108    -8 A     America/…\n# … with 1,448 more rows\n\n\n\n8.2.2 relocate()\nPour réordonner des colonnes, on pourra aussi avoir recours à dplyr::relocate() en indiquant les premières variables. Il n’est pas nécessaire d’ajouter everything() car avec dplyr::relocate() toutes les variables sont conservées.\n\nairports |> \n  relocate(lon, lat, name)\n\n# A tibble: 1,458 × 8\n      lon   lat name                           faa     alt    tz dst   tzone    \n    <dbl> <dbl> <chr>                          <chr> <dbl> <dbl> <chr> <chr>    \n 1  -80.6  41.1 Lansdowne Airport              04G    1044    -5 A     America/…\n 2  -85.7  32.5 Moton Field Municipal Airport  06A     264    -6 A     America/…\n 3  -88.1  42.0 Schaumburg Regional            06C     801    -6 A     America/…\n 4  -74.4  41.4 Randall Airport                06N     523    -5 A     America/…\n 5  -81.4  31.1 Jekyll Island Airport          09J      11    -5 A     America/…\n 6  -82.2  36.4 Elizabethton Municipal Airport 0A9    1593    -5 A     America/…\n 7  -84.5  41.5 Williams County Airport        0G6     730    -5 A     America/…\n 8  -76.8  42.9 Finger Lakes Regional Airport  0G7     492    -5 A     America/…\n 9  -76.6  39.8 Shoestring Aviation Airfield   0P2    1000    -5 U     America/…\n10 -123.   48.1 Jefferson County Intl          0S9     108    -8 A     America/…\n# … with 1,448 more rows\n\n\n\n8.2.3 rename()\nUne variante de dplyr::select() est dplyr::rename()4, qui permet de renommer facilement des colonnes. On l’utilise en lui passant des paramètres de la forme nouveau_nom = ancien_nom. Ainsi, si on veut renommer les colonnes lon et lat de airports en longitude et latitude :4 Il est également possible de renommer des colonnes directement avec select(), avec la même syntaxe que pour rename().\n\nairports |> \n  rename(longitude = lon, latitude = lat)\n\n# A tibble: 1,458 × 8\n   faa   name                           latitude longi…¹   alt    tz dst   tzone\n   <chr> <chr>                             <dbl>   <dbl> <dbl> <dbl> <chr> <chr>\n 1 04G   Lansdowne Airport                  41.1   -80.6  1044    -5 A     Amer…\n 2 06A   Moton Field Municipal Airport      32.5   -85.7   264    -6 A     Amer…\n 3 06C   Schaumburg Regional                42.0   -88.1   801    -6 A     Amer…\n 4 06N   Randall Airport                    41.4   -74.4   523    -5 A     Amer…\n 5 09J   Jekyll Island Airport              31.1   -81.4    11    -5 A     Amer…\n 6 0A9   Elizabethton Municipal Airport     36.4   -82.2  1593    -5 A     Amer…\n 7 0G6   Williams County Airport            41.5   -84.5   730    -5 A     Amer…\n 8 0G7   Finger Lakes Regional Airport      42.9   -76.8   492    -5 A     Amer…\n 9 0P2   Shoestring Aviation Airfield       39.8   -76.6  1000    -5 U     Amer…\n10 0S9   Jefferson County Intl              48.1  -123.    108    -8 A     Amer…\n# … with 1,448 more rows, and abbreviated variable name ¹​longitude\n\n\nSi les noms de colonnes comportent des espaces ou des caractères spéciaux, on peut les entourer de guillemets (\") ou de quotes inverses (`) :\n\nflights |> \n  rename(\n    \"retard départ\" = dep_delay,\n    \"retard arrivée\" = arr_delay\n  ) |> \n  select(`retard départ`, `retard arrivée`)\n\n# A tibble: 336,776 × 2\n   `retard départ` `retard arrivée`\n             <dbl>            <dbl>\n 1               2               11\n 2               4               20\n 3               2               33\n 4              -1              -18\n 5              -6              -25\n 6              -4               12\n 7              -5               19\n 8              -3              -14\n 9              -3               -8\n10              -2                8\n# … with 336,766 more rows\n\n\n\n8.2.4 rename_with()\nLa fonction dplyr::rename_with() permets de renommer plusieurs colonnes d’un coup en transmettant une fonction, par exemple toupper() qui passe tous les caractères en majuscule.\n\nairports |> \n  rename_with(toupper)\n\n# A tibble: 1,458 × 8\n   FAA   NAME                             LAT    LON   ALT    TZ DST   TZONE    \n   <chr> <chr>                          <dbl>  <dbl> <dbl> <dbl> <chr> <chr>    \n 1 04G   Lansdowne Airport               41.1  -80.6  1044    -5 A     America/…\n 2 06A   Moton Field Municipal Airport   32.5  -85.7   264    -6 A     America/…\n 3 06C   Schaumburg Regional             42.0  -88.1   801    -6 A     America/…\n 4 06N   Randall Airport                 41.4  -74.4   523    -5 A     America/…\n 5 09J   Jekyll Island Airport           31.1  -81.4    11    -5 A     America/…\n 6 0A9   Elizabethton Municipal Airport  36.4  -82.2  1593    -5 A     America/…\n 7 0G6   Williams County Airport         41.5  -84.5   730    -5 A     America/…\n 8 0G7   Finger Lakes Regional Airport   42.9  -76.8   492    -5 A     America/…\n 9 0P2   Shoestring Aviation Airfield    39.8  -76.6  1000    -5 U     America/…\n10 0S9   Jefferson County Intl           48.1 -123.    108    -8 A     America/…\n# … with 1,448 more rows\n\n\nOn pourra notamment utiliser les fonctions du package snakecase et, en particulier, snakecase::to_snake_case() que je recommande pour nommer de manière consistante les variables5.5 Le snake case est une convention typographique en informatique consistant à écrire des ensembles de mots, généralement, en minuscules en les séparant par des tirets bas.\n\n8.2.5 pull()\nLa fonction dplyr::pull() permet d’accéder au contenu d’une variable. C’est un équivalent aux opérateurs $ ou [[]]. On peut lui passer un nom de variable ou bien sa position.\n\nairports |> \n  pull(alt) |> \n  mean()\n\n[1] 1001.416\n\n\n\n\n\n\n\n\nNote\n\n\n\ndplyr::pull() ressemble à la fonction purrr::chuck() que nous avons déjà abordée (cf. Section 7.4). Cependant, dplyr::pull() ne fonctionne que sur des tableaux de données tandis que purrr::chuck() est plus générique et peut s’appliquer à tous types de listes.\n\n\n\n8.2.6 mutate()\ndplyr::mutate() permet de créer de nouvelles colonnes dans le tableau de données, en général à partir de variables existantes.\nPar exemple, la table airports contient l’altitude de l’aéroport en pieds. Si l’on veut créer une nouvelle variable alt_m avec l’altitude en mètres, on peut faire :\n\nairports <- \n  airports |> \n  mutate(alt_m = alt / 3.2808)\n\nOn peut créer plusieurs nouvelles colonnes en une seule fois, et les expressions successives peuvent prendre en compte les résultats des calculs précédents. L’exemple suivant convertit d’abord la distance en kilomètres dans une variable distance_km, puis utilise cette nouvelle colonne pour calculer la vitesse en km/h.\n\nflights <- \n  flights |> \n  mutate(\n    distance_km = distance / 0.62137,\n    vitesse = distance_km / air_time * 60\n)"
  },
  {
    "objectID": "manipulation/dplyr.html#opérations-groupées",
    "href": "manipulation/dplyr.html#opérations-groupées",
    "title": "8  dplyr",
    "section": "\n8.3 Opérations groupées",
    "text": "8.3 Opérations groupées\n\n8.3.1 group_by()\nUn élément très important de dplyr est la fonction dplyr::group_by(). Elle permet de définir des groupes de lignes à partir des valeurs d’une ou plusieurs colonnes. Par exemple, on peut grouper les vols selon leur mois :\n\nflights |> \n  group_by(month)\n\n# A tibble: 336,776 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     1      533        529       4     850     830      20 UA     \n 3  2013     1     1      542        540       2     923     850      33 AA     \n 4  2013     1     1      544        545      -1    1004    1022     -18 B6     \n 5  2013     1     1      554        600      -6     812     837     -25 DL     \n 6  2013     1     1      554        558      -4     740     728      12 UA     \n 7  2013     1     1      555        600      -5     913     854      19 B6     \n 8  2013     1     1      557        600      -3     709     723     -14 EV     \n 9  2013     1     1      557        600      -3     838     846      -8 B6     \n10  2013     1     1      558        600      -2     753     745       8 AA     \n# … with 336,766 more rows, 11 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, distance_km <dbl>, vitesse <dbl>, and\n#   abbreviated variable names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#   ⁴​sched_arr_time, ⁵​arr_delay\n\n\nPar défaut ceci ne fait rien de visible, à part l’apparition d’une mention Groups dans l’affichage du résultat. Mais à partir du moment où des groupes ont été définis, les verbes comme dplyr::slice() ou dplyr::mutate() vont en tenir compte lors de leurs opérations.\nPar exemple, si on applique dplyr::slice() à un tableau préalablement groupé, il va sélectionner les lignes aux positions indiquées pour chaque groupe. Ainsi la commande suivante affiche le premier vol de chaque mois, selon leur ordre d’apparition dans le tableau :\n\nflights |> \n  group_by(month) |> \n  slice(1)\n\n# A tibble: 12 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     2     1      456        500      -4     652     648       4 US     \n 3  2013     3     1        4       2159     125     318      56     142 B6     \n 4  2013     4     1      454        500      -6     636     640      -4 US     \n 5  2013     5     1        9       1655     434     308    2020     408 VX     \n 6  2013     6     1        2       2359       3     341     350      -9 B6     \n 7  2013     7     1        1       2029     212     236    2359     157 B6     \n 8  2013     8     1       12       2130     162     257      14     163 B6     \n 9  2013     9     1        9       2359      10     343     340       3 B6     \n10  2013    10     1      447        500     -13     614     648     -34 US     \n11  2013    11     1        5       2359       6     352     345       7 B6     \n12  2013    12     1       13       2359      14     446     445       1 B6     \n# … with 11 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, distance_km <dbl>, vitesse <dbl>, and abbreviated\n#   variable names ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time,\n#   ⁵​arr_delay\n\n\nIdem pour dplyr::mutate() : les opérations appliquées lors du calcul des valeurs des nouvelles colonnes sont appliquée groupe de lignes par groupe de lignes. Dans l’exemple suivant, on ajoute une nouvelle colonne qui contient le retard moyen du mois correspondant :\n\nflights |> \n  group_by(month) |> \n  mutate(mean_delay_month = mean(dep_delay, na.rm = TRUE))\n\n# A tibble: 336,776 × 22\n# Groups:   month [12]\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     1      533        529       4     850     830      20 UA     \n 3  2013     1     1      542        540       2     923     850      33 AA     \n 4  2013     1     1      544        545      -1    1004    1022     -18 B6     \n 5  2013     1     1      554        600      -6     812     837     -25 DL     \n 6  2013     1     1      554        558      -4     740     728      12 UA     \n 7  2013     1     1      555        600      -5     913     854      19 B6     \n 8  2013     1     1      557        600      -3     709     723     -14 EV     \n 9  2013     1     1      557        600      -3     838     846      -8 B6     \n10  2013     1     1      558        600      -2     753     745       8 AA     \n# … with 336,766 more rows, 12 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, distance_km <dbl>, vitesse <dbl>,\n#   mean_delay_month <dbl>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nCeci peut permettre, par exemple, de déterminer si un retard donné est supérieur ou inférieur au retard moyen du mois en cours.\ndplyr::group_by() peut aussi être utile avec dplyr::filter(), par exemple pour sélectionner les vols avec le retard au départ le plus important pour chaque mois :\n\nflights |> \n  group_by(month) |> \n  filter(dep_delay == max(dep_delay, na.rm = TRUE))\n\n# A tibble: 12 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     9      641        900    1301    1242    1530    1272 HA     \n 2  2013    10    14     2042        900     702    2255    1127     688 DL     \n 3  2013    11     3      603       1645     798     829    1913     796 DL     \n 4  2013    12     5      756       1700     896    1058    2020     878 AA     \n 5  2013     2    10     2243        830     853     100    1106     834 F9     \n 6  2013     3    17     2321        810     911     135    1020     915 DL     \n 7  2013     4    10     1100       1900     960    1342    2211     931 DL     \n 8  2013     5     3     1133       2055     878    1250    2215     875 MQ     \n 9  2013     6    15     1432       1935    1137    1607    2120    1127 MQ     \n10  2013     7    22      845       1600    1005    1044    1815     989 MQ     \n11  2013     8     8     2334       1454     520     120    1710     490 EV     \n12  2013     9    20     1139       1845    1014    1457    2210    1007 AA     \n# … with 11 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, distance_km <dbl>, vitesse <dbl>, and abbreviated\n#   variable names ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time,\n#   ⁵​arr_delay\n\n\n\nAttention : la clause dplyr::roup_by() marche pour les verbes déjà vus précédemment, sauf pour dplyr::arrange(), qui par défaut trie la table sans tenir compte des groupes. Pour obtenir un tri par groupe, il faut lui ajouter l’argument .by_group = TRUE.\n\nOn peut voir la différence en comparant les deux résultats suivants :\n\nflights |> \n  group_by(month) |> \n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     9      641        900    1301    1242    1530    1272 HA     \n 2  2013     6    15     1432       1935    1137    1607    2120    1127 MQ     \n 3  2013     1    10     1121       1635    1126    1239    1810    1109 MQ     \n 4  2013     9    20     1139       1845    1014    1457    2210    1007 AA     \n 5  2013     7    22      845       1600    1005    1044    1815     989 MQ     \n 6  2013     4    10     1100       1900     960    1342    2211     931 DL     \n 7  2013     3    17     2321        810     911     135    1020     915 DL     \n 8  2013     6    27      959       1900     899    1236    2226     850 DL     \n 9  2013     7    22     2257        759     898     121    1026     895 DL     \n10  2013    12     5      756       1700     896    1058    2020     878 AA     \n# … with 336,766 more rows, 11 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, distance_km <dbl>, vitesse <dbl>, and\n#   abbreviated variable names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#   ⁴​sched_arr_time, ⁵​arr_delay\n\nflights |> \n  group_by(month) |> \n  arrange(desc(dep_delay), .by_group = TRUE)\n\n# A tibble: 336,776 × 21\n# Groups:   month [12]\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     9      641        900    1301    1242    1530    1272 HA     \n 2  2013     1    10     1121       1635    1126    1239    1810    1109 MQ     \n 3  2013     1     1      848       1835     853    1001    1950     851 MQ     \n 4  2013     1    13     1809        810     599    2054    1042     612 DL     \n 5  2013     1    16     1622        800     502    1911    1054     497 B6     \n 6  2013     1    23     1551        753     478    1812    1006     486 DL     \n 7  2013     1    10     1525        900     385    1713    1039     394 UA     \n 8  2013     1     1     2343       1724     379     314    1938     456 EV     \n 9  2013     1     2     2131       1512     379    2340    1741     359 UA     \n10  2013     1     7     2021       1415     366    2332    1724     368 B6     \n# … with 336,766 more rows, 11 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, distance_km <dbl>, vitesse <dbl>, and\n#   abbreviated variable names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#   ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\n8.3.2 summarise()\ndplyr::summarise() permet d’agréger les lignes du tableau en effectuant une opération résumée sur une ou plusieurs colonnes. Il s’agit de toutes les fonctions qui prennent en entrée un ensemble de valeurs et renvoie une valeur unique, comme la moyenne (mean()). Par exemple, si l’on souhaite connaître les retards moyens au départ et à l’arrivée pour l’ensemble des vols du tableau flights :\n\nflights |> \n  summarise(\n    retard_dep = mean(dep_delay, na.rm=TRUE),\n    retard_arr = mean(arr_delay, na.rm=TRUE)\n  )\n\n# A tibble: 1 × 2\n  retard_dep retard_arr\n       <dbl>      <dbl>\n1       12.6       6.90\n\n\nCette fonction est en général utilisée avec dplyr::group_by(), puisqu’elle permet du coup d’agréger et de résumer les lignes du tableau groupe par groupe. Si l’on souhaite calculer le délai maximum, le délai minimum et le délai moyen au départ pour chaque mois, on pourra faire :\n\nflights |>\n  group_by(month) |>\n  summarise(\n    max_delay = max(dep_delay, na.rm=TRUE),\n    min_delay = min(dep_delay, na.rm=TRUE),\n    mean_delay = mean(dep_delay, na.rm=TRUE)\n  )\n\n# A tibble: 12 × 4\n   month max_delay min_delay mean_delay\n   <int>     <dbl>     <dbl>      <dbl>\n 1     1      1301       -30      10.0 \n 2     2       853       -33      10.8 \n 3     3       911       -25      13.2 \n 4     4       960       -21      13.9 \n 5     5       878       -24      13.0 \n 6     6      1137       -21      20.8 \n 7     7      1005       -22      21.7 \n 8     8       520       -26      12.6 \n 9     9      1014       -24       6.72\n10    10       702       -25       6.24\n11    11       798       -32       5.44\n12    12       896       -43      16.6 \n\n\ndplyr::summarise() dispose d’une fonction spéciale dplyr::n(), qui retourne le nombre de lignes du groupe. Ainsi si l’on veut le nombre de vols par destination, on peut utiliser :\n\nflights |>\n  group_by(dest) |>\n  summarise(n = n())\n\n# A tibble: 105 × 2\n   dest      n\n   <chr> <int>\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# … with 95 more rows\n\n\ndplyr::n() peut aussi être utilisée avec dplyr::filter() et dplyr::mutate().\n\n8.3.3 count()\nÀ noter que quand l’on veut compter le nombre de lignes par groupe, on peut utiliser directement la fonction dplyr::count(). Ainsi le code suivant est identique au précédent :\n\nflights |>\n  count(dest)\n\n# A tibble: 105 × 2\n   dest      n\n   <chr> <int>\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# … with 95 more rows\n\n\n\n8.3.4 Grouper selon plusieurs variables\nOn peut grouper selon plusieurs variables à la fois, il suffit de les indiquer dans la clause du dplyr::group_by() :\n\nflights |>\n  group_by(month, dest) |>\n  summarise(nb = n()) |>\n  arrange(desc(nb))\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1,113 × 3\n# Groups:   month [12]\n   month dest     nb\n   <int> <chr> <int>\n 1     8 ORD    1604\n 2    10 ORD    1604\n 3     5 ORD    1582\n 4     9 ORD    1582\n 5     7 ORD    1573\n 6     6 ORD    1547\n 7     7 ATL    1511\n 8     8 ATL    1507\n 9     8 LAX    1505\n10     7 LAX    1500\n# … with 1,103 more rows\n\n\nOn peut également compter selon plusieurs variables :\n\nflights |> \n  count(origin, dest) |> \n  arrange(desc(n))\n\n# A tibble: 224 × 3\n   origin dest      n\n   <chr>  <chr> <int>\n 1 JFK    LAX   11262\n 2 LGA    ATL   10263\n 3 LGA    ORD    8857\n 4 JFK    SFO    8204\n 5 LGA    CLT    6168\n 6 EWR    ORD    6100\n 7 JFK    BOS    5898\n 8 LGA    MIA    5781\n 9 JFK    MCO    5464\n10 EWR    BOS    5327\n# … with 214 more rows\n\n\nOn peut utiliser plusieurs opérations de groupage dans le même pipeline. Ainsi, si l’on souhaite déterminer le couple origine/destination ayant le plus grand nombre de vols selon le mois de l’année, on devra procéder en deux étapes :\n\nd’abord grouper selon mois, origine et destination pour calculer le nombre de vols\npuis grouper uniquement selon le mois pour sélectionner la ligne avec la valeur maximale.\n\nAu final, on obtient le code suivant :\n\nflights |>\n  group_by(month, origin, dest) |>\n  summarise(nb = n()) |>\n  group_by(month) |>\n  filter(nb == max(nb))\n\n`summarise()` has grouped output by 'month', 'origin'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 12 × 4\n# Groups:   month [12]\n   month origin dest     nb\n   <int> <chr>  <chr> <int>\n 1     1 JFK    LAX     937\n 2     2 JFK    LAX     834\n 3     3 JFK    LAX     960\n 4     4 JFK    LAX     935\n 5     5 JFK    LAX     960\n 6     6 JFK    LAX     928\n 7     7 JFK    LAX     985\n 8     8 JFK    LAX     979\n 9     9 JFK    LAX     925\n10    10 JFK    LAX     965\n11    11 JFK    LAX     907\n12    12 JFK    LAX     947\n\n\nLorsqu’on effectue un dplyr::group_by() suivi d’un dplyr::summarise(), le tableau résultat est automatiquement dégroupé de la dernière variable de regroupement. Ainsi le tableau généré par le code suivant est groupé par month et origin6 :6 Comme expliqué dans le message affiché dans la console, cela peut être contrôlé avec l’argument .groups de dplyr::summarise(), dont les options sont décrites dans l’aide de la fonction.\n\nflights |>\n  group_by(month, origin, dest) |>\n  summarise(nb = n())\n\n`summarise()` has grouped output by 'month', 'origin'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 2,313 × 4\n# Groups:   month, origin [36]\n   month origin dest     nb\n   <int> <chr>  <chr> <int>\n 1     1 EWR    ALB      64\n 2     1 EWR    ATL     362\n 3     1 EWR    AUS      51\n 4     1 EWR    AVL       2\n 5     1 EWR    BDL      37\n 6     1 EWR    BNA     111\n 7     1 EWR    BOS     430\n 8     1 EWR    BQN      31\n 9     1 EWR    BTV     100\n10     1 EWR    BUF     119\n# … with 2,303 more rows\n\n\nCela peut permettre d’enchaîner les opérations groupées. Dans l’exemple suivant, on calcule le pourcentage des trajets pour chaque destination par rapport à tous les trajets du mois :\n\nflights |>\n  group_by(month, dest) |>\n  summarise(nb = n()) |> \n  mutate(pourcentage = nb / sum(nb) * 100)\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1,113 × 4\n# Groups:   month [12]\n   month dest     nb pourcentage\n   <int> <chr> <int>       <dbl>\n 1     1 ALB      64     0.237  \n 2     1 ATL    1396     5.17   \n 3     1 AUS     169     0.626  \n 4     1 AVL       2     0.00741\n 5     1 BDL      37     0.137  \n 6     1 BHM      25     0.0926 \n 7     1 BNA     399     1.48   \n 8     1 BOS    1245     4.61   \n 9     1 BQN      93     0.344  \n10     1 BTV     223     0.826  \n# … with 1,103 more rows\n\n\nOn peut à tout moment dégrouper un tableau à l’aide de dplyr::ungroup(). Ce serait par exemple nécessaire, dans l’exemple précédent, si on voulait calculer le pourcentage sur le nombre total de vols plutôt que sur le nombre de vols par mois :\n\nflights |>\n  group_by(month, dest) |>\n  summarise(nb = n()) |> \n  ungroup() |> \n  mutate(pourcentage = nb / sum(nb) * 100)\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1,113 × 4\n   month dest     nb pourcentage\n   <int> <chr> <int>       <dbl>\n 1     1 ALB      64    0.0190  \n 2     1 ATL    1396    0.415   \n 3     1 AUS     169    0.0502  \n 4     1 AVL       2    0.000594\n 5     1 BDL      37    0.0110  \n 6     1 BHM      25    0.00742 \n 7     1 BNA     399    0.118   \n 8     1 BOS    1245    0.370   \n 9     1 BQN      93    0.0276  \n10     1 BTV     223    0.0662  \n# … with 1,103 more rows\n\n\nÀ noter que dplyr::count(), par contre, renvoit un tableau non groupé :\n\nflights |> \n  count(month, dest)\n\n# A tibble: 1,113 × 3\n   month dest      n\n   <int> <chr> <int>\n 1     1 ALB      64\n 2     1 ATL    1396\n 3     1 AUS     169\n 4     1 AVL       2\n 5     1 BDL      37\n 6     1 BHM      25\n 7     1 BNA     399\n 8     1 BOS    1245\n 9     1 BQN      93\n10     1 BTV     223\n# … with 1,103 more rows"
  },
  {
    "objectID": "manipulation/dplyr.html#cheatsheet",
    "href": "manipulation/dplyr.html#cheatsheet",
    "title": "8  dplyr",
    "section": "\n8.4 Cheatsheet",
    "text": "8.4 Cheatsheet"
  },
  {
    "objectID": "manipulation/dplyr.html#webin-r",
    "href": "manipulation/dplyr.html#webin-r",
    "title": "8  dplyr",
    "section": "\n8.5 webin-R",
    "text": "8.5 webin-R\nOn pourra également se référer au webin-R #04 (manipuler les données avec dplyr) sur YouTube."
  },
  {
    "objectID": "manipulation/facteurs.html#création-dun-facteur",
    "href": "manipulation/facteurs.html#création-dun-facteur",
    "title": "9  Facteurs et forcats",
    "section": "\n9.1 Création d’un facteur",
    "text": "9.1 Création d’un facteur\nLe plus simple pour créer un facteur est de partir d’un vecteur textuel et d’utiliser la fonction factor().\n\nx <- c(\"nord\", \"sud\", \"sud\", \"est\", \"est\", \"est\")\nx |> \n  factor()\n\n[1] nord sud  sud  est  est  est \nLevels: est nord sud\n\n\nPar défaut, les niveaux du facteur obtenu correspondent aux valeurs uniques du fecteur textuel, triés par ordre alphabétique. Si l’on veut contrôler l’ordre des niveaux, et éventuellement indiquer un niveau absent des données, on utilisera l’argument levels de factor().\n\nx |> \n  factor(levels = c(\"nord\", \"est\", \"sud\", \"ouest\"))\n\n[1] nord sud  sud  est  est  est \nLevels: nord est sud ouest\n\n\nSi une valeur observée dans les données n’est pas indiqué dans levels, elle sera siliencieusement convertie en valeur manquante (NA).\n\nx |> \n  factor(levels = c(\"nord\", \"sud\"))\n\n[1] nord sud  sud  <NA> <NA> <NA>\nLevels: nord sud\n\n\nSi l’on veut être averti par un warning dans ce genre de situation, on pourra avoir plutôt recours à la fonction readr::parse_factor() du package readr, qui, le cas échéant, renverra un tableau avec les problèmes rencontrés.\n\nx |> \n  readr::parse_factor(levels = c(\"nord\", \"sud\"))\n\nWarning: 3 parsing failures.\nrow col           expected actual\n  4  -- value in level set    est\n  5  -- value in level set    est\n  6  -- value in level set    est\n\n\n[1] nord sud  sud  <NA> <NA> <NA>\nattr(,\"problems\")\n# A tibble: 3 × 4\n    row   col expected           actual\n  <int> <int> <chr>              <chr> \n1     4    NA value in level set est   \n2     5    NA value in level set est   \n3     6    NA value in level set est   \nLevels: nord sud\n\n\nUne fois un facteur créé, on peut accéder à la liste de ses étiquettes avec levels().\n\nf <- factor(x)\nlevels(f)\n\n[1] \"est\"  \"nord\" \"sud\" \n\n\nDans certaines situations (par exemple pour la réalisation d’une régression logistique ordinale), on peut avoir avoir besoin d’indiquer que les modalités du facteur sont ordonnées héarchiquement. Dans ce cas là, on aura simplement recours à ordered() pour créer/convertir notre facteur.\n\nc(\"supérieur\", \"primaire\", \"secondaire\", \"primaire\", \"supérieur\") |> \n  ordered(levels = c(\"primaire\", \"secondaire\", \"supérieur\"))\n\n[1] supérieur  primaire   secondaire primaire   supérieur \nLevels: primaire < secondaire < supérieur\n\n\nTechniquement, les valeurs d’un facteur sont stockés de manière interne à l’aide de nombres entiers, dont la valeur représente la position de l’étiquette correspondante dans l’attribut levels. Ainsi, un facteur à n modalités sera toujours codé avec les nombre entiers allant de 1 à n.\n\nclass(f)\n\n[1] \"factor\"\n\ntypeof(f)\n\n[1] \"integer\"\n\nas.integer(f)\n\n[1] 2 3 3 1 1 1\n\nas.character(f)\n\n[1] \"nord\" \"sud\"  \"sud\"  \"est\"  \"est\"  \"est\""
  },
  {
    "objectID": "manipulation/facteurs.html#changer-lordre-des-modalités",
    "href": "manipulation/facteurs.html#changer-lordre-des-modalités",
    "title": "9  Facteurs et forcats",
    "section": "\n9.2 Changer l’ordre des modalités",
    "text": "9.2 Changer l’ordre des modalités\nLe pacakge forcats, chargé par défaut lorsque l’on exécute la commande library(tidyverse), fournie plusieurs fonctions pour manipuler des facteurs. Pour donner des exemples d’utilisation de ces différentes fonctions, nous allons utiliser le jeu de données hdv2003 du package questionr.\n\n\n\n\nlibrary(tidyverse)\ndata(\"hdv2003\", package = \"questionr\")\n\nConsidérons la variable qualif qui indique le niveau de qualification des enquêtés. On peut voir la liste des niveaux de ce facteur, et leur ordre, avec levels(), ou en effectuant un tri à plat avec la fonction questionr::freq().\n\nhdv2003$qualif |> \n  levels()\n\n[1] \"Ouvrier specialise\"       \"Ouvrier qualifie\"        \n[3] \"Technicien\"               \"Profession intermediaire\"\n[5] \"Cadre\"                    \"Employe\"                 \n[7] \"Autre\"                   \n\nhdv2003$qualif |> \n  questionr::freq()\n\n                           n    % val%\nOuvrier specialise       203 10.2 12.3\nOuvrier qualifie         292 14.6 17.7\nTechnicien                86  4.3  5.2\nProfession intermediaire 160  8.0  9.7\nCadre                    260 13.0 15.7\nEmploye                  594 29.7 35.9\nAutre                     58  2.9  3.5\nNA                       347 17.3   NA\n\n\nParfois, on a simplement besoin d’inverser l’ordre des facteurs, ce qui peut se faire facilement avec la fonction forcats::fct_rev(). Elle renvoie le facteur fourni en entrée en ayant inverser l’ordre des modalités (mais sans modifier l’ordre des valeurs dans le vecteur).\n\nhdv2003$qualif |> \n  fct_rev() |> \n  questionr::freq()\n\n                           n    % val%\nAutre                     58  2.9  3.5\nEmploye                  594 29.7 35.9\nCadre                    260 13.0 15.7\nProfession intermediaire 160  8.0  9.7\nTechnicien                86  4.3  5.2\nOuvrier qualifie         292 14.6 17.7\nOuvrier specialise       203 10.2 12.3\nNA                       347 17.3   NA\n\n\nPour plus de contrôle, on utilisera forcats::fct_relevel() où l’on indique l’ordre souhaité des modalités. On peut également seulement indiquer les premières modalités, les autres seront ajoutées à la fin sans changer leur ordre.\n\nhdv2003$qualif |> \n  fct_relevel(\"Cadre\", \"Autre\", \"Technicien\", \"Employe\") |> \n  questionr::freq()\n\n                           n    % val%\nCadre                    260 13.0 15.7\nAutre                     58  2.9  3.5\nTechnicien                86  4.3  5.2\nEmploye                  594 29.7 35.9\nOuvrier specialise       203 10.2 12.3\nOuvrier qualifie         292 14.6 17.7\nProfession intermediaire 160  8.0  9.7\nNA                       347 17.3   NA\n\n\nLa fonction forcats::fct_infreq() ordonne les modalités de celle la plus fréquente à celle la moins fréquente (nombre d’observations) :\n\nhdv2003$qualif |> \n  fct_infreq() |> \n  questionr::freq()\n\n                           n    % val%\nEmploye                  594 29.7 35.9\nOuvrier qualifie         292 14.6 17.7\nCadre                    260 13.0 15.7\nOuvrier specialise       203 10.2 12.3\nProfession intermediaire 160  8.0  9.7\nTechnicien                86  4.3  5.2\nAutre                     58  2.9  3.5\nNA                       347 17.3   NA\n\n\nPour inverser l’ordre, on combinera forcats::fct_infreq() avec forcats::fct_rev().\n\nhdv2003$qualif |> \n  fct_infreq() |> \n  fct_rev() |> \n  questionr::freq()\n\n                           n    % val%\nAutre                     58  2.9  3.5\nTechnicien                86  4.3  5.2\nProfession intermediaire 160  8.0  9.7\nOuvrier specialise       203 10.2 12.3\nCadre                    260 13.0 15.7\nOuvrier qualifie         292 14.6 17.7\nEmploye                  594 29.7 35.9\nNA                       347 17.3   NA\n\n\nDans certains cas, on souhaite créer un facteur dont les modalités sont triées selon leur ordre d’apparation dans le jeu de données. Pour cela, on aura recours à forcats::fct_inorder().\n\nv <- c(\"c\", \"a\", \"d\", \"b\", \"a\", \"c\")\nfactor(v)\n\n[1] c a d b a c\nLevels: a b c d\n\nfct_inorder(v)\n\n[1] c a d b a c\nLevels: c a d b\n\n\nLa fonction forcats::fct_reorder() permets de trier les modalités en fonction d’une autre variable. Par exemple, si je souhaite trier les modalités de la variable qualif en fonction de l’âge moyen (dans chaque modalité) :\n\nhdv2003$qualif_tri_age <-\n  hdv2003$qualif |> \n  fct_reorder(hdv2003$age, .fun = mean)\nhdv2003 |> \n  dplyr::group_by(qualif_tri_age) |> \n  dplyr::summarise(age_moyen = mean(age))\n\n# A tibble: 8 × 2\n  qualif_tri_age           age_moyen\n  <fct>                        <dbl>\n1 Technicien                    45.9\n2 Employe                       46.7\n3 Autre                         47.0\n4 Ouvrier specialise            48.9\n5 Profession intermediaire      49.1\n6 Cadre                         49.7\n7 Ouvrier qualifie              50.0\n8 <NA>                          47.9\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nquestionr propose une interface graphique afin de faciliter les opérations de réordonnancement manuel. Pour la lancer, sélectionner le menu Addins puis Levels ordering, ou exécuter la fonction questionr::iorder() en lui passant comme paramètre le facteur à réordonner.\n\n\n\n\nUne démonstration en vidéo de cet add-in est disponible dans le webin-R #05 (recoder des variables) sur [YouTube](https://youtu.be/CokvTbtWdwc?t=3934)."
  },
  {
    "objectID": "manipulation/facteurs.html#sec-modifier-modalites",
    "href": "manipulation/facteurs.html#sec-modifier-modalites",
    "title": "9  Facteurs et forcats",
    "section": "\n9.3 Modifier les modalités",
    "text": "9.3 Modifier les modalités\nPour modifier le nom des modalités, on pourra avoir recours à forcats::fct_recode() avec une syntaxe de la forme \"nouveau nom\" = \"ancien nom\".\n\nhdv2003$sexe |> \n  questionr::freq()\n\n         n  % val%\nHomme  899 45   45\nFemme 1101 55   55\n\nhdv2003$sexe <- \n  hdv2003$sexe |> \n  fct_recode(f = \"Femme\", m = \"Homme\")\nhdv2003$sexe |> \n  questionr::freq()\n\n     n  % val%\nm  899 45   45\nf 1101 55   55\n\n\nOn peut également fusionner des modalités ensemble en leur attribuant le même nom.\n\nhdv2003$nivetud |> \n  questionr::freq()\n\n                                                                  n    % val%\nN'a jamais fait d'etudes                                         39  2.0  2.1\nA arrete ses etudes, avant la derniere annee d'etudes primaires  86  4.3  4.6\nDerniere annee d'etudes primaires                               341 17.0 18.1\n1er cycle                                                       204 10.2 10.8\n2eme cycle                                                      183  9.2  9.7\nEnseignement technique ou professionnel court                   463 23.2 24.5\nEnseignement technique ou professionnel long                    131  6.6  6.9\nEnseignement superieur y compris technique superieur            441 22.0 23.4\nNA                                                              112  5.6   NA\n\nhdv2003$instruction <- \n  hdv2003$nivetud |> \n  fct_recode(\n    \"primaire\" = \"N'a jamais fait d'etudes\",\n    \"primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n    \"primaire\" = \"Derniere annee d'etudes primaires\",\n    \"secondaire\" = \"1er cycle\",\n    \"secondaire\" = \"2eme cycle\",\n    \"technique/professionnel\" = \"Enseignement technique ou professionnel court\",\n    \"technique/professionnel\" = \"Enseignement technique ou professionnel long\",\n    \"supérieur\" = \"Enseignement superieur y compris technique superieur\"\n  )\nhdv2003$instruction |> \n  questionr::freq()\n\n                          n    % val%\nprimaire                466 23.3 24.7\nsecondaire              387 19.4 20.5\ntechnique/professionnel 594 29.7 31.5\nsupérieur               441 22.0 23.4\nNA                      112  5.6   NA\n\n\n\n\n\n\n\n\nInterface graphique\n\n\n\nLe packagequestionr propose une interface graphique facilitant le recodage des modalités d’une variable qualitative. L’objectif est de permettre à la personne qui l’utilise de saisir les nouvelles valeurs dans un formulaire, et de générer ensuite le code R correspondant au recodage indiqué.\nPour utiliser cette interface, sous RStudio vous pouvez aller dans le menu Addins (présent dans la barre d’outils principale) puis choisir Levels recoding. Sinon, vous pouvez lancer dans la console la fonction questionr::irec() en lui passant comme paramètre la variable à recoder.\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nUne démonstration en vidéo de cet add-in est disponible dans le webin-R #05 (recoder des variables) sur [YouTube](https://youtu.be/CokvTbtWdwc?t=3387).\n\n\n\n\n\nLa fonction forcats::fct_collapse() est une variante de forcats::fct_recode() pour indiquer les fusions de modalités. La même recodification s’écrirait alors :\n\nhdv2003$instruction <- \n  hdv2003$nivetud |> \n  fct_collapse(\n    \"primaire\" = c(\n      \"N'a jamais fait d'etudes\",\n      \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n      \"Derniere annee d'etudes primaires\"\n    ),\n    \"secondaire\" = c(\n      \"1er cycle\",\n      \"2eme cycle\"\n    ),\n    \"technique/professionnel\" = c(\n      \"Enseignement technique ou professionnel court\",\n      \"Enseignement technique ou professionnel long\"\n    ),\n    \"supérieur\" = \"Enseignement superieur y compris technique superieur\"\n  )\n\nPour transformer les valeurs manquantes (NA) en une modalité explicite, on pourra avoir recours à forcats::fct_explicit_na().\n\nhdv2003$instruction <-\n  hdv2003$instruction |> \n  fct_explicit_na(na_level = \"(manquant)\")\nhdv2003$instruction |> \n  questionr::freq()\n\n                          n    % val%\nprimaire                466 23.3 23.3\nsecondaire              387 19.4 19.4\ntechnique/professionnel 594 29.7 29.7\nsupérieur               441 22.0 22.0\n(manquant)              112  5.6  5.6\n\n\nPlusieurs fonctions permettent de regrouper plusieurs modalités dans une modalité autres.\nPar exemple, avec forcats::fct_other(), on pourra indiquer les modalités à garder.\n\nhdv2003$qualif |> \n  questionr::freq()\n\n                           n    % val%\nOuvrier specialise       203 10.2 12.3\nOuvrier qualifie         292 14.6 17.7\nTechnicien                86  4.3  5.2\nProfession intermediaire 160  8.0  9.7\nCadre                    260 13.0 15.7\nEmploye                  594 29.7 35.9\nAutre                     58  2.9  3.5\nNA                       347 17.3   NA\n\nhdv2003$qualif |> \n  fct_other(keep = c(\"Technicien\", \"Cadre\", \"Employe\")) |> \n  questionr::freq()\n\n             n    % val%\nTechnicien  86  4.3  5.2\nCadre      260 13.0 15.7\nEmploye    594 29.7 35.9\nOther      713 35.6 43.1\nNA         347 17.3   NA\n\n\nLa fonction forcats::fct_lump_n() permets de ne conserver que les modalités les plus fréquentes et de regrouper les autres dans une modalité autres.\n\nhdv2003$qualif |> \n  fct_lump_n(n = 4, other_level = \"Autres\") |> \n  questionr::freq()\n\n                     n    % val%\nOuvrier specialise 203 10.2 12.3\nOuvrier qualifie   292 14.6 17.7\nCadre              260 13.0 15.7\nEmploye            594 29.7 35.9\nAutres             304 15.2 18.4\nNA                 347 17.3   NA\n\n\nEt forcats::fct_lump_min() celles qui ont un minimum d’observations.\n\nhdv2003$qualif |> \n  fct_lump_min(min = 200, other_level = \"Autres\") |> \n  questionr::freq()\n\n                     n    % val%\nOuvrier specialise 203 10.2 12.3\nOuvrier qualifie   292 14.6 17.7\nCadre              260 13.0 15.7\nEmploye            594 29.7 35.9\nAutres             304 15.2 18.4\nNA                 347 17.3   NA\n\n\nIl peut arriver qu’une des modalités d’un facteur ne soit pas représentée dans les données.\n\nv <- factor(\n  c(\"a\", \"a\", \"b\", \"a\"),\n  levels = c(\"a\", \"b\", \"c\")\n)\nquestionr::freq(v)\n\n  n  % val%\na 3 75   75\nb 1 25   25\nc 0  0    0\n\n\nPour calculer certains tests statistiques ou faire tourner un modèle, ces modalités sans observation peuvent être problématiques. forcats::fct_drop() permet de supprimer les modalités qui n’apparaissent pas dans les données.\n\nv\n\n[1] a a b a\nLevels: a b c\n\nv |> fct_drop()\n\n[1] a a b a\nLevels: a b\n\n\nÀ l’inverse, forcats::fct_expand() permet d’ajouter une ou plusieurs modalités à un facteur.\n\nv\n\n[1] a a b a\nLevels: a b c\n\nv |> fct_expand(\"d\", \"e\")\n\n[1] a a b a\nLevels: a b c d e"
  },
  {
    "objectID": "manipulation/facteurs.html#sec-cut",
    "href": "manipulation/facteurs.html#sec-cut",
    "title": "9  Facteurs et forcats",
    "section": "\n9.4 Découper une variable numérique en classes",
    "text": "9.4 Découper une variable numérique en classes\nIl est fréquent d’avoir besoin de découper une variable numérique en une variable catgéorielles (un facteur) à plusieurs modalités, par exemple pour créer des groupes d’âges à partir d’une variable age.\nOn utilise pour cela la fonction cut() qui prend, outre la variable à découper, un certain nombre d’arguments :\n\n\nbreaks indique soit le nombre de classes souhaité, soit, si on lui fournit un vecteur, les limites des classes ;\n\nlabels permet de modifier les noms de modalités attribués aux classes ;\n\ninclude.lowest et right influent sur la manière dont les valeurs situées à la frontière des classes seront inclues ou exclues ;\n\ndig.lab indique le nombre de chiffres après la virgule à conserver dans les noms de modalités.\n\nPrenons tout de suite un exemple et tentons de découper la variable age en cinq classes :\n\nhdv2003 <-\n  hdv2003 |> \n  mutate(groupe_ages = cut(age, 5))\nhdv2003$groupe_ages |> questionr::freq()\n\n              n    % val%\n(17.9,33.8] 454 22.7 22.7\n(33.8,49.6] 628 31.4 31.4\n(49.6,65.4] 556 27.8 27.8\n(65.4,81.2] 319 16.0 16.0\n(81.2,97.1]  43  2.1  2.1\n\n\nPar défaut R nous a bien créé cinq classes d’amplitudes égales. La première classe va de 17,9 à 33,8 ans (en fait de 17 à 32), etc.\nLes frontières de classe seraient plus présentables si elles utilisaient des nombres ronds. On va donc spécifier manuellement le découpage souhaité, par tranches de 20 ans :\n\nhdv2003 <-\n  hdv2003 |> \n  mutate(groupe_ages = cut(age, c(18, 20, 40, 60, 80, 97)))\nhdv2003$groupe_ages |> questionr::freq()\n\n          n    % val%\n(18,20]  55  2.8  2.8\n(20,40] 660 33.0 33.3\n(40,60] 780 39.0 39.3\n(60,80] 436 21.8 22.0\n(80,97]  52  2.6  2.6\nNA       17  0.9   NA\n\n\nLes symboles dans les noms attribués aux classes ont leur importance : ( signifie que la frontière de la classe est exclue, tandis que [ signifie qu’elle est incluse. Ainsi, (20,40] signifie « strictement supérieur à 20 et inférieur ou égal à 40 ».\nOn remarque que du coup, dans notre exemple précédent, la valeur minimale, 18, est exclue de notre première classe, et qu’une observation est donc absente de ce découpage. Pour résoudre ce problème on peut soit faire commencer la première classe à 17, soit utiliser l’option include.lowest=TRUE :\n\nhdv2003 <-\n  hdv2003 |> \n  mutate(groupe_ages = cut(\n    age, \n    c(18, 20, 40, 60, 80, 97),\n    include.lowest = TRUE\n  ))\nhdv2003$groupe_ages |> questionr::freq()\n\n          n    % val%\n[18,20]  72  3.6  3.6\n(20,40] 660 33.0 33.0\n(40,60] 780 39.0 39.0\n(60,80] 436 21.8 21.8\n(80,97]  52  2.6  2.6\n\n\nOn peut également modifier le sens des intervalles avec l’option right=FALSE :\n\nhdv2003 <-\n  hdv2003 |> \n  mutate(groupe_ages = cut(\n    age, \n    c(18, 20, 40, 60, 80, 97),\n    include.lowest = TRUE,\n    right = FALSE\n  ))\nhdv2003$groupe_ages |> questionr::freq()\n\n          n    % val%\n[18,20)  48  2.4  2.4\n[20,40) 643 32.1 32.1\n[40,60) 793 39.6 39.6\n[60,80) 454 22.7 22.7\n[80,97]  62  3.1  3.1\n\n\n\n\n\n\n\n\nInterface graphique\n\n\n\nIl n’est pas nécessaire de connaître toutes les options de cut(). Le package questionr propose là encore une interface graphique permettant de visualiser l’effet des différents paramètres et de générer le code R correspondant.\nPour utiliser cette interface, sous RStudio vous pouvez aller dans le menu Addins (présent dans la barre d’outils principale) puis choisir Numeric range dividing. Sinon, vous pouvez lancer dans la console la fonction questionr::icut() en lui passant comme paramètre la variable numérique à découper.\n Une démonstration en vidéo de cet add-in est disponible dans le webin-R #05 (recoder des variables) sur [YouTube](https://youtu.be/CokvTbtWdwc?t=2795)."
  },
  {
    "objectID": "manipulation/combiner-variables.html#if_else",
    "href": "manipulation/combiner-variables.html#if_else",
    "title": "10  Combiner plusieurs variables",
    "section": "\n10.1 if_else()",
    "text": "10.1 if_else()\ndplyr::if_else() prend trois arguments : un test, les valeurs à renvoyer si le test est vrai, et les valeurs à renvoyer si le test est faux.\nVoici un exemple simple :\n\nv <- c(12, 14, 8, 16)\nif_else(v > 10, \"Supérieur à 10\", \"Inférieur à 10\")\n\n[1] \"Supérieur à 10\" \"Supérieur à 10\" \"Inférieur à 10\" \"Supérieur à 10\"\n\n\nLa fonction devient plus intéressante avec des tests combinant plusieurs variables. Par exemple, imaginons qu’on souhaite créer une nouvelle variable indiquant les hommes de plus de 60 ans :\n\nhdv2003 <- \n  hdv2003 |> \n  mutate(\n    statut = if_else(\n      sexe == \"Homme\" & age > 60,\n      \"Homme de plus de 60 ans\",\n      \"Autre\"\n    )\n  )\nhdv2003 |> \n  pull(statut) |> \n  questionr::freq()\n\n                           n    % val%\nAutre                   1778 88.9 88.9\nHomme de plus de 60 ans  222 11.1 11.1\n\n\nIl est possible d’utiliser des variables ou des combinaisons de variables au sein du dplyr::if_else(). Suppons une petite enquête menée auprès de femmes et d’hommes. Le questionnaire comportait une question de préférence posée différemment aux femmes et aux hommes et dont les réponses ont ainsi été collectées dans deux variables différentes, pref_f et pref_h, que l’on souhaite combiner en une seule variable. De même, une certaine mesure quantitative a été réalisée, mais une correction est nécessaire pour normaliser ce score (retirer 0.4 aux scores des hommes et 0.6 aux scores des femmes). Cela peut être réalisé avec le code ci-dessous.\n\ndf <- tibble(\n  sexe = c(\"f\", \"f\", \"h\", \"h\"),\n  pref_f = c(\"a\", \"b\", NA, NA),\n  pref_h = c(NA, NA, \"c\", \"d\"),\n  mesure = c(1.2, 4.1, 3.8, 2.7)\n)\ndf\n\n# A tibble: 4 × 4\n  sexe  pref_f pref_h mesure\n  <chr> <chr>  <chr>   <dbl>\n1 f     a      <NA>      1.2\n2 f     b      <NA>      4.1\n3 h     <NA>   c         3.8\n4 h     <NA>   d         2.7\n\ndf <- \n  df |> \n  mutate(\n    pref = if_else(sexe == \"f\", pref_f, pref_h),\n    indicateur = if_else(sexe == \"h\", mesure - 0.4, mesure - 0.6)\n  )\ndf\n\n# A tibble: 4 × 6\n  sexe  pref_f pref_h mesure pref  indicateur\n  <chr> <chr>  <chr>   <dbl> <chr>      <dbl>\n1 f     a      <NA>      1.2 a            0.6\n2 f     b      <NA>      4.1 b            3.5\n3 h     <NA>   c         3.8 c            3.4\n4 h     <NA>   d         2.7 d            2.3\n\n\n\n\n\n\n\n\nif_else() et ifelse()\n\n\n\nLa fonction dplyr::if_else() ressemble à la fonction ifelse() en base R. Il y a néanmoins quelques petites différences :\n\n\ndplyr::if_else() vérifie que les valeurs fournies pour true et celles pour false sont du même type et de la même classe et renvoie une erreur dans le cas contraire, là où ifelse() sera plus permissif ;\nsi un vecteur a des attributs (cf. Chapitre 6), ils seront préservés par dplyr::if_else() (et pris dans le vecteur true), ce que ne fera pas if_else() ;\n\ndplyr::if_else() propose un argument optionnel supplémentaire missing pour indiquer les valeurs à retourner lorsque le test renvoie NA."
  },
  {
    "objectID": "manipulation/combiner-variables.html#case_when",
    "href": "manipulation/combiner-variables.html#case_when",
    "title": "10  Combiner plusieurs variables",
    "section": "\n10.2 case_when()",
    "text": "10.2 case_when()\ndplyr::case_when() est une généralisation de dplyr::if_else() qui permet d’indiquer plusieurs tests et leurs valeurs associées.\nImaginons que l’on souhaite créer une nouvelle variable permettant d’identifier les hommes de plus de 60 ans, les femmes de plus de 60 ans, et les autres. On peut utiliser la syntaxe suivante :\n\nhdv2003 <-\n  hdv2003 |> \n  mutate(\n    statut = case_when(\n      age >= 60 & sexe == \"Homme\" ~ \"Homme, 60 et plus\",\n      age >= 60 & sexe == \"Femme\" ~ \"Femme, 60 et plus\",\n      TRUE ~ \"Autre\"\n    )\n  )\nhdv2003 |> \n  pull(statut) |> \n  questionr::freq()\n\n                     n    % val%\nAutre             1484 74.2 74.2\nFemme, 60 et plus  278 13.9 13.9\nHomme, 60 et plus  238 11.9 11.9\n\n\ndplyr::case_when() prend en arguments une série d’instructions sous la forme condition ~ valeur. Il les exécute une par une, et dès qu’une condition est vraie, il renvoit la valeur associée.\nLa clause TRUE ~ \"Autre\" permet d’assigner une valeur à toutes les lignes pour lesquelles aucune des conditions précédentes n’est vraie.\n\n\n\n\n\n\nImportant\n\n\n\nAttention : comme les conditions sont testées l’une après l’autre et que la valeur renvoyée est celle correspondant à la première condition vraie, l’ordre de ces conditions est très important. Il faut absolument aller du plus spécifique au plus général.\nPar exemple le recodage suivant ne fonctionne pas :\n\nhdv2003 <-\n  hdv2003 |> \n  mutate(\n    statut = case_when(\n      sexe == \"Homme\" ~ \"Homme\",\n      age >= 60 & sexe == \"Homme\" ~ \"Homme, 60 et plus\",\n      TRUE ~ \"Autre\"\n    )\n  )\nhdv2003 |> \n  pull(statut) |> \n  questionr::freq()\n\n         n  % val%\nAutre 1101 55   55\nHomme  899 45   45\n\n\nComme la condition sexe == \"Homme\" est plus générale que sexe == \"Homme\" & age > 60, cette deuxième condition n’est jamais testée ! On n’obtiendra jamais la valeur correspondante.\nPour que ce recodage fonctionne il faut donc changer l’ordre des conditions pour aller du plus spécifique au plus général :\n\nhdv2003 <-\n  hdv2003 |> \n  mutate(\n    statut = case_when(\n      age >= 60 & sexe == \"Homme\" ~ \"Homme, 60 et plus\",\n      sexe == \"Homme\" ~ \"Homme\",\n      TRUE ~ \"Autre\"\n    )\n  )\nhdv2003 |> \n  pull(statut) |> \n  questionr::freq()\n\n                     n    % val%\nAutre             1101 55.0 55.0\nHomme              661 33.1 33.1\nHomme, 60 et plus  238 11.9 11.9\n\n\nC’est pour cela que l’on peut utiliser, en toute dernière condition, la valeur TRUE pour indiquer dans tous les autres cas."
  },
  {
    "objectID": "manipulation/combiner-variables.html#recode_if",
    "href": "manipulation/combiner-variables.html#recode_if",
    "title": "10  Combiner plusieurs variables",
    "section": "\n10.3 recode_if()",
    "text": "10.3 recode_if()\nParfois, on n’a besoin de ne modifier une variable que pour certaines observations. Prenons un petit exemple :\n\ndf <- tibble(\n  pref = factor(c(\"bleu\", \"rouge\", \"autre\", \"rouge\", \"autre\")),\n  autre_details = c(NA, NA, \"bleu ciel\", NA, \"jaune\")\n)\ndf\n\n# A tibble: 5 × 2\n  pref  autre_details\n  <fct> <chr>        \n1 bleu  <NA>         \n2 rouge <NA>         \n3 autre bleu ciel    \n4 rouge <NA>         \n5 autre jaune        \n\n\nNous avons demandé aux enquêtés d’indiquer leur couleur préférée. Ils pouvaient répondre bleu ou rouge et avait également la possibilité de choisir autre et d’indiquer la valeur de leur choix dans un champs textuel libre.\nUne des personnes enquêtées a choisi autre et a indiqué dans le champs texte la valeur bleu ciel. Pour les besoins de l’analyse, on peut considérer que cette valeur bleu ciel pour être tout simplement recodée en bleu.\nEn syntaxe R classique, on pourra simplement faire :\n\ndf$pref[df$autre_details == \"bleu ciel\"] <- \"bleu\"\n\nAvec dplyr::if_else(), on serait tenté d’écrire :\n\ndf |> \n  mutate(pref = if_else(autre_details == \"bleu ciel\", \"bleu\", pref))\n\nError in `mutate()`:\n! Problem while computing `pref = if_else(autre_details == \"bleu ciel\",\n  \"bleu\", pref)`.\nCaused by error in `if_else()`:\n! `false` must be a character vector, not a `factor` object.\n\n\nOn obtient une erreur, car dplyr::if_else() exige les valeurs fournie pour true et false soient de même type. Essayons alors :\n\ndf |> \n  mutate(pref = if_else(autre_details == \"bleu ciel\", factor(\"bleu\"), pref))\n\nWarning in `[<-.factor`(`*tmp*`, i, value = structure(1L, levels = c(\"autre\", :\nniveau de facteur incorrect, NAs générés\n\n\n# A tibble: 5 × 2\n  pref  autre_details\n  <fct> <chr>        \n1 <NA>  <NA>         \n2 <NA>  <NA>         \n3 bleu  bleu ciel    \n4 <NA>  <NA>         \n5 <NA>  jaune        \n\n\nIci nous avons un autre problème, signalé par un message d’avertissement (warning) : dplyr::if_else() ne préserve que les attributs du vecteur passé en true et non ceux passés à false. Or l’ensemble des modalités (niveaux du facteur) de la variable pref n’ont pas été définis dans factor(\"bleu\") et sont ainsi perdus, générant une perte de données (valeurs manquantes NA).\nPour obtenir le bon résultat, il faudrait inverser la condition :\n\ndf |> \n  mutate(pref = if_else(\n    autre_details != \"bleu ciel\", \n    pref, \n    factor(\"bleu\")\n  ))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  <fct> <chr>        \n1 <NA>  <NA>         \n2 <NA>  <NA>         \n3 bleu  bleu ciel    \n4 <NA>  <NA>         \n5 autre jaune        \n\n\nMais ce n’est toujours pas suffisant. En effet, la variable autre_details a des valeurs manquantes pour lesquelles le test autre_details != \"bleu ciel\" renvoie NA ce qui une fois encore génère des valeurs manquantes non souhaitées. Dès lors, il nous faut soit définir l’argument missing de dplyr::if_else(), soit être plus précis dans notre test.\n\ndf |> \n  mutate(pref = if_else(\n    autre_details != \"bleu ciel\", \n    pref, \n    factor(\"bleu\"),\n    missing = pref\n  ))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  <fct> <chr>        \n1 bleu  <NA>         \n2 rouge <NA>         \n3 bleu  bleu ciel    \n4 rouge <NA>         \n5 autre jaune        \n\ndf |> \n  mutate(pref = if_else(\n    autre_details != \"bleu ciel\" | is.na(autre_details), \n    pref, \n    factor(\"bleu\")\n  ))\n\n# A tibble: 5 × 2\n  pref  autre_details\n  <fct> <chr>        \n1 bleu  <NA>         \n2 rouge <NA>         \n3 bleu  bleu ciel    \n4 rouge <NA>         \n5 autre jaune        \n\n\nBref, on peut s’en sortir avec dplyr::if_else() mais ce n’est pas forcément le plus pratique dans le cas présent. La syntaxe en base R fonctionne très bien, mais ne peut pas être intégrée à un enchainement d’opérations utilisant le pipe.\nDans ce genre de situation, on pourra être intéressé par la fonction labelled::recode_if() disponible dans le package labelled. Elle permet de ne modifier que certaines observations d’un vecteur en fonction d’une condition. Si la condition vaut FALSE ou NA, les observations concernées restent inchangées. Voyons comment cela s’écrit :\n\ndf <-\n  df |> \n  mutate(\n    pref = pref |> \n      labelled::recode_if(autre_details == \"bleu ciel\", \"bleu\")\n  )\ndf\n\n# A tibble: 5 × 2\n  pref  autre_details\n  <fct> <chr>        \n1 bleu  <NA>         \n2 rouge <NA>         \n3 bleu  bleu ciel    \n4 rouge <NA>         \n5 autre jaune        \n\n\nC’est tout de suite plus intuitif !"
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#principe",
    "href": "manipulation/etiquettes-variables.html#principe",
    "title": "11  Étiquettes de variables",
    "section": "\n11.1 Principe",
    "text": "11.1 Principe\nLes étiquettes de variable permettent de donner un nom long, plus explicite, aux différentes colonnes d’un tableau de données (ou encore directement à un vecteur autonome). Dans le champs des grandes enquêtes, il est fréquent de nommer les variables q101, q102, etc. pour refléter le numéro de la question et d’indiquer ce qu’elle réprésente (groupe d’âges, milieur de résidence…) avec une étiquette.\nUn usage, introduit par le package haven, et repris depuis par de nombreux autres packages dont gtsummary que nous aborderons dans de prochains chapitres, consiste à stocker les étiquettes de variables sous la forme d’un attribut1 \"label\" attaché au vecteur / à la colonne du tableau.1 Pour plus d’information sur les attributs, voir Chapitre 6.\nLe package labelled permet de manipuler aisément ces étiquettes de variables.\nLa visonneuse de données de RStudio sait reconnaître et afficher ces étiquettes de variable lorsqu’elles existent. Prenons pour exemple le jeu de données gtsummary::trial dont les colonnes ont des étiquettes de variable. La commande View(gtsummary::trial) permet d’ouvrir la visionneuse de données de RStudio. Comme on peut le constater, une étiquette de variable est bien présente sous le nom des différentes colonnes.\n\n\nFigure 11.1: Présentation du tableau gtsummary::trial dans la visionneuse de RStudio\n\n\nLa fonction labelled::look_for() du package labelled permet de lister l’ensemble des variables d’un tableau de données et affiche notamment les étiquettes de variable associées.\n\nlibrary(labelled)\ngtsummary::trial |> \n  look_for()\n\n pos variable label                  col_type values\n 1   trt      Chemotherapy Treatment chr            \n 2   age      Age                    dbl            \n 3   marker   Marker Level (ng/mL)   dbl            \n 4   stage    T Stage                fct      T1    \n                                              T2    \n                                              T3    \n                                              T4    \n 5   grade    Grade                  fct      I     \n                                              II    \n                                              III   \n 6   response Tumor Response         int            \n 7   death    Patient Died           int            \n 8   ttdeath  Months to Death/Censor dbl            \n\n\nLa fonction labelled::look_for() permet également de rechercher des variables en tenant compte à la fois de leur nom et de leur étiquette.\n\ngtsummary::trial |> \n  look_for(\"months\")\n\n pos variable label                  col_type values\n 8   ttdeath  Months to Death/Censor dbl            \n\n\n\n\n\n\n\n\nAstuce\n\n\n\nComme on le voit, la fonction labelled::look_for() est tout à fait adaptée pour générer un dictionnaire de codification. Ses différentes options sont détaillées dans une vignette dédiée. Les résultats renvoyés par labelled::look_for() sont récupérables dans un tableau de données que l’on pourra ainsi manipuler à sa guise.\n\ngtsummary::trial |> \n  look_for() |> \n  dplyr::as_tibble()\n\n# A tibble: 8 × 6\n    pos variable label                  col_type levels       value_labels\n  <int> <chr>    <chr>                  <chr>    <named list> <named list>\n1     1 trt      Chemotherapy Treatment chr      <NULL>       <NULL>      \n2     2 age      Age                    dbl      <NULL>       <NULL>      \n3     3 marker   Marker Level (ng/mL)   dbl      <NULL>       <NULL>      \n4     4 stage    T Stage                fct      <chr [4]>    <NULL>      \n5     5 grade    Grade                  fct      <chr [3]>    <NULL>      \n6     6 response Tumor Response         int      <NULL>       <NULL>      \n7     7 death    Patient Died           int      <NULL>       <NULL>      \n8     8 ttdeath  Months to Death/Censor dbl      <NULL>       <NULL>"
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#manipulation-sur-un-vecteur-une-colonne",
    "href": "manipulation/etiquettes-variables.html#manipulation-sur-un-vecteur-une-colonne",
    "title": "11  Étiquettes de variables",
    "section": "\n11.2 Manipulation sur un vecteur / une colonne",
    "text": "11.2 Manipulation sur un vecteur / une colonne\nLa fonction labelled::var_label() permets de voir l’étiquette de variable attachée à un vecteur (renvoie NULL s’il n’y en a pas) mais également d’ajouter/modifier une étiquette.\nLe fait d’ajouter une étiquette de variable à un vecteur ne modifie en rien son type ni sa classe. On peut associer une étiquette de variable à n’importe quel type de variable, qu’elle soit numérique, textuelle, un facteur ou encore des dates.\n\nv <- c(1, 5, 2, 4, 1)\nv |> var_label()\n\nNULL\n\nvar_label(v) <- \"Mon étiquette\"\nvar_label(v)\n\n[1] \"Mon étiquette\"\n\nstr(v)\n\n num [1:5] 1 5 2 4 1\n - attr(*, \"label\")= chr \"Mon étiquette\"\n\nvar_label(v) <- \"Une autre étiquette\"\nvar_label(v)\n\n[1] \"Une autre étiquette\"\n\nstr(v)\n\n num [1:5] 1 5 2 4 1\n - attr(*, \"label\")= chr \"Une autre étiquette\"\n\n\nPour supprimer une étiquette, il suffit d’attribuer la valeur NULL.\n\nvar_label(v) <- NULL\nstr(v)\n\n num [1:5] 1 5 2 4 1\n\n\nOn peut appliquer labelled::var_label() directement sur une colonne de tableau.\n\nvar_label(iris$Petal.Length) <- \"Longueur du pétale\"\nvar_label(iris$Petal.Width) <- \"Largeur du pétale\"\nvar_label(iris$Species) <- \"Espèce\"\niris |> \n  look_for()\n\n pos variable     label              col_type values    \n 1   Sepal.Length —                  dbl                \n 2   Sepal.Width  —                  dbl                \n 3   Petal.Length Longueur du pétale dbl                \n 4   Petal.Width  Largeur du pétale  dbl                \n 5   Species      Espèce             fct      setosa    \n                                              versicolor\n                                              virginica"
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#manipulation-sur-un-tableau-de-données",
    "href": "manipulation/etiquettes-variables.html#manipulation-sur-un-tableau-de-données",
    "title": "11  Étiquettes de variables",
    "section": "\n11.3 Manipulation sur un tableau de données",
    "text": "11.3 Manipulation sur un tableau de données\nLa fonction labelled::set_variable_labels() permets de manipuler les étiquettes de variable d’un tableau de données avec une syntaxe du type dplyr.\n\niris <- \n  iris |> \n  set_variable_labels(\n    Species = NULL,\n    Sepal.Length = \"Longeur du sépale\"\n  )\niris |> \n  look_for()\n\n pos variable     label              col_type values    \n 1   Sepal.Length Longeur du sépale  dbl                \n 2   Sepal.Width  —                  dbl                \n 3   Petal.Length Longueur du pétale dbl                \n 4   Petal.Width  Largeur du pétale  dbl                \n 5   Species      —                  fct      setosa    \n                                              versicolor\n                                              virginica"
  },
  {
    "objectID": "manipulation/etiquettes-variables.html#préserver-les-étiquettes",
    "href": "manipulation/etiquettes-variables.html#préserver-les-étiquettes",
    "title": "11  Étiquettes de variables",
    "section": "\n11.4 Préserver les étiquettes",
    "text": "11.4 Préserver les étiquettes\nCertaines fonctions de R ne préservent pas les attributs et risquent donc d’effacer les étiquettes de variables que l’on a définit. Un exemple est la fonction générique subset() qui permet de sélectionner certaines lignes remplissant une certaines conditions.\n\niris |> \n  look_for()\n\n pos variable     label              col_type values    \n 1   Sepal.Length Longeur du sépale  dbl                \n 2   Sepal.Width  —                  dbl                \n 3   Petal.Length Longueur du pétale dbl                \n 4   Petal.Width  Largeur du pétale  dbl                \n 5   Species      —                  fct      setosa    \n                                              versicolor\n                                              virginica \n\niris |> \n  subset(Species == \"setosa\") |> \n  look_for()\n\n pos variable     label col_type values    \n 1   Sepal.Length —     dbl                \n 2   Sepal.Width  —     dbl                \n 3   Petal.Length —     dbl                \n 4   Petal.Width  —     dbl                \n 5   Species      —     fct      setosa    \n                                 versicolor\n                                 virginica \n\n\nOn pourra, dans ce cas précis, préférer la fonction dplyr::filter() qui préserve les attributs et donc les étiquettes de variables.\n\niris |> \n  dplyr::filter(Species == \"setosa\") |> \n  look_for()\n\n pos variable     label              col_type values    \n 1   Sepal.Length Longeur du sépale  dbl                \n 2   Sepal.Width  —                  dbl                \n 3   Petal.Length Longueur du pétale dbl                \n 4   Petal.Width  Largeur du pétale  dbl                \n 5   Species      —                  fct      setosa    \n                                              versicolor\n                                              virginica \n\n\nOn pourra également tirer parti de la fonction labelled::copy_labels_from() qui permet de copier les étiquettes d’un tabeau à un autre.\n\niris |> \n  subset(Species == \"setosa\") |> \n  copy_labels_from(iris) |> \n  look_for()\n\n pos variable     label              col_type values    \n 1   Sepal.Length Longeur du sépale  dbl                \n 2   Sepal.Width  —                  dbl                \n 3   Petal.Length Longueur du pétale dbl                \n 4   Petal.Width  Largeur du pétale  dbl                \n 5   Species      —                  fct      setosa    \n                                              versicolor\n                                              virginica"
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#la-classe-haven_labelled",
    "href": "manipulation/etiquettes-valeurs.html#la-classe-haven_labelled",
    "title": "12  Étiquettes de valeurs",
    "section": "\n12.1 La classe haven_labelled\n",
    "text": "12.1 La classe haven_labelled\n\nAfin d’assurer une importation complète des données depuis SPSS, Stata et SAS, le package haven a introduit un nouveau type de vecteurs, la classe haven_labelled, qui permet justement de rendre compte de ces vecteurs labellisés (i.e. avec des étiquettes de valeurs). Le package labelled fournie un jeu de fonctions pour faciliter la manipulation des vecteurs labellisés.\n\n\n\n\n\n\nImportant\n\n\n\nLes vecteurs labellisés sont un format intermédiaire qui permets d’importer les données telles qu’elles ont été définies dans le fichier source. Il n’est pas destiné à être utilisé pour l’analyse statistique.\nPour la réalisation de tableaux, graphiques, modèles, R attend que les variables catégorielles soit codées sous formes de facteurs, et que les variables continues soient numériques. On aura donc besoin, à un moment ou à un autre, de convertir les vecteurs labellisés en facteurs ou en variables numériques classiques."
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-vecteur-une-colonne",
    "href": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-vecteur-une-colonne",
    "title": "12  Étiquettes de valeurs",
    "section": "\n12.2 Manipulation sur un vecteur / une colonne",
    "text": "12.2 Manipulation sur un vecteur / une colonne\nPour définir des étiquettes, la fonction de base est labelled::val_labels(). Il est possible de définir des étiquettes de valeurs pour des vecteurs numériques, d’entiers et textuels. On indiquera les étiquettes sous la forme étiquette = valeur. Cette fonction s’utilise de la même manière que labelled::var_label() abordée au chapitre précédent (cf. Chapitre 11). Un appel simple renvoie les étiquettes de valeur associées au vecteur, NULL s’il n’y en n’a pas. Combiner avec l’opérateur d’assignation (<-), on peut ajouter/modifier les étiquettes de valeurs associées au vecteur.\n\nlibrary(labelled)\nv <- c(1, 2, 1, 9)\nv\n\n[1] 1 2 1 9\n\nclass(v)\n\n[1] \"numeric\"\n\nval_labels(v)\n\nNULL\n\nval_labels(v) <- c(non = 1, oui = 2)\nval_labels(v)\n\nnon oui \n  1   2 \n\nv\n\n<labelled<double>[4]>\n[1] 1 2 1 9\n\nLabels:\n value label\n     1   non\n     2   oui\n\nclass(v)\n\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n\nComme on peut le voir avec cet exemple simple :\n\nl’ajout d’étiquettes de valeurs modifie la class de l’objet (qui est maintenant un vecteur de la classe haven_labelled) ;\nl’objet obtenu est multi-classes, la classe double indiquant ici qu’il s’agit d’un vecteur numérique ;\nil n’est pas obligatoire d’associer une étiquette de valeurs à toutes les valeurs observées dans le vecteur (ici, nous n’avons pas défini d’étiquettes pour la valeur 9).\n\nLa fonction labelled::val_label() (notez l’absence d’un s à la fin du nom de la fonction) permet d’accéder / de modifier l’étiquette associée à une valeur spécifique.\n\nval_label(v, 1)\n\n[1] \"non\"\n\nval_label(v, 9)\n\nNULL\n\nval_label(v, 9) <- \"(manquant)\"\nval_label(v, 2) <- NULL\nv\n\n<labelled<double>[4]>\n[1] 1 2 1 9\n\nLabels:\n value      label\n     1        non\n     9 (manquant)\n\n\nPour supprimer, toutes les étiquettes de valeurs, on attribuera NULL avec labelled::val_labels().\n\nval_labels(v) <- NULL\nv\n\n[1] 1 2 1 9\n\nclass(v)\n\n[1] \"numeric\"\n\n\nOn remarquera que, lorsque toutes les étiquettes de valeurs sont supprimées, la nature de l’objet change à nouveau et il redevient un simple vecteur numérique.\n\n\n\n\n\n\nMise en garde\n\n\n\nIl est essentiel de bien comprendre que l’ajout d’étiquettes de valeurs ne change pas fondamentalement la nature du vecteur. Cela ne le transforme pas en variable catégorielle. À ce stade, le vecteur n’a pas été transformé en facteur. Cela reste un vecteur numérique qui est considéré comme tel par R. On peut ainsi en calculer une moyenne, ce qui serait impossible avec un facteur.\n\nv <- c(1, 2, 1, 2)\nval_labels(v) <- c(non = 1, oui = 2)\nmean(v)\n\n[1] 1.5\n\nf <- factor(v, levels = c(1, 2), labels = c(\"non\", \"oui\"))\nmean(f)\n\nWarning in mean.default(f): l'argument n'est ni numérique, ni logique : renvoi\nde NA\n\n\n[1] NA\n\n\n\n\nLes fonctions labelled::val_labels() et labelled::val_label() peuvent également être utilisées sur les colonnes d’un tableau.\n\ndf <- dplyr::tibble(\n  x = c(1, 2, 1, 2),\n  y = c(3, 9, 9, 3)\n)\nval_labels(df$x) <- c(non = 1, oui = 2)\nval_label(df$y, 9) <- \"(manquant)\"\ndf\n\n# A tibble: 4 × 2\n  x         y             \n  <dbl+lbl> <dbl+lbl>     \n1 1 [non]   3             \n2 2 [oui]   9 [(manquant)]\n3 1 [non]   9 [(manquant)]\n4 2 [oui]   3             \n\n\nOn pourra noter, que si notre tableau est un tibble, les étiquettes sont rendues dans la console quand on affiche le tableau.\nLa fonction labelled::look_for() est également un bon moyen d’afficher les étiquettes de valeurs.\n\ndf |> \n  look_for()\n\n pos variable label col_type values        \n 1   x        —     dbl+lbl  [1] non       \n                             [2] oui       \n 2   y        —     dbl+lbl  [9] (manquant)"
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-tableau-de-données",
    "href": "manipulation/etiquettes-valeurs.html#manipulation-sur-un-tableau-de-données",
    "title": "12  Étiquettes de valeurs",
    "section": "\n12.3 Manipulation sur un tableau de données",
    "text": "12.3 Manipulation sur un tableau de données\n{labelled} fournie 3 fonctions directement applicables sur un tableau de données : labelled::set_value_labels(), labelled::add_value_labels() et labelled::remove_value_labels(). La première remplace l’ensemble des étiquettes de valeurs associées à une variable, la seconde ajoute des étiquettes de valeurs (et conserve celles déjà définies), la troisième supprime les étiquettes associées à certaines valeurs spécifiques (et laisse les autres inchangées).\n\ndf |> \n  look_for()\n\n pos variable label col_type values        \n 1   x        —     dbl+lbl  [1] non       \n                             [2] oui       \n 2   y        —     dbl+lbl  [9] (manquant)\n\ndf <- df |> \n  set_value_labels(\n    x = c(yes = 2),\n    y = c(\"a répondu\" = 3, \"refus de répondre\" = 9)\n  )\ndf |> \n  look_for()\n\n pos variable label col_type values               \n 1   x        —     dbl+lbl  [2] yes              \n 2   y        —     dbl+lbl  [3] a répondu        \n                             [9] refus de répondre\n\ndf <- df |> \n  add_value_labels(\n    x = c(no = 1)\n  ) |> \n  remove_value_labels(\n    y = 9\n  )\ndf |> \n  look_for()\n\n pos variable label col_type values       \n 1   x        —     dbl+lbl  [2] yes      \n                             [1] no       \n 2   y        —     dbl+lbl  [3] a répondu"
  },
  {
    "objectID": "manipulation/etiquettes-valeurs.html#conversion",
    "href": "manipulation/etiquettes-valeurs.html#conversion",
    "title": "12  Étiquettes de valeurs",
    "section": "\n12.4 Conversion",
    "text": "12.4 Conversion\n\n12.4.1 Quand convertir les vecteurs labellisés ?\nLa classe haven_labelled permets d’ajouter des métadonnées aux variables sous la forme d’étiquettes de valeurs. Lorsque les données sont importées depuis SAS, SPSS ou Stata, cela permet notamment de conserver le codage original du fichier importé.\nMais il faut noter que ces étiquettes de valeur n’indique pas pour autant de manière systématique le type de variable (catégorielle ou continue). Les vecteurs labellisés n’ont donc pas vocation à être utilisés pour l’analyse, notamment le calcul de modèles statistiques. Ils doivent être convertis en facteurs (pour les variables catégorielles) ou en vecteurs numériques (pour les variables continues).\nLa question qui peut se poser est donc de choisir à quel moment cette conversion doit avoir lieu dans un processus d’analyse. On peut considérer deux approches principales.\n\n\nFigure 12.1: Deux approches possibles pour la conversion des étiquettes de valeurs\n\n\nDans l’approche A, les vecteurs labellisés sont convertis juste après l’import des données, en utilisant les fonctions labelled::unlabelled(), labelled::to_factor() ou base::unclass() qui sont présentées ci-après. Dès lors, toute la partie de nettoyage et de recodage des données se fera en utilisant les fonctions classiques de R. Si l’on n’a pas besoin de conserver le codage original, cette approche a l’avantage de s’inscrire dans le fonctionnement usuel de R.\nDans l’approche B, les vecteurs labellisés sont conservés pour l’étape de nettoyage et de recodage des données. Dans ce cas là, on pourra avoir recours aux fonctions de l’extension labelled qui facilitent la gestion des données labellisées. Cette approche est particulièrement intéressante quand (i) on veut pouvoir se référer au dictionnaire de codification fourni avec les données sources et donc on veut conserver le codage original et/ou (ii) quand les données devront faire l’objet d’un réexport après transformation. Par contre, comme dans l’approche A, il faudra prévoir une conversion des variables labellisées au moment de l’analyse.\n\n\n\n\n\n\nAvertissement\n\n\n\nDans tous les cas, il est recommandé d’adopter l’une ou l’autre approche, mais d’éviter de mélanger les différents types de vecteur. Une organisation rigoureuse de ses données et de son code est essentielle !\n\n\n\n12.4.2 Convertir un vecteur labellisé en facteur\nIl est très facile de convertir un vecteur labellisé en facteur à l’aide la fonction labelled::to_factor() du package labelled1.1 On priviligiera la fonction labelled::to_factor() à la fonction haven::as_factor() de l’extension haven, la première ayant plus de possibilités et un comportement plus consistent.\n\nv <- c(1,2,9,3,3,2,NA)\nval_labels(v) <- c(\n  oui = 1, \"peut-être\" = 2, \n  non = 3, \"ne sait pas\" = 9\n)\nv\n\n<labelled<double>[7]>\n[1]  1  2  9  3  3  2 NA\n\nLabels:\n value       label\n     1         oui\n     2   peut-être\n     3         non\n     9 ne sait pas\n\nto_factor(v)\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] <NA>       \nLevels: oui peut-être non ne sait pas\n\n\nIl possible d’indiquer si l’on souhaite, comme étiquettes du facteur, utiliser les étiquettes de valeur (par défaut), les valeurs elles-mêmes, ou bien les étiquettes de valeurs préfixées par la valeur d’origine indiquée entre crochets.\n\nto_factor(v, 'l')\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] <NA>       \nLevels: oui peut-être non ne sait pas\n\nto_factor(v, 'v')\n\n[1] 1    2    9    3    3    2    <NA>\nLevels: 1 2 3 9\n\nto_factor(v, 'p')\n\n[1] [1] oui         [2] peut-être   [9] ne sait pas [3] non        \n[5] [3] non         [2] peut-être   <NA>           \nLevels: [1] oui [2] peut-être [3] non [9] ne sait pas\n\n\nPar défaut, les modalités du facteur seront triées selon l’ordre des étiquettes de valeur. Mais cela peut être modifié avec l’argument sort_levels si l’on préfère trier selon les valeurs ou selon l’ordre alphabétique des étiquettes.\n\nto_factor(v, sort_levels = 'v')\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] <NA>       \nLevels: oui peut-être non ne sait pas\n\nto_factor(v, sort_levels = 'l')\n\n[1] oui         peut-être   ne sait pas non         non         peut-être  \n[7] <NA>       \nLevels: ne sait pas non oui peut-être\n\n\n\n12.4.3 Convertir un vecteur labellisé en numérique ou en texte\nPour rappel, il existe deux types de vecteurs labellisés : des vecteurs numériques labellisés (x dans l’exemple ci-dessous) et des vecteurs textuels labellisés (y dans l’exemple ci-dessous).\n\nx <- c(1, 2, 9, 3, 3, 2, NA)\nval_labels(x) <- c(\n  oui = 1, \"peut-être\" = 2, \n  non = 3, \"ne sait pas\" = 9\n)\n  \ny <- c(\"f\", \"f\", \"h\", \"f\")\nval_labels(y) <- c(femme = \"f\", homme = \"h\")\n\nPour leur retirer leur caractère labellisé et revenir à leur classe d’origine, on peut utiliser la fonction unclass().\n\nunclass(x)\n\n[1]  1  2  9  3  3  2 NA\nattr(,\"labels\")\n        oui   peut-être         non ne sait pas \n          1           2           3           9 \n\nunclass(y)\n\n[1] \"f\" \"f\" \"h\" \"f\"\nattr(,\"labels\")\nfemme homme \n  \"f\"   \"h\" \n\n\nÀ noter que dans ce cas-là, les étiquettes sont conservées comme attributs du vecteur.\nUne alternative est d’utiliser labelled::remove_labels() qui supprimera toutes les étiquettes, y compris les étiquettes de variable. Pour conserver les étiquettes de variables et ne supprimer que les étiquettes de valeurs, on indiquera keep_var_label = TRUE.\n\nvar_label(x) <- \"Etiquette de variable\"\nremove_labels(x)\n\n[1]  1  2  9  3  3  2 NA\n\nremove_labels(x, keep_var_label = TRUE)\n\n[1]  1  2  9  3  3  2 NA\nattr(,\"label\")\n[1] \"Etiquette de variable\"\n\nremove_labels(y)\n\n[1] \"f\" \"f\" \"h\" \"f\"\n\n\nDans le cas d’un vecteur numérique labellisé que l’on souhaiterait convertir en variable textuelle, on pourra utiliser labelled::to_character() à la place de labelled::to_factor() qui, comme sa grande soeur, utilisera les étiquettes de valeurs.\n\nto_character(x)\n\n[1] \"oui\"         \"peut-être\"   \"ne sait pas\" \"non\"         \"non\"        \n[6] \"peut-être\"   NA           \nattr(,\"label\")\n[1] \"Etiquette de variable\"\n\n\n\n12.4.4 Conversion conditionnelle en facteurs\nIl n’est pas toujours possible de déterminer la nature d’une variable (continue ou catégorielle) juste à partir de la présence ou l’absence d’étiquettes de valeur. En effet, on peut utiliser des étiquettes de valeur dans le cadre d’une variable continue pour indiquer certaines valeurs spécifiques.\nUne bonne pratique est de vérifier chaque variable inclue dans une analyse, une à une.\nCependant, une règle qui fonctionne dans 90% des cas est de convertir un vecteur labellisé en facteur si et seulement si toutes les valeurs observées dans le vecteur disposent d’une étiquette de valeur correspondante. C’est ce que propose la fonction labelled::unlabelled() qui peut même être appliqué à tout un tableau de données. Par défaut, elle fonctionne ainsi :\n\nles variables non labellisées restent inchangées (variables f et g dans l’exemple ci-dessous);\nsi toutes les valeurs observées d’une variable labellisées ont une étiquette, elles sont converties en facteurs (variables b et c);\nsinon, on leur applique base::unclass() (variables a, d et e).\n\n\ndf <- dplyr::tibble(\n  a = c(1, 1, 2, 3),\n  b = c(1, 1, 2, 3),\n  c = c(1, 1, 2, 2),\n  d = c(\"a\", \"a\", \"b\", \"c\"),\n  e = c(1, 9, 1, 2),\n  f = 1:4,\n  g = as.Date(c(\n    \"2020-01-01\", \"2020-02-01\", \n    \"2020-03-01\", \"2020-04-01\"\n  ))\n) |> \n  set_value_labels(\n    a = c(No = 1, Yes = 2),\n    b = c(No = 1, Yes = 2, DK = 3),\n    c = c(No = 1, Yes = 2, DK = 3),\n    d = c(No = \"a\", Yes = \"b\"),\n    e = c(No = 1, Yes = 2)\n  )\ndf |> look_for()\n\n pos variable label col_type values \n 1   a        —     dbl+lbl  [1] No \n                             [2] Yes\n 2   b        —     dbl+lbl  [1] No \n                             [2] Yes\n                             [3] DK \n 3   c        —     dbl+lbl  [1] No \n                             [2] Yes\n                             [3] DK \n 4   d        —     chr+lbl  [a] No \n                             [b] Yes\n 5   e        —     dbl+lbl  [1] No \n                             [2] Yes\n 6   f        —     int             \n 7   g        —     date            \n\nto_factor(df) |> look_for()\n\n pos variable label col_type values\n 1   a        —     fct      No    \n                             Yes   \n                             3     \n 2   b        —     fct      No    \n                             Yes   \n                             DK    \n 3   c        —     fct      No    \n                             Yes   \n                             DK    \n 4   d        —     fct      No    \n                             Yes   \n                             c     \n 5   e        —     fct      No    \n                             Yes   \n                             9     \n 6   f        —     int            \n 7   g        —     date           \n\nunlabelled(df) |> look_for()\n\n pos variable label col_type values\n 1   a        —     dbl            \n 2   b        —     fct      No    \n                             Yes   \n                             DK    \n 3   c        —     fct      No    \n                             Yes   \n                             DK    \n 4   d        —     chr            \n 5   e        —     dbl            \n 6   f        —     int            \n 7   g        —     date           \n\n\nOn peut indiquer certaines options, par exemple drop_unused_labels = TRUE pour supprimer des facteurs créés les niveaux non observées dans les données (voir la variable c).\n\nunlabelled(df, drop_unused_labels = TRUE) |> \n  look_for()\n\n pos variable label col_type values\n 1   a        —     dbl            \n 2   b        —     fct      No    \n                             Yes   \n                             DK    \n 3   c        —     fct      No    \n                             Yes   \n 4   d        —     chr            \n 5   e        —     dbl            \n 6   f        —     int            \n 7   g        —     date           \n\nunlabelled(df, levels = \"prefixed\") |> \n  look_for()\n\n pos variable label col_type values \n 1   a        —     dbl             \n 2   b        —     fct      [1] No \n                             [2] Yes\n                             [3] DK \n 3   c        —     fct      [1] No \n                             [2] Yes\n                             [3] DK \n 4   d        —     chr             \n 5   e        —     dbl             \n 6   f        —     int             \n 7   g        —     date"
  },
  {
    "objectID": "manipulation/valeurs-manquantes.html#valeurs-manquantes-étiquettées-tagged-nas",
    "href": "manipulation/valeurs-manquantes.html#valeurs-manquantes-étiquettées-tagged-nas",
    "title": "13  Valeurs manquantes",
    "section": "\n13.1 Valeurs manquantes étiquettées (tagged NAs)",
    "text": "13.1 Valeurs manquantes étiquettées (tagged NAs)\n\n13.1.1 Création et test\nLes tagged NAs sont de véritables valeurs manquantes (NA) au sens de R, auxquelles a été attachées sur étiquette, une lettre unique minuscule (a-z) ou majuscule (A-Z). On peut les créer avec labelled::tagged_na().\n\nx <- c(1:3, tagged_na(\"a\"), tagged_na(\"z\"), NA)\n\nPour la plupart des fonctions de R, les tagged NAs sont juste considérées comme des valeurs manquantes régulières (regumar NAs). Dès lors, par défaut, elles sont justes affichées à l’écran comme n’importe quelle valeur manquante et la fonction is.na() renvoie TRUE.\n\nx\n\n[1]  1  2  3 NA NA NA\n\nis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nPour afficher les étiquettes associées à ces valeurs manquantes, il faut avoir recours à labelled::na_tag(), labelled::print_tagged_na() ou encore labelled::format_tagged_na().\n\nna_tag(x)\n\n[1] NA  NA  NA  \"a\" \"z\" NA \n\nprint_tagged_na(x)\n\n[1]     1     2     3 NA(a) NA(z)    NA\n\nformat_tagged_na(x)\n\n[1] \"    1\" \"    2\" \"    3\" \"NA(a)\" \"NA(z)\" \"   NA\"\n\n\nPour tester si une certaine valeur manquante est une regular NA ou une tagged NA, on aura recours à labelled::is_regular_na() et à labelled::is_tagged_na().\n\nis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE\n\nis_regular_na(x)\n\n[1] FALSE FALSE FALSE FALSE FALSE  TRUE\n\nis_tagged_na(x)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE FALSE\n\n\nIl est possible de tester une étiquette particulière en passant un deuxième argument à labelled::is_tagged_na().\n\nis_tagged_na(x, \"a\")\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE\n\n\n\n\n\n\n\n\nNote\n\n\n\nIl n’est possible de définir des tagged NAs seulement pour des vecteurs numériques (double). Si l’on ajoute une tagged NA à un vecteur d’entiers, ce vecteur sera converti en vecteur numérique. Si on l’ajoute à un vecteur textuel, la valeur manquante sera convertie en regular NA.\n\ny <- c(\"a\", \"b\", tagged_na(\"z\"))\ny\n\n[1] \"a\" \"b\" NA \n\nis_tagged_na(y)\n\n[1] FALSE FALSE FALSE\n\nformat_tagged_na(y)\n\nError: `x` must be a double vector\n\nz <- c(1L, 2L, tagged_na(\"a\"))\ntypeof(z)\n\n[1] \"double\"\n\nformat_tagged_na(z)\n\n[1] \"    1\" \"    2\" \"NA(a)\"\n\n\n\n\n\n13.1.2 Valeurs uniques, doublons et tris\nPar défaut, les fonctions classiques de R unique(), duplicated(), ordered() ou encore sort() traiteront les tagged NAs comme des valeurs manquantes tout ce qu’il y a de plus classique, et ne feront pas de différences entre des tagged NAs ayant des étiquettes différentes.\nPour traiter des tagged NAs ayant des étiquettes différentes comme des valeurs différentes, on aura recours aux fonctions labelled::unique_tagged_na(), labelled::duplicated_tagged_na(), labelled::order_tagged_na() ou encore labelled::sort_tagged_na().\n\nx <- c(1, 2, tagged_na(\"a\"), 1, tagged_na(\"z\"), 2, tagged_na(\"a\"), NA)\nx |> \n  print_tagged_na()\n\n[1]     1     2 NA(a)     1 NA(z)     2 NA(a)    NA\n\nx |> \n  unique() |> \n  print_tagged_na()\n\n[1]     1     2 NA(a)\n\nx |> \n  unique_tagged_na() |> \n  print_tagged_na()\n\n[1]     1     2 NA(a) NA(z)    NA\n\nx |> \n  duplicated()\n\n[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nx |> \n  duplicated_tagged_na()\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE\n\nx |> \n  sort(na.last = TRUE) |> \n  print_tagged_na()\n\n[1]     1     1     2     2 NA(a) NA(z) NA(a)    NA\n\nx |> \n  sort_tagged_na()  |> \n  print_tagged_na()\n\n[1]     1     1     2     2 NA(a) NA(a) NA(z)    NA\n\n\n\n13.1.3 Tagged NAs et étiquettes de valeurs\nIl est tout à fait possible d’associer une étiquette de valeurs (cf. Chapitre 12) à des tagged NAs.\n\nx <- c(\n  1, 0, \n  1, tagged_na(\"r\"), \n  0, tagged_na(\"d\"), \n  tagged_na(\"z\"), NA\n)\nval_labels(x) <- c(\n  no = 0, \n  yes = 1,\n  \"don't know\" = tagged_na(\"d\"),\n  refusal = tagged_na(\"r\")\n)\nx\n\n<labelled<double>[8]>\n[1]     1     0     1 NA(r)     0 NA(d) NA(z)    NA\n\nLabels:\n value      label\n     0         no\n     1        yes\n NA(d) don't know\n NA(r)    refusal\n\n\nLorsqu’un vecteur labellisé est converti en facteur avec labelled::to_factor(), les tagged NAs sont, par défaut convertis en en valeurs manquantes classiques (regular NAs). Il n’est pas possible de définir des tagged NAs pour des facteurs.\n\nx |> to_factor()\n\n[1] yes  no   yes  <NA> no   <NA> <NA> <NA>\nLevels: no yes\n\n\nL’option explicit_tagged_na de labelled::to_factor() permets de convertir les tagged NAs en modalités explicites du facteur.\n\nx |> \n  to_factor(explicit_tagged_na = TRUE)\n\n[1] yes        no         yes        refusal    no         don't know NA(z)     \n[8] <NA>      \nLevels: no yes don't know refusal NA(z)\n\nx |> \n  to_factor(\n    levels = \"prefixed\", \n    explicit_tagged_na = TRUE\n  )\n\n[1] [1] yes            [0] no             [1] yes            [NA(r)] refusal   \n[5] [0] no             [NA(d)] don't know [NA(z)] NA(z)      <NA>              \nLevels: [0] no [1] yes [NA(d)] don't know [NA(r)] refusal [NA(z)] NA(z)\n\n\n\n13.1.4 Conversion en user NAs\nLa fonction labelled::tagged_na_to_user_na() permets de convertir des tagged NAs en user NAs.\n\nx |> \n  tagged_na_to_user_na()\n\n<labelled_spss<double>[8]>\n[1]  1  0  1  3  0  2  4 NA\nMissing range:  [2, 4]\n\nLabels:\n value      label\n     0         no\n     1        yes\n     2 don't know\n     3    refusal\n     4      NA(z)\n\nx |> \n  tagged_na_to_user_na(user_na_start = 10)\n\n<labelled_spss<double>[8]>\n[1]  1  0  1 11  0 10 12 NA\nMissing range:  [10, 12]\n\nLabels:\n value      label\n     0         no\n     1        yes\n    10 don't know\n    11    refusal\n    12      NA(z)\n\n\nLa fonction labelled::tagged_na_to_regular_na() convertit les tagged NAs en valeurs manquantes classiques (regular NAs).\n\nx |> \n  tagged_na_to_regular_na()\n\n<labelled<double>[8]>\n[1]  1  0  1 NA  0 NA NA NA\n\nLabels:\n value label\n     0    no\n     1   yes\n\nx |> \n  tagged_na_to_regular_na() |>\n  is_tagged_na()\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "manipulation/valeurs-manquantes.html#valeurs-manquantes-définies-par-lutilisateurs-user-nas",
    "href": "manipulation/valeurs-manquantes.html#valeurs-manquantes-définies-par-lutilisateurs-user-nas",
    "title": "13  Valeurs manquantes",
    "section": "\n13.2 Valeurs manquantes définies par l’utilisateurs (user NAs)",
    "text": "13.2 Valeurs manquantes définies par l’utilisateurs (user NAs)\nLe package haven a introduit la classe haven_labelled_spss, une extension de la classe haven_labelled permettant d’indiquer des valeurs à considérer comme manquantes à la manière de SPSS.\n\n\n\n\n\n\nImportant\n\n\n\nCela revient à associer à un vecteur des attributs (cf. Chapitre 6) additionnels pour indiquer des valeurs que l’utilisateur pourrait/devrait considérer comme manquante. Cependant, il ne s’agit que de métadonnées et en interne ces valeurs ne sont pas stockées sous forme de NA mais restent des valeurs valides.\nIl convient de garder en mémoire que la très grande majorité des fonctions de R ne prendront pas en compte ces métadonnées et traiteront donc ces valeurs comme des valeurs valides. C’est donc à l’utilisateur de convertir, au besoin, ces les valeurs indiquées comme manquantes en réelles valeurs manquantes (NA).\n\n\n\n13.2.1 Création\nIl est possible d’indiquer des valeurs à considérer comme manquantes (user NAs) de deux manières :\n\nsoit en indiquant une liste de valeurs individuelles avec labelled::na_values() (on peut indiquer NULL pour supprimer les déclarations existantes) ;\nsoit en indiquant deux valeurs représentant une plage de valeurs à considérées comme manquantes avec labelled::na_range() (seront considérées comme manquantes toutes les valeurs supérieures ou égale au premier chiffre et inférieures ou égales au second chiffre1).\n\n1 On peut utiler -Inf et Inf qui représentent respectivement moins l’infini et l’infini.\nv <- c(1, 2, 3, 9, 1, 3, 2, NA)\nval_labels(v) <- c(\n  faible = 1, \n  fort = 3, \n  \"ne sait pas\" = 9\n)\nna_values(v) <- 9\nv\n\n<labelled_spss<double>[8]>\n[1]  1  2  3  9  1  3  2 NA\nMissing values: 9\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\nna_values(v) <- NULL\nv\n\n<labelled<double>[8]>\n[1]  1  2  3  9  1  3  2 NA\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\nna_range(v) <- c(5, Inf)\nv\n\n<labelled_spss<double>[8]>\n[1]  1  2  3  9  1  3  2 NA\nMissing range:  [5, Inf]\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\n\nOn peut noter que les user NAs peuvent cohabiter avec des regular NAs ainsi qu’avec des étiquettes de valeurs (value labels, cf. Chapitre 12).\nPour manipuler les variables d’un tableau de données, on peut également avoir recours à labelled::set_na_values() et labelled::set_na_range().\n\ndf <- \n  dplyr::tibble(\n    s1 = c(\"M\", \"M\", \"F\", \"F\"), \n    s2 = c(1, 1, 2, 9)\n  ) |> \n  set_na_values(s2 = 9)\ndf$s2\n\n<labelled_spss<double>[4]>\n[1] 1 1 2 9\nMissing values: 9\n\ndf <- \n  df |> \n  set_na_values(s2 = NULL)\ndf$s2\n\n<labelled<double>[4]>\n[1] 1 1 2 9\n\n\n\n13.2.2 Tests\nLa fonction is.na() est l’une des rares fonctions de base R à reconnaître les user NAs et donc à renvoyer TRUE dans ce cas. Pour des tests plus spécifiques, on aura recours à labelled::is_user_na() et labelled::is_regular_na().\n\nv\n\n<labelled_spss<double>[8]>\n[1]  1  2  3  9  1  3  2 NA\nMissing range:  [5, Inf]\n\nLabels:\n value       label\n     1      faible\n     3        fort\n     9 ne sait pas\n\nv |> is.na()\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE\n\nv |> is_user_na()\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\nv |> is_regular_na()\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\n\n13.2.3 Conversion\nComme dit précédemment, pour la plupart des fonctions de R, les users NAs sont toujours des valeurs valides.\n\nx <- c(1:5, 11:15)\nna_range(x) <- c(10, Inf)\nx\n\n<labelled_spss<integer>[10]>\n [1]  1  2  3  4  5 11 12 13 14 15\nMissing range:  [10, Inf]\n\nmean(x)\n\n[1] 8\n\n\nOn aura alors recours à labelled::user_na_to_regular_na() pour convertir les users NAs en véritables valeurs manquantes avant de procéder à un calcul statistique.\n\nx |> \n  user_na_to_na()\n\n<labelled<integer>[10]>\n [1]  1  2  3  4  5 NA NA NA NA NA\n\nx |> \n  user_na_to_na() |> \n  mean(na.rm = TRUE)\n\n[1] 3\n\n\nUne alternative consiste à transformer les user NAs en tagged NAs avec labelled::user_na_to_tagged_na().\n\nx |> \n  user_na_to_tagged_na() |> \n  print_tagged_na()\n\n'x' has been converted into a double vector.\n\n\n [1]     1     2     3     4     5 NA(a) NA(b) NA(c) NA(d) NA(e)\n\nx |> \n  user_na_to_tagged_na() |> \n  mean(na.rm = TRUE)\n\n'x' has been converted into a double vector.\n\n\n[1] 3\n\n\nPour supprimer les métadonnées relatives aux user NAs sans les convertir en valeurs manquantes, on aura recours à labelled::remove_user_na().\n\nx |>\n  remove_user_na()\n\n<labelled<integer>[10]>\n [1]  1  2  3  4  5 11 12 13 14 15\n\nx |> \n  remove_user_na() |> \n  mean()\n\n[1] 8\n\n\nEnfin, lorsque l’on convertit un vecteur labellisé en facteur avec labelled::to_factor(), on pourra utiliser l’argument user_na_to_na pour indiquer si les users NAs doivent être convertis ou non en valeurs manquantes classiques (NA).\n\nx <- c(1, 2, 9, 2)\nval_labels(x) <- c(oui = 1, non = 2, refus = 9)\nna_values(x) <- 9\nx |>\n  to_factor(user_na_to_na = TRUE)\n\n[1] oui  non  <NA> non \nLevels: oui non\n\nx |>\n  to_factor(user_na_to_na = FALSE)\n\n[1] oui   non   refus non  \nLevels: oui non refus"
  },
  {
    "objectID": "manipulation/import-export.html#importer-un-fichier-texte",
    "href": "manipulation/import-export.html#importer-un-fichier-texte",
    "title": "14  Import & Export de données",
    "section": "\n14.1 Importer un fichier texte",
    "text": "14.1 Importer un fichier texte\nLes fichiers texte constituent un des formats les plus largement supportés par la majorité des logiciels statistiques. Presque tous permettent d’exporter des données dans un format texte, y compris les tableurs comme Libre Office, Open Office ou Excel.\nCependant, il existe une grande variétés de format texte, qui peuvent prendre différents noms selon les outils, tels que texte tabulé ou texte (séparateur : tabulation), CSV (pour comma-separated value, sachant que suivant les logiciels le séparateur peut être une virgule ou un point-virgule).\n\n14.1.1 Structure d’un fichier texte\nDès lors, avant d’importer un fichier texte dans R, il est indispensable de regarder comment ce dernier est structuré. Il importe de prendre note des éléments suivants :\n\nLa première ligne contient-elle le nom des variables ?\nQuel est le caractère séparateur entre les différentes variables (encore appelé séparateur de champs) ? Dans le cadre d’un fichier CSV, il aurait pu s’agir d’une virgule ou d’un point-virgule.\nQuel est le caractère utilisé pour indiquer les décimales (le séparateur décimal) ? Il s’agit en général d’un point (à l’anglo-saxonne) ou d’une virgule (à la française).\nLes valeurs textuelles sont-elles encadrées par des guillemets et, si oui, s’agit-il de guillements simple (') ou de guillemets doubles (\") ?\nPour les variables textuelles, y a-t-il des valeurs manquantes et si oui comment sont-elles indiquées ? Par exemple, le texte NA est parfois utilisé.\n\nIl ne faut pas hésitez à ouvrir le fichier avec un éditeur de texte pour le regarder de plus près.\n\n14.1.2 Interface graphique avec RStudio\nRStudio fournit une interface graphique pour faciliter l’import d’un fichier texte. Pour cela, il suffit d’aller dans le menu File > Import Dataset et de choisir l’option From CSV1. Cette option est également disponible via l’onglet Environment dans le quadrant haut-droite.1 L’option CSV fonctionne pour tous les fichiers de type texte, même si votre fichier a une autre extension, .txt par exemple\nPour la suite, nous allons utiliser ce fichier texte à titre d’exemple.\n\n\nFigure 14.1: Importer un fichier texte avec RStudio\n\n\nL’interface de RStudio vous présente sous Import Options les différentes options d’import disponible. La section Data Preview vous permet de voir en temps réel comment les données sont importées. La section Code Preview vous indique le code R correspondant à vos choix. Il n’y a plus qu’à le copier/coller dans un de vos scripts ou à cliquer sur Import pour l’exécuter.\nVous pourrez remarquer que RStudio fait appel à l’extension readr du tidyverse pour l’import des données via la fonction readr::read_csv().\nreadr essaie de deviner le type de chacune des colonnes, en se basant sur les premières observations. En cliquant sur le nom d’une colonne, il est possible de modifier le type de la variable importée. Il est également possible d’exclure une colonne de l’import (skip).\n\n14.1.3 Dans un script\nL’interface graphique de RStudio fournit le code d’import. On peut également l’adapter à ces besoins en consultant la page d’aide de readr::read_csv() pour plus de détails. Par exemple :\n\nlibrary(readr)\nd <- read_delim(\n  \"http://larmarange.github.io/analyse-R/data/exemple_texte_tabule.txt\", \n  delim = \"\\t\", \n  quote = \"'\"\n)\n\nOn peut indiquer le chemin local vers un fichier (le plus courant) ou bien directement l’URL d’un fichier sur Internet.\nreadr propose plusieurs fonctions proches : readr::read_delim(), readr::read_csv(), readr::read_csv2() et readr::read_tsv(). Elles fonctionnent toutes de manière identique et ont les mêmes arguments. Seule différence, les valeurs par défaut de certainsparamètres.\n\n\n\n\n\n\nFichiers de très grande taille\n\n\n\nSi vous travaillez sur des données de grandes dimensions, les formats texte peuvent être lents à exporter et importer. Dans ce cas là, on pourra jeter un œil au package vroom et/ou aux fonctions data.table::fread() et data.table::fwrite().\n\n\n\nDans des manuels ou des exemples en ligne, vous trouverez parfois mention des fonctions utils::read.table(), utils::read.csv(), utils::read.csv2(), utils::read.delim() ou encore utils::read.delim2(). Il s’agit des fonctions natives et historiques de R (extension {utils}) dédiées à l’import de fichiers textes. Elles sont similaires à celles de readr dans l’idée générale mais diffèrent dans leurs détails et les traitements effectués sur les données (pas de détection des dates par exemple). Pour plus d’information, vous pouvez vous référer à la page d’aide de ces fonctions."
  },
  {
    "objectID": "manipulation/import-export.html#importer-un-fichier-excel",
    "href": "manipulation/import-export.html#importer-un-fichier-excel",
    "title": "14  Import & Export de données",
    "section": "\n14.2 Importer un fichier Excel",
    "text": "14.2 Importer un fichier Excel\nUne première approche pour importer des données Excel dans R consiste à les exporter depuis Excel dans un fichier texte (texte tabulé ou CSV) puis de suivre la procédure d’importation d’un fichier texte.\nUne feuille Excel peut également être importée directement avec l’extension readxl du tidyverse.\nLa fonction readxl::read_excel() permet d’importer à la fois des fichiers .xls (Excel 2003 et précédents) et .xlsx (Excel 2007 et suivants).\n\nlibrary(readxl)\ndonnees <- read_excel(\"data/fichier.xlsx\")\n\nUne seule feuille de calculs peut être importée à la fois. On pourra préciser la feuille désirée avec sheet en indiquant soit le nom de la feuille, soit sa position (première, seconde, …).\n\ndonnees <- read_excel(\"data/fichier.xlsx\", sheet = 3)\ndonnees <- read_excel(\"data/fichier.xlsx\", sheet = \"mes_donnees\")\n\nOn pourra préciser avec col_names si la première ligne contient le nom des variables.\nPar défaut, readxl::read_excel() va essayer de deviner le type (numérique, textuelle, date) de chaque colonne. Au besoin, on pourra indiquer le type souhaité de chaque colonne avec col_types.\nRStudio propose également pour les fichiers Excel un assitant d’importation, similaire à celui pour les fichiers texte, permettant de faciliter l’import."
  },
  {
    "objectID": "manipulation/import-export.html#importer-depuis-des-logiciels-de-statistique",
    "href": "manipulation/import-export.html#importer-depuis-des-logiciels-de-statistique",
    "title": "14  Import & Export de données",
    "section": "\n14.3 Importer depuis des logiciels de statistique",
    "text": "14.3 Importer depuis des logiciels de statistique\nLe package haven du tidyverse a été développé spécifiquement pour permettre l’importation de données depuis les formats des logiciels Stata, SAS et SPSS.\nIl vise à offrir une importation unifiée depuis ces trois logiciels (là où le package foreign distribué en standard avec R adopte des conventions différentes selon le logiciel source).\nAfin de ne pas perdre d’information lors de l’import, haven a introduit la notion d’étiquettes de variables (cf. Chapitre 11), une classe de vecteurs pour la gestion des étiquettes de valeurs (cf. Chapitre 12), des mécanismes pour reproduire la gestion des valeurs manquantes de ces trois logiciels (cf. Chapitre 13), mais également une gestion et un import correct des dates, dates-heures et des variables horaires (cf. le package hms).\nÀ noter que RStudio intègre égalementg une interface graphique pour l’import des fichiers Stata, SAS et SPSS.\n\n14.3.1 SPSS\nLes fichiers générés par SPSS sont de deux types : les fichiers SPSS natifs (extension .sav) et les fichiers au format SPSS export (extension .por).\nDans les deux cas, on aura recours à la fonction haven::read_spss() :\n\nlibrary(haven)\ndonnees <- read_spss(\"data/fichier.sav\", user_na = TRUE)\n\n\n\n\n\n\n\nValeurs manquantes\n\n\n\nDans SPSS, il est possible de définir des valeurs à considérées comme manquantes ou user NAs, voir Chapitre 13. Par défaut, haven::read_spss() convertir toutes ces valeurs en NA lors de l’import.\nOr, il est parfois important de garder les différentes valeurs originelles. Dans ce cas, on appellera haven::read_spss() avec l’option user_na = TRUE.\n\n\n\n14.3.2 SAS\nLes fichiers SAS se présentent en général sous deux format : format SAS export (extension .xport ou .xpt) ou format SAS natif (extension .sas7bdat).\nLes fichiers SAS natifs peuvent être importées directement avec haven::read_sas() de l’extension haven :\n\nlibrary(haven)\ndonnees <- read_sas(\"data/fichier.sas7bdat\")\n\nAu besoin, on pourra préciser en deuxième argument le nom d’un fichier SAS catalogue (extension .sas7bcat) contenant les métadonnées du fichier de données.\n\nlibrary(haven)\ndonnees <- read_sas(\n  \"data/fichier.sas7bdat\", \n  catalog_file = \"data/fichier.sas7bcat\"\n)\n\n\n\n\n\n\n\nNote\n\n\n\nLes fichiers au format SAS export peuvent être importés via la fonction foreign::read.xport() de l’extension foreign. Celle-ci s’utilise très simplement, en lui passant le nom du fichier en argument :\n\nlibrary(foreign)\ndonnees <- read.xport(\"data/fichier.xpt\")\n\n\n\n\n14.3.3 Stata\nPour les fichiers Stata (extension .dta), on aura recours aux fonctions haven::read_dta() et haven::read_stata() de l’extension haven. Ces deux fonctions sont identiques.\n\nlibrary(haven)\ndonnees <- read_dta(\"data/fichier.dta\")\n\n\n\n\n\n\n\nImportant\n\n\n\nGestion des valeurs manquantes\nDans Stata, il est possible de définir plusieurs types de valeurs manquantes, qui sont notées sous la forme .a à .z. Elles sont importées par haven sous formes de tagged NAs, cf. Chapitre 13.\n\n\n\n14.3.4 dBase\nL’Insee et d’autres producteur de données diffusent leurs fichiers au format dBase (extension .dbf). Ceux-ci sont directement lisibles dans R avec la fonction foreign::read.dbf() de l’extension foreign.\n\nlibrary(foreign)\ndonnees <- read.dbf(\"data/fichier.dbf\")"
  },
  {
    "objectID": "manipulation/import-export.html#sauver-ses-données",
    "href": "manipulation/import-export.html#sauver-ses-données",
    "title": "14  Import & Export de données",
    "section": "\n14.4 Sauver ses données",
    "text": "14.4 Sauver ses données\nR dispose également de son propre format pour sauvegarder et échanger des données. On peut sauver n’importe quel objet créé avec R et il est possible de sauver plusieurs objets dans un même fichier. L’usage est d’utiliser l’extension .RData pour les fichiers de données R. La fonction à utiliser s’appelle tout simplement save().\nPar exemple, si l’on souhaite sauvegarder son tableau de données d ainsi que les objets tailles et poids dans un fichier export.RData :\n\nsave(d, tailles, poids, file = \"export.RData\")\n\nÀ tout moment, il sera toujours possible de recharger ces données en mémoire à l’aide de la fonction load() :\n\nload(\"export.RData\")\n\n\n\n\n\n\n\nMise en garde\n\n\n\nSi entre temps vous aviez modifié votre tableau d, vos modifications seront perdues. En effet, si lors du chargement de données, un objet du même nom existe en mémoire, ce dernier sera remplacé par l’objet importé.\n\n\nLa fonction save.image() est un raccourci pour sauvergarder tous les objets de la session de travail dans le fichier .RData (un fichier un peu étrange car il n’a pas de nom mais juste une extension). Lors de la fermeture de RStudio, il vous sera demandé si vous souhaitez enregistrer votre session. Si vous répondez Oui, c’est cette fonction save.image() qui sera appliquée.\n\nsave.image()\n\nUn autre mécanisme possible est le format RDS de R. La fonction saveRDS() permet de sauvegarder un et un seul objet R dans un fichier.\n\nsaveRDS(d, file = \"mes_donnees.rds\")\n\nCet objet pourra ensuite être lu avec la fonction readRDS(). Mais au lieu d’être directement chargé dans la mémoire de l’environnement de travail, l’objet lu sera retourné par la fonction readRDS() et ce sera à l’utilisateur de le sauvegarder.\n\ndonnees <- readRDS(\"mes_donnees.rds\")"
  },
  {
    "objectID": "manipulation/import-export.html#export-de-tableaux-de-données",
    "href": "manipulation/import-export.html#export-de-tableaux-de-données",
    "title": "14  Import & Export de données",
    "section": "\n14.5 Export de tableaux de données",
    "text": "14.5 Export de tableaux de données\nOn peut avoir besoin d’exporter un tableau de données R vers différents formats. La plupart des fonctions d’import disposent d’un équivalent permettant l’export de données. On citera notamment :\n\n\nreadr::write_csv() et readr::write_tsv() permettent d’exporter au format CSV et texte tabulé respectivement, readr::write_delim() offrant de multiples options pour l’exort au format texte ;\n\nhaven::write_sas() permet d’exporter au format SAS ;\n\n\nhaven::write_sav() au format SPSS ;\n\n\nhaven::write_dta() au format Stata ;\n\n\nforeign::write.dbf() au format dBase.\n\nL’extension readxl ne fournit pas de fonction pour exporter au format Excel. Par contre, on pourra passer par la fonction openxlsx::write.xlsx() du package openxlsx ou la fonction xlsx::write.xlsx() de l’extension xlsx. L’intérêt de openxlsx est de ne pas dépendre de Java à la différence de xlsx."
  },
  {
    "objectID": "manipulation/formater-nombre.html#label_number",
    "href": "manipulation/formater-nombre.html#label_number",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.1 label_number()\n",
    "text": "15.1 label_number()\n\nscales::label_number() est la fonction de base de mise en forme de nombres dans scales, une majorité des autres fonctions faisant appel à scales::label_number() et partageant les mêmes arguments.\nLe paramètre accurary permets de définir le niveau d’arrondi à utiliser. Par exemple, .1 pour afficher une seule décimale. Il est aussi possible d’indiquer un nombre qui n’est pas une puissance de 10 (par exemple .25). Si on n’indique rien (NULL), alors scales::label_number() essaiera de deviner un nombre de décimales pertinent en fonction des valeurs du vecteur de nombres à mettre en forme.\n\nlabel_number(accuracy = NULL)(x)\n\n[1] \"0.00\"         \"0.12\"         \"4.57\"         \"874.44\"       \"8 957 845.00\"\n\nlabel_number(accuracy = .1)(x)\n\n[1] \"0.0\"         \"0.1\"         \"4.6\"         \"874.4\"       \"8 957 845.0\"\n\nlabel_number(accuracy = .25)(x)\n\n[1] \"0.0\"         \"0.0\"         \"4.5\"         \"874.5\"       \"8 957 845.0\"\n\nlabel_number(accuracy = 10)(x)\n\n[1] \"0\"         \"0\"         \"0\"         \"870\"       \"8 957 840\"\n\n\nL’option scale permets d’indiquer un facteur multiplicatif à appliquer avant de mettre en forme. On utilisera le plus souvent les options prefix et suffix en même temps pour indiquer les unités.\n\nlabel_number(scale = 100, suffix = \"%\")(x) # pour cent\n\n[1] \"0%\"           \"12%\"          \"457%\"         \"87 444%\"      \"895 784 500%\"\n\nlabel_number(scale = 1000, suffix = \"\\u2030\")(x) # pour mille\n\n[1] \"2‰\"             \"123‰\"           \"4 567‰\"         \"874 440‰\"      \n[5] \"8 957 845 000‰\"\n\nlabel_number(scale = .001, suffix = \" milliers\", accuracy = .1)(x)\n\n[1] \"0.0 milliers\"     \"0.0 milliers\"     \"0.0 milliers\"     \"0.9 milliers\"    \n[5] \"8 957.8 milliers\"\n\n\nLes arguments decimal.mark et big.mark permettent de définir, respectivement, le séparateur de décimale et le séparateur de milliers. Ainsi, pour afficher des nombres à la française (virgule pour les décimales, espace pour les milliers) :\n\nlabel_number(decimal.mark = \",\", big.mark = \" \")(x)\n\n[1] \"0,00\"         \"0,12\"         \"4,57\"         \"874,44\"       \"8 957 845,00\"\n\n\nNote : il est possible d’utiliser small.interval et small.mark pour ajouter des séparateurs parmi les décimales.\n\nlabel_number(accuracy = 10^-9, small.mark = \"|\", small.interval = 3)(x)\n\n[1] \"0.002|300|000\"         \"0.123|000|000\"         \"4.567|000|000\"        \n[4] \"874.440|000|000\"       \"8 957 845.000|000|000\"\n\n\nLes options style_positive et style_negative permettent de personnaliser la manière dont les valeurs positives et négatives sont mises en forme.\n\ny <- c(-1.2, -0.3, 0, 2.4, 7.2)\nlabel_number(style_positive = \"plus\")(y)\n\n[1] \"-1.2\" \"-0.3\" \"0.0\"  \"+2.4\" \"+7.2\"\n\nlabel_number(style_negative = \"parens\")(y)\n\n[1] \"(1.2)\" \"(0.3)\" \"0.0\"   \"2.4\"   \"7.2\""
  },
  {
    "objectID": "manipulation/formater-nombre.html#les-autres-fonctions-de-scales",
    "href": "manipulation/formater-nombre.html#les-autres-fonctions-de-scales",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.2 Les autres fonctions de {scales}\n",
    "text": "15.2 Les autres fonctions de {scales}\n\n\n15.2.1 label_comma()\n\nscales::label_comma() (et scales::comma()) est une variante de scales::label_number() qui, par défaut, affiche les nombres à l’américaine, avec une virgule comme séparateur de milliers.\n\nlabel_comma()(x)\n\n[1] \"0.00\"         \"0.12\"         \"4.57\"         \"874.44\"       \"8,957,845.00\"\n\n\n\n15.2.2 label_percent()\n\nscales::label_percent() (et scales::percent()) est une variante de scales::label_number() qui affiche les nombres sous formes de pourcentages (les options par défaut sont scale = 100, suffix = \"%\").\n\nlabel_percent()(x)\n\n[1] \"0%\"           \"12%\"          \"457%\"         \"87 444%\"      \"895 784 500%\"\n\n\nOn peut utiliser cette fonction pour afficher des résultats en pour mille (le code unicode du symbole ‰ étant u2030) :\n\nlabel_percent(scale = 1000, suffix = \"\\u2030\")(x)\n\n[1] \"2‰\"             \"123‰\"           \"4 567‰\"         \"874 440‰\"      \n[5] \"8 957 845 000‰\"\n\n\n\n15.2.3 label_dollar()\n\nscales::label_dollar() est adapté à l’affichage des valeurs monétaires.\n\nlabel_dollar()(x)\n\n[1] \"$0\"         \"$0\"         \"$5\"         \"$874\"       \"$8,957,845\"\n\nlabel_dollar(prefix = \"\", suffix = \" €\", accuracy = .01, big.mark = \" \")(x)\n\n[1] \"0.00 €\"         \"0.12 €\"         \"4.57 €\"         \"874.44 €\"      \n[5] \"8 957 845.00 €\"\n\n\nL’option style_negative permet d’afficher les valeurs négatives avec des parenthèses, convention utilisée dans certaines disciplines.\n\nlabel_dollar()(c(12.5, -4, 21, -56.36))\n\n[1] \"$12.50\"  \"-$4.00\"  \"$21.00\"  \"-$56.36\"\n\nlabel_dollar(style_negative = \"parens\")(c(12.5, -4, 21, -56.36))\n\n[1] \"$12.50\"   \"($4.00)\"  \"$21.00\"   \"($56.36)\"\n\n\n\n15.2.4 label_pvalue()\n\nscales::label_pvalue() est adapté pour la mise en forme de p-valeurs.\n\nlabel_pvalue()(c(0.000001, 0.023, 0.098, 0.60, 0.9998))\n\n[1] \"<0.001\" \"0.023\"  \"0.098\"  \"0.600\"  \">0.999\"\n\nlabel_pvalue(accuracy = .01, add_p = TRUE)(c(0.000001, 0.023, 0.098, 0.60))\n\n[1] \"p<0.01\" \"p=0.02\" \"p=0.10\" \"p=0.60\"\n\n\n\n15.2.5 label_number_si()\n\nscales::label_number_si() cherche le préfixe du Système international d’unités le plus proche et arrondi chaque valeur en fonction, en ajoutant la précision correspondante.\n\nlabel_number_si(unit = \"g\")(c(.00000145, .0034, 5, 12478, 14569787))\n\nWarning: `label_number_si()` was deprecated in scales 1.2.0.\nℹ Please use the `scale_cut` argument of `label_number()` instead.\n\n\n[1] \"0.0000 g\" \"0.0034 g\" \"5.0000 g\" \"12 Kg\"    \"15 Mg\"   \n\n\n\n15.2.6 label_scientific()\n\nscales::label_scientific() affiche les nombres dans un format scientifique (avec des puissances de 10).\n\nlabel_scientific(unit = \"g\")(c(.00000145, .0034, 5, 12478, 14569787))\n\n[1] \"1.45e-06\" \"3.40e-03\" \"5.00e+00\" \"1.25e+04\" \"1.46e+07\"\n\n\n\n15.2.7 label_bytes()\n\nscales::label_bytes() mets en forme des tailles exprimées en octets, utilisant au besoin des multiples de 1024.\n\nb <- c(478, 1235468, 546578944897)\nlabel_bytes()(b)\n\n[1] \"478 B\"  \"1 MB\"   \"547 GB\"\n\nlabel_bytes(units = \"auto_binary\")(b)\n\n[1] \"478 iB\"  \"1 MiB\"   \"509 GiB\"\n\n\n\n15.2.8 label_ordinal()\n\nscales::label_bytes() permets d’afficher des rangs ou nombres ordinaux. Plusieurs langues sont disponibles.\n\nlabel_ordinal()(1:5)\n\n[1] \"1st\" \"2nd\" \"3rd\" \"4th\" \"5th\"\n\nlabel_ordinal(rules = ordinal_french())(1:5)\n\n[1] \"1er\" \"2e\"  \"3e\"  \"4e\"  \"5e\" \n\nlabel_ordinal(rules = ordinal_french(gender = \"f\", plural = TRUE))(1:5)\n\n[1] \"1res\" \"2es\"  \"3es\"  \"4es\"  \"5es\" \n\n\n\n15.2.9 label_date(), label_date_short() & label_time()\n\nscales::label_date(), scales::label_date_short() et scales::label_time() peuvent être utilisées pour la mise en forme de dates.\n\nlabel_date()(as.Date(\"2020-02-14\"))\n\n[1] \"2020-02-14\"\n\nlabel_date(format = \"%d/%m/%Y\")(as.Date(\"2020-02-14\"))\n\n[1] \"14/02/2020\"\n\nlabel_date_short()(as.Date(\"2020-02-14\"))\n\n[1] \"14\\nfévr.\\n2020\"\n\n\nLa mise en forme des dates est un peu complexe. Ne pas hésiter à consulter le fichier d’aide de la fonction base::strptime() pour plus d’informations.\n\n15.2.10 label_wrap()\n\nLa fonction scales::label_wrap() est un peu différente. Elle permets d’insérer des retours à la ligne (\\n) dans des chaines de caractères. Elle tient compte des espaces pour identifier les mots et éviter ainsi des coupures au milieu d’un mot.\n\nx <- \"Ceci est un texte assez long et que l'on souhaiterait afficher sur plusieurs lignes. Cependant, on souhaite éviter que des coupures apparaissent au milieu d'un mot.\"\nlabel_wrap(80)(x)\n\n[1] \"Ceci est un texte assez long et que l'on souhaiterait afficher sur plusieurs\\nlignes. Cependant, on souhaite éviter que des coupures apparaissent au milieu\\nd'un mot.\"\n\nlabel_wrap(80)(x) |> message()\n\nCeci est un texte assez long et que l'on souhaiterait afficher sur plusieurs\nlignes. Cependant, on souhaite éviter que des coupures apparaissent au milieu\nd'un mot.\n\nlabel_wrap(40)(x) |> message()\n\nCeci est un texte assez long et que\nl'on souhaiterait afficher sur\nplusieurs lignes. Cependant, on\nsouhaite éviter que des coupures\napparaissent au milieu d'un mot."
  },
  {
    "objectID": "manipulation/formater-nombre.html#les-fonctions-de-formatage-de-gtsummary",
    "href": "manipulation/formater-nombre.html#les-fonctions-de-formatage-de-gtsummary",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.3 Les fonctions de formatage de {gtsummary}\n",
    "text": "15.3 Les fonctions de formatage de {gtsummary}\n\nVéritable couteau-suisse du statisticien, le package gtsummary sera largement utilisé dans les prochains chapitres pour produire des tableaux statistiques prêts à être publiés.\nCe package utilise par défaut ses propres fonctions de formatage mais, au besoin, il sera toujours possible de lui transmettre des fonctions de formatage créées avec scales.\n\n15.3.1 style_number()\n\nFonction de base, gtsummary::style_number() accepte les paramètres big.mark (séparateur de milliers), decimal.mark (séparateur de décimales) et scale (facteur d’échelle). Le nombre de décimales se précisera quant à lui avec digits où l’on indiquera le nombre de décimales souhaité.\n\nlibrary(gtsummary)\n\n#BlackLivesMatter\n\nx <- c(0.123, 0.9, 1.1234, 12.345, -0.123, -0.9, -1.1234, -132.345)\nstyle_number(x, digits = 1)\n\n[1] \"0.1\"    \"0.9\"    \"1.1\"    \"12.3\"   \"-0.1\"   \"-0.9\"   \"-1.1\"   \"-132.3\"\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nNous verrons dans le chapitre sur les statistiques univariées (cf. Section 18.2.1) la fonction gtsummary::theme_gtsummary_language() qui permet de fixer globalement le séparateur de milliers et celui des décimales, afin de changer les valeurs par défaut de l’ensemble des fonctions de formatage de gtsummary.\nIl est important de noter que cela n’a aucun effet sur les fonctions de formatage de scales.\n\n\n\n\n\n\n\n\nMise en garde\n\n\n\ngtsummary::style_number() est directement une fonction de formatage (comme scales::number()) et non une fonction qui générère une fonction de formatage (comme scales::label::number()).\nPour créer une fonction de formatage personnalisée, on pourra avoir recours à purrr::partial() qui permet d’appeller partiellement une fonctio et qui renvoie une nouvelle fonction avec des paramètres par défaut personnalisés.\n\nfr <- style_number |>\n  purrr::partial(decimal.mark = \",\", digits = 1)\nfr(x)\n\n[1] \"0,1\"    \"0,9\"    \"1,1\"    \"12,3\"   \"-0,1\"   \"-0,9\"   \"-1,1\"   \"-132,3\"\n\n\n\n\n\n15.3.2 style_sigfig()\n\nVariante de gtsummary::style_number(), gstummary::style_sigfig() arrondi les valeurs transmises pour n’afficher qu’un nombre choisi de chiffres significatifs. Le nombre de décimales peut ainsi varier.\n\nstyle_sigfig(x)\n\n[1] \"0.12\"  \"0.90\"  \"1.1\"   \"12\"    \"-0.12\" \"-0.90\" \"-1.1\"  \"-132\" \n\nstyle_sigfig(x, digits = 3)\n\n[1] \"0.123\"  \"0.900\"  \"1.12\"   \"12.3\"   \"-0.123\" \"-0.900\" \"-1.12\"  \"-132\"  \n\n\n\n15.3.3 style_percent()\n\nLa fonction gtsummary::style_percent() a un fonctionnement un peu différent de celui de scales::label_percent(). Par défaut, le symbole % n’est pas affiché (mais paramétrable avec symbol = TRUE. Par défaut, une décimale est affichée pour les valeurs inférieures à 10% et aucune pour celles supérieures à 10%. Un symbole < est ajouté devant les valeurs strictement positives inférieures à 0,1%.\n\nv <- c(0, 0.0001, 0.005, 0.01, 0.10, 0.45356, 0.99, 1.45)\nlabel_percent(accuracy = .1)(v)\n\n[1] \"0.0%\"   \"0.0%\"   \"0.5%\"   \"1.0%\"   \"10.0%\"  \"45.4%\"  \"99.0%\"  \"145.0%\"\n\nstyle_percent(v)\n\n[1] \"0\"    \"<0.1\" \"0.5\"  \"1.0\"  \"10\"   \"45\"   \"99\"   \"145\" \n\nstyle_percent(v, symbol = TRUE)\n\n[1] \"0%\"    \"<0.1%\" \"0.5%\"  \"1.0%\"  \"10%\"   \"45%\"   \"99%\"   \"145%\" \n\nstyle_percent(v, digits = 1)\n\n[1] \"0\"     \"0.01\"  \"0.50\"  \"1.00\"  \"10.0\"  \"45.4\"  \"99.0\"  \"145.0\"\n\n\n\n15.3.4 style_pvalue()\n\nLa fonction gtsummary::style_pvalue() est similaire à scales::label_pvalue() mais adapte le nombre de décimales affichées,\n\np <- c(0.000001, 0.023, 0.098, 0.60, 0.9998)\nlabel_pvalue()(p)\n\n[1] \"<0.001\" \"0.023\"  \"0.098\"  \"0.600\"  \">0.999\"\n\nstyle_pvalue(p)\n\n[1] \"<0.001\" \"0.023\"  \"0.10\"   \"0.6\"    \">0.9\"  \n\nstyle_pvalue(p, prepend_p = TRUE)\n\n[1] \"p<0.001\" \"p=0.023\" \"p=0.10\"  \"p=0.6\"   \"p>0.9\"  \n\n\n\n15.3.5 style_ratio()\n\nEnfin, gtsummary::style_ratio() est adaptée à l’affichage de ratios.\n\nr <- c(0.123, 0.9, 1.1234, 12.345, 101.234, -0.123, -0.9, -1.1234, -12.345, -101.234)\nstyle_ratio(r)\n\n [1] \"0.12\"  \"0.90\"  \"1.12\"  \"12.3\"  \"101\"   \"-0.12\" \"-0.90\" \"1.00\"  \"1.00\" \n[10] \"1.00\""
  },
  {
    "objectID": "manipulation/formater-nombre.html#bonus-signif_stars-de-ggstats",
    "href": "manipulation/formater-nombre.html#bonus-signif_stars-de-ggstats",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.4 Bonus : signif_stars() de {ggstats}\n",
    "text": "15.4 Bonus : signif_stars() de {ggstats}\n\nLa fonction ggstats::signif_stars() de ggstats permet d’afficher des p-valeurs sous forme d’étoiles de significativité, Par défaut, trois astérisques si p < 0,001, deux si p < 0,01, une si p < 0,05 et un point si p < 0,10. Les valeurs sont bien sur paramétrables.\n\np <- c(0.5, 0.1, 0.05, 0.01, 0.001)\nggstats::signif_stars(p)\n\n[1] \"\"    \".\"   \"*\"   \"**\"  \"***\"\n\nggstats::signif_stars(p, one = .15, point = NULL)\n\n[1] \"\"    \"*\"   \"*\"   \"**\"  \"***\""
  },
  {
    "objectID": "manipulation/formater-nombre.html#section",
    "href": "manipulation/formater-nombre.html#section",
    "title": "15  Mettre en forme des nombres",
    "section": "\n15.5 ",
    "text": "15.5"
  },
  {
    "objectID": "manipulation/couleurs.html#noms-de-couleur",
    "href": "manipulation/couleurs.html#noms-de-couleur",
    "title": "16  Couleurs & Palettes",
    "section": "\n16.1 Noms de couleur",
    "text": "16.1 Noms de couleur\nLorsque l’on doit indiquer à R une couleur, notamment dans les fonctions graphiques, on peut mentionner certaines couleurs en toutes lettres (en anglais) comme \"red\" ou \"blue\". La liste des couleurs reconnues par R est disponible sur http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf.\n\nlibrary(tidyverse)\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(colour = \"red\", fill = \"blue\")"
  },
  {
    "objectID": "manipulation/couleurs.html#couleurs-rvb-et-code-hexadécimal",
    "href": "manipulation/couleurs.html#couleurs-rvb-et-code-hexadécimal",
    "title": "16  Couleurs & Palettes",
    "section": "\n16.2 Couleurs RVB et code hexadécimal",
    "text": "16.2 Couleurs RVB et code hexadécimal\nEn informatique, les couleurs sont usuellement codées en Rouge/Vert/Bleu (voir https://fr.wikipedia.org/wiki/Rouge_vert_bleu) et représentées par un code hexadécimal à 6 caractères (chiffres 0 à 9 et/ou lettres A à F), précédés du symbole #. Ce code est reconnu par R. On pourra par exemple indiquer \"#FF0000\" pour la couleur rouge ou \"#666666\" pour un gris foncé. Le code hexadécimal des différentes couleurs peut s’obtenir aisément sur internet, de nombreux sites étant consacrés aux palettes de couleurs.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(colour = \"#666666\", fill = \"#FF0000\") \n\n\n\n\n\n\n\nParfois, au lieu du code hexadécimal, les couleurs RVB sont indiquées avec trois chiffres entiers compris entre 0 et 255. La conversion en hexadécimal se fait avec la fonction grDevices::rgb().\n\nrgb(255, 0, 0, maxColorValue = 255)\n\n[1] \"#FF0000\""
  },
  {
    "objectID": "manipulation/couleurs.html#palettes-de-couleurs",
    "href": "manipulation/couleurs.html#palettes-de-couleurs",
    "title": "16  Couleurs & Palettes",
    "section": "\n16.3 Palettes de couleurs",
    "text": "16.3 Palettes de couleurs\n\n16.3.1 Color Brewer\nLe projet Color Brewer a développé des palettes cartographiques, à la fois séquentielles, divergentes et catégorielles, présentées en détail sur http://colorbrewer2.org/. Pour chaque type de palette, et en fonction du nombre de classes, est indiqué sur ce site si la palette est adaptée aux personnes souffrant de daltonisme, si elle est rendra correctement sur écran, en cas d’impression couleur et en cas d’impression en noir et blanc.\nVoici un aperçu des différentes palettes disponibles :\n\n\n\n\n\n\n\n\nL’extension {RColorBrewer} permets d’accéder à ces palettes sous R.\nSi on utilise ggplot2, les palettes Color Brewer sont directement disponibles via les fonctions ggplot2::scale_fill_brewer() et ggplot2::scale_colour_brewer().\n\n\n\n\n\n\nMise en garde\n\n\n\nLes palettes Color Brewer sont seulement implémentées pour des variables catégorielles. Il est cependant possible de les utiliser avec des variables continues en les combinants avec ggplot2::scale_fill_gradientn() ou ggplot2::scale_coulour_gradientn() (en remplaçant \"Set1\" par le nom de la palette désirée) :\n\nscale_fill_gradientn(values = RColorBrewer::brewer.pal(6, \"Set1\"))\n\n\n\n\n16.3.2 Palettes de Paul Tol\nLe physicien Paul Tol a développé plusieurs palettes de couleurs adaptées aux personnes souffrant de déficit de perception des couleurs (daltonisme). À titre personnel, il s’agit des palettes de couleurs que j’utilise le plus fréquemment.\nLe détail de ses travaux est présenté sur https://personal.sron.nl/~pault/.\nLe pacakge khroma implémente ces palettes de couleurs proposées par Paul Tol afin de pouvoir les utilisées directement dans R et avec {ggplot}.\n\nlibrary(khroma)\nplot_scheme(colour(\"bright\")(7), colours = TRUE)\n\n\n\n\n\n\nggplot(mpg) +\n  aes(x = displ, y = hwy, colour = class) +\n  geom_point() +\n  khroma::scale_colour_bright()\n\n\n\n\n\n\n\n\nplot_scheme(colour(\"muted\")(9), colours = TRUE)\n\n\n\n\n\n\n\n\nplot_scheme(colour(\"PRGn\")(9), colours = TRUE, size = 0.9)\n\n\n\n\n\n\n\nPour la liste complète des palettes disponibles, voir https://packages.tesselle.org/khroma/articles/tol.html.\n\n16.3.3 Interface unifiée avec {paletteer}\n\nL’extension paletteer vise à proposer une interface unifiée pour l’utilisation de palettes de couleurs fournies par d’autres packages (dont khroma, mais aussi par exemple ggsci qui fournit les palettes utilisées par certaines revues scientifiques). Plus de 2 500 palettes sont ainsi disponibles.\nOn peut afficher un aperçu des principales palettes disponibles dans paletteer avec la commande suivante :\n\ngt::info_paletteer()\n\nPour afficher la liste complète des palettes discrètes et continues, on utilisera les commandes suivantes :\n\npalettes_d_names |> View()\npalettes_c_names |> View()\n\nLa fonction paletteer::paletteer_d() permet d’obtenir les codes hexadécimaux d’une parlette discrète en précisant le nombre de couleurs attendues. Les fonctions paletteer::scale_color_paletteer_d() et paletteer::scale_fill_paletteer_d() permettront d’utiliser une palette donnée avec ggplot2.\n\nlibrary(paletteer)\npaletteer_d(\"khroma::bright\", n = 5)\n\n<colors>\n#4477AAFF #EE6677FF #228833FF #CCBB44FF #66CCEEFF \n\nggplot(mpg) +\n  aes(x = displ, y = hwy, colour = class) +\n  geom_point() +\n  scale_color_paletteer_d(\"khroma::bright\")\n\n\n\n\n\n\n\nL’équivalent existe pour les palettes continues, avec paletteer::paletteer_c(), paletteer::scale_color_paletteer_c() et paletteer::scale_fill_paletteer_c() .\n\npaletteer_c(\"viridis::viridis\", n = 6)\n\n<colors>\n#440154FF #414487FF #2A788EFF #22A884FF #7AD151FF #FDE725FF \n\nggplot(iris) +\n  aes(x = Sepal.Length, y = Sepal.Width, colour = Petal.Length) +\n  geom_point() +\n  scale_colour_paletteer_c(\"viridis::viridis\", direction = -1)"
  },
  {
    "objectID": "analyses/ggplot2.html#ressources",
    "href": "analyses/ggplot2.html#ressources",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.1 Ressources",
    "text": "17.1 Ressources\nIl existe de très nombreuses ressources traitant de ggplot2.\nPour une introduction en français, on pourra se référer au chapitre Visualiser avec ggplot2 de l’Introduction à R et au tidyverse de Julien Barnier, au chapitre Introduction à ggplot2, la grammaire des graphiques du site analyse-R et adapté d’une séance de cours de François Briatte, ou encore au chapitre Graphiques du cours Logiciel R et programmation d’Ewen Gallic.\nPour les anglophones, la référence reste encore l’ouvrage ggplot2: Elegant Graphics for Data Analysis d’Hadley Wickham lui-même, dont la troisième édition est librement accessible en ligne (https://ggplot2-book.org/). D’un point de vue pratique, l’ouvrage R Graphics Cookbook: practical recipes for visualizing data de Winston Chang est une mine d’informations, ouvrage là encore librement accessible en ligne (https://r-graphics.org/)."
  },
  {
    "objectID": "analyses/ggplot2.html#les-bases-de-ggplot2",
    "href": "analyses/ggplot2.html#les-bases-de-ggplot2",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.2 Les bases de ggplot2\n",
    "text": "17.2 Les bases de ggplot2\n\nggplot2 nécessite que les données du graphique soient sous la forme d’un tableau de données (data.frame ou tibble) au format tidy, c’est-à-dire avec une ligne par observation et les différentes valeurs à représenter sous forme de variables du tableau.\n\n\nFigure 17.1: La grammaire des graphiques\n\n\nTous les graphiques avec ggplot2 suivent une même logique. En premier lieu, on appelera la fonction ggplot2::ggplot() en lui passant en paramètre le fichier de données.\nggplot2 nomme esthétiques les différentes propriétés visuelles d’un graphique, à savoir l’axe des x (x), celui des y (y), la couleur des lignes (colour), celle de remplissage des polygones (fill), le type de lignes (linetype), la forme des points (shape), etc. Une représentation graphique consiste donc à représenter chacune de nos variables d’intérêt selon une esthétique donnée. En second lieu, on appelera donc la fonction ggplot2::aes() pour indiquer la correspondance entre les variables de notre fichier de données et les esthétiques du graphique.\nA minima, il est nécessaire d’indiquer en troisième lieu une géométrie, autrement dit la manière dont les éléments seront représentés visuellement. À chaque géométrie corresponds une fonction commençant par geom_, par exemple ggplot2::geom_point() pour dessiner des points, ggplot2::geom_line() pour des lignes, ggplot2::geom_bar() pour des barres ou encore ggplot2::geom_area() pour des aires. Il existe de nombreuses géométries différentes1, chacune prenant en compte certaines esthétiques, certaines étant requises pour cette géométrie et d’autres optionnelles. La liste des esthétiques prises en compte par chaque géométrie est indiquée dans l’aide en ligne de cette dernière.1 On trouvera une liste dans la cheat sheet de ggplot2, voir Section 17.3.\nVoici un exemple minimal de graphique avec ggplot2 :\n\nlibrary(ggplot2)\np <- \n  ggplot(iris) +\n  aes(\n    x = Petal.Length, \n    y = Petal.Width, \n    colour = Species\n  ) +\n  geom_point()\np\n\n\n\nFigure 17.2: Un exemple simple de nuage de points avec ggplot2\n\n\n\n\n\n\n\n\n\n\nSyntaxe additive\n\n\n\nLe développement de ggplot2 a débuté avant celui du tidyverse et la généralisation du pipe. Dès lors, on ne sera pas étonné que la syntaxe de ggplot2 n’ait pas recours à ce dernier mais repose sur une approche additive. Un graphique est dès lors initialisé avec la fonction ggplot2::ggplot() et l’on ajoutera successivement des éléments au graphique en appelant différentes fonctions et en utilisant l’opérateur +.\n\n\nIl est ensuite possible de personnaliser de nombreux éléments d’un graphique et notamment :\n\nles étiquettes ou labs (titre, axes, légendes) avec ggplot2::ggtitle(), ggplot2::xlab(), ggplot2::ylab() ou encore la fonction plus générique ggplot2::labs() ;\nles échelles (scales) des différentes esthétiques avec les fonctions commençant par scale_ ;\nle système de coordonnées avec les fonctions commençant par coord_ ;\nles facettes (facets) avec les fonctions commençant par facet_ ;\nla légende (guides) avec les fonctions commençant par guide_ ;\nle thème du graphiques (mise en forme des différents éléments) avec ggplot2::theme().\n\n\np +\n  labs(\n    x = \"Longueur du pétale\",\n    y = \"Largeur du pétale\",\n    colour = \"Espèce\"\n  ) +\n  ggtitle(\n    \"Relation entre longueur et largeur des pétales\",\n    subtitle = \"Jeu de données Iris\"\n  ) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_y_continuous(\n    labels = scales::label_number(decimal.mark = \",\")\n  ) +\n  coord_equal() +\n  facet_grid(cols = vars(Species)) +\n  guides(\n    color = guide_legend(nrow = 2)\n  ) +\n  theme_light() +\n  theme(\n    legend.position = \"bottom\",\n    axis.title = element_text(face = \"bold\")\n  )\n\n\n\nFigure 17.3: Un exemple avancé de nuage de points avec ggplot2\n\n\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code."
  },
  {
    "objectID": "analyses/ggplot2.html#sec-cheatsheet-ggplot2",
    "href": "analyses/ggplot2.html#sec-cheatsheet-ggplot2",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.3 Cheatsheet",
    "text": "17.3 Cheatsheet\n\n\nFigure 17.4: Cheatsheet ggplot2"
  },
  {
    "objectID": "analyses/ggplot2.html#sec-esquisse",
    "href": "analyses/ggplot2.html#sec-esquisse",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.4 Exploration visuelle avec esquisse\n",
    "text": "17.4 Exploration visuelle avec esquisse\n\nLe package esquisse propose un addin offrant une interface visuelle pour la création de graphiques ggplot2. Après installation du package, on pourra lancer esquisse directement à partir du menu addins de RStudio.\n\n\nFigure 17.5: Lancement d’esquisse à partir du menu Addins de RStudio\n\n\nAu lancement de l’addin, une interface permettra de choisir le tableau de données à partir duquel générer le graphique. Le plus simple est de choisir un tableau présent dans l’environnement. Mais esquisse offre aussi la possibilité d’importer des fichiers externes, voir de procéder à quelques modificatiosn des données.\n\n\nFigure 17.6: Import de données au lancement d’esquisse\n\n\nLe principe général d’esquisse consiste à associer des variables à des esthétiques par glisser/déposer2. L’outil déterminera automatiquement une géométrie adaptée en fonction de la nature des variables (continues ou catgéorielles). Un clic sur le nom de la géométrie en haut à gauche permet de sélectionner une autre géométrie.2 Si une esthétique n’est pas visible à l’écran, on pourra cliquer en haut à droite sur l’icône en forme de roue dentée afin de choisir d’afficher plus d’esthétiques.\n\n\nFigure 17.7: Choix d’une géométrie dans esquisse\n\n\nLes menus situés en bas de l’écran permettent d’ajouter/modifier des étiquettes, de modifier certaines options du graphiques, de modifier les échelles de couleurs et l’apparence du graphique, et de filtrer les observations inclues dans le graphique.\nLe menu Code permet de récupérer le code correspondant au graphique afin de pouvoir le copier/coller dans un script.\n\n\nFigure 17.8: Obtenir le code du graphique obtenu avec esquisse\n\n\nesquisse offre également la possibilité d’exporter le graphique obtenu dans différents formats."
  },
  {
    "objectID": "analyses/ggplot2.html#webin-r",
    "href": "analyses/ggplot2.html#webin-r",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.5 webin-R",
    "text": "17.5 webin-R\nL’utilisation d’esquisse est présentée dans le webin-R #03 (statistiques descriptives avec gtsummary et esquisse) sur YouTube.\n\nggplot2 est abordé plus en détails dans le webin-R #08 (ggplot2 et la grammaire des graphiques) sur YouTube."
  },
  {
    "objectID": "analyses/ggplot2.html#combiner-plusieurs-graphiques",
    "href": "analyses/ggplot2.html#combiner-plusieurs-graphiques",
    "title": "17  Graphiques avec ggplot2",
    "section": "\n17.6 Combiner plusieurs graphiques",
    "text": "17.6 Combiner plusieurs graphiques\nPlusieurs packages proposent des fonctions pour combiner ensemble des graphiques ggplot2, comme patchwork, ggpubr, {egg} ou cowplot. Ici, nous privilégierons le package patchwork car, bien qu’il ne fasse pas partie du tidyverse, est développé et maintenant par les mêmes auteurs que ggplot2.\nCommençons par créer quelques graphiques avec ggplot2.\n\np1 <- ggplot(mtcars) +\n  aes(x = wt, y = mpg) + \n  geom_point()\np2 <- ggplot(mtcars) +\n  aes(x = factor(cyl)) +\n  geom_bar()\np3 <- ggplot(mtcars) +\n  aes(x = factor(cyl), y = mpg) +\n  geom_violin() +\n  theme(axis.title = element_text(size = 20))\np4 <- ggplot(mtcars) +\n  aes(x = factor(cyl), y = mpg) + \n  geom_boxplot() +\n  ylab(NULL)\n\nLe symbole + permet de combiner des graphiques entre eux. Le package patchwork déterminera le nombre de lignes et de colonnes en fonction du nombre de graphiques. On pourra noter que les axes des graphiques sont alignés les uns par rapports aux autres.\n\nlibrary(patchwork)\np1 + p2 + p3 + p4\n\n\n\n\n\n\n\nLes symboles | et / permettent d’indiquer une disposition côte à côte ou les uns au-dessus des autres.\n\np1 | p2 | p3\n\n\n\n\n\n\n\n\np1 / p2\n\n\n\n\n\n\n\nOn peut utiliser les parenthèses pour indiquer des arrangements plus complexes.\n\n(p1 + p2) / p3\n\n\n\n\n\n\n\n\n(p1 + p2) | p3\n\n\n\n\n\n\n\nSi l’on a une liste de graphiques, on pourra appeler patchwork::wrap_plots().\n\nlist(p1, p2, p3, p4) |> \n  wrap_plots()\n\n\n\n\n\n\n\nLa fonction patchwork::plot_layout() permet de controler les hauteurs / largeurs relatives des lignes / colonnes.\n\np1 + p2 + p3 + p4 + plot_layout(widths = c(2, 1))\n\n\n\n\n\n\n\nOn peut également ajouter un titre ou des étiquettes avec patchwork::plot_annotation().\n\np1 + p2 + p3 + p4 +\n  plot_annotation(\n    title = \"Titre du graphique\",\n    subtitle = \"sous-titre\",\n    caption = \"notes additionelles\",\n    tag_levels = \"a\",\n    tag_suffix = \".\"\n  )"
  },
  {
    "objectID": "analyses/statistique-univariee.html#exploration-graphique",
    "href": "analyses/statistique-univariee.html#exploration-graphique",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.1 Exploration graphique",
    "text": "18.1 Exploration graphique\nUne première approche consiste à explorer visuelle la variable d’intérêt, notamment à l’aide de l’interface proposée par esquisse (cf Section 17.4).\nNous indiquons ci-après le code correspond aux graphiques ggplot2 les plus courants.\n\nlibrary(ggplot2)\n\n\n18.1.1 Variable continue\nUn histogramme est la représentation graphique la plus commune pour représenter la distribution d’une variable, par exemple ici la longueur des pétales (variable Petal.Length) du fichier de données datasets::iris. Il s’obtient avec la géométrie ggplot2::geom_histogram().\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nFigure 18.1: un histogramme simple\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nIl faut noter qu’il nous a suffit d’associer simplement la variable Petal.Length à l’esthétique x, sans avoir eu besoin d’indiquer une variable pour l’esthétique y.\nEn fait, ggplot2 associe par défaut à toute géométrie une certaine statistique. Dans le cas de ggplot2::geom_histogram(), il s’agit de la statistique ggplot2::stat_bin() qui divise la variable continue en classes de même largeur et compte le nombre d’observation dans chacunes. ggplot2::stat_bin() renvoie un certain nombre de variables calculées (la liste complète est indiquée dans la documentation dans la section Compute variables), dont la variable count qui correspond au nombre d’observations la classe. On peut associer cette variable calculée à une esthétique grace à la fonction ggplot2::after_stat(), par exemple aes(y = after_stat(count)). Dans le cas présent, ce n’est pas nécessaire car ggplot2 fait cette association automatiquement si l’on n’a pas déjà attribué une variable à l’esthétique y.\n\n\nOn peut personnaliser la couleur de remplissage des rectangles en indiquant une valeur fixe pour l’esthétique fill dans l’appel de ggplot2::geom_histogram() (et non via la fonction ggplot2::aes() puisqu’il ne s’agit pas d’une variable du tableau de données). L’esthétique colour permet de spécifier la couleur du trait des rectangles. Enfin, le paramètre binwidth permet de spécifier la largeur des barres.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(\n    fill =\"lightblue\", \n    colour = \"black\", \n    binwidth = 1\n  ) +\n  xlab(\"Longeur du pétale\") +\n  ylab(\"Effectifs\")\n\n\n\nFigure 18.2: un histogramme personnalisé\n\n\n\n\nOn peut alternativement indiquer un nombre de classes avec bins.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_histogram(bins = 10, colour = \"black\")\n\n\n\nFigure 18.3: un histogramme en 10 classes\n\n\n\n\nUne représentation alternative de la distribution d’une variable peut être obtenue avec une courbe de densité, dont la particularité est d’avoir une surface sous la courbe égale à 1. Une telle courbe s’obtient avec ggplot2::geom_density(). Le paramètre adjust permet d’ajuster le niveau de lissage de la courbe.\n\nggplot(iris) +\n  aes(x = Petal.Length) +\n  geom_density(adjust = .5)\n\n\n\nFigure 18.4: une courbe de densité\n\n\n\n\n\n18.1.2 Variable catégorielle\nPour représenter la répartition des effectifs parmi les modalités d’une variable catégorielle, on a souvent tendance à utiliser des diagrammes en secteurs (camemberts). Or, ce type de représentation graphique est très rarement appropriée : l’oeil humain préfère comparer des longueurs plutôt que des surfaces1.1 Voir en particulier https://www.data-to-viz.com/caveat/pie.html pour un exemple concret.\nDans certains contextes ou pour certaines présentations, on pourra éventuellement considérer un diagramme en donut, mais le plus souvent, rien ne vaut un bon vieux diagramme en barres avec ggplot2::geom_bar(). Prenons pour l’exemple la variable occup du jeu de données hdv2003 du package questionr.\n\ndata(\"hdv2003\", package = \"questionr\")\nggplot(hdv2003) +\n  aes(x = occup) +\n  geom_bar()\n\n\n\nFigure 18.5: un diagramme en barres simple\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLà encore, ggplot2 a calculé de lui-même le nombre d’observations de chaque modalité, en utilisant cette fois la statistique ggplot2::stat_count().\n\n\nSi l’on souhaite représenter des pourcentages plutôt que des effectifs, le plus simple est d’avoir recours à la statistique ggstats::stat_prop() du package ggstats2. Pour appeler cette statistique, on utilisera simplement stat = \"prop\" dans les géométries concernées.2 Cette statistique est également disponible via le package GGally.\nCette statistique, qui sera également bien utile pour des graphiques plus complexes, nécessite qu’on lui indique une esthétique by pour dans quels sous-groupes calculés des proportions. Ici, nous avons un seul groupe considéré et nous souhaitons des pourcentages du total. On indiquera simplement by = 1.\nPour formater l’axe vertical avec des pourcentages, on pourra avoir recours à la fonction scales::label_percent() que l’on appelera via ggplot2::scale_y_continuous().\n\nlibrary(ggstats)\nggplot(hdv2003) +\n  aes(x = occup, y = after_stat(prop), by = 1) +\n  geom_bar(stat = \"prop\") +\n  scale_y_continuous(labels = scales::label_percent())\n\n\n\nFigure 18.6: un diagramme en barres épuré\n\n\n\n\nPour une publication ou une communication, il ne faut surtout pas hésiter à épurer vos graphiques (less is better!), voire à trier les modalités en fonction de leur fréquence pour faciliter la lecture (ce qui se fait aisément avec forcats::fct_infreq()).\n\nggplot(hdv2003) +\n  aes(x = forcats::fct_infreq(occup), \n      y = after_stat(prop), by = 1) +\n  geom_bar(stat = \"prop\", \n           fill = \"#4477AA\", colour = \"black\") +\n  geom_text(\n    aes(label = after_stat(prop) |> \n          scales::percent(accuracy = .1)),\n    stat = \"prop\",\n    nudge_y = .02\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    axis.text.y = element_blank()\n  ) +\n  xlab(NULL) + ylab(NULL) +\n  ggtitle(\"Occupation des personnes enquêtées\")\n\n\n\nFigure 18.7: un diagramme en barres épuré\n\n\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code."
  },
  {
    "objectID": "analyses/statistique-univariee.html#sec-tri-a-plat",
    "href": "analyses/statistique-univariee.html#sec-tri-a-plat",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.2 Tableaux et tris à plat",
    "text": "18.2 Tableaux et tris à plat\nLe package gtsummary constitue l’une des boites à outils de l’analyste quantitativiste, car il permet de réaliser très facilement des tableaux quasiment publiables en l’état. En matière de statistique univarisée, la fonction clé est gtsummary::tbl_summary().\nCommençons avec un premier exemple rapide. On part d’un tableau de données et on indique, avec l’argument include, les variables à afficher dans le tableau statistique (si on n’indique rien, toutes les variables du tableau de données sont considérées). Il faut noter que l’argument include de gtsummary::tbl_summary() utilise la même syntaxe dite tidy select que dplyr::select() (cf. Section 8.2.1). On peut indiquer tout autant des variables catégorielles que des variables continues.\n\nlibrary(gtsummary)\nhdv2003 |> \n  tbl_summary(include = c(age, occup))\n\n\n\n\n\n\n\n  \n  \nCharacteristic\n      \nN = 2,0001\n\n    \n\n\nage\n48 (35, 60)\n\n\noccup\n\n\n\n    Exerce une profession\n1,049 (52%)\n\n\n    Chomeur\n134 (6.7%)\n\n\n    Etudiant, eleve\n94 (4.7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3.9%)\n\n\n    Au foyer\n171 (8.6%)\n\n\n    Autre inactif\n83 (4.2%)\n\n\n\n\n1 Median (IQR); n (%)\n    \n\nTable 18.1:  un tableau simple \n\n\n\n\n\n\n\n\n\nRemarque sur les types de variables et les sélecteurs associés\n\n\n\ngtsummary permets de réaliser des tableaux statistiques combinant plusieurs variables, l’affichage des résultats pouvant dépendre du type de variables.\nPar défaut, gtsummary considère qu’une variable est catégorielle s’il s’agit d’un facteur, d’une variable textuelle ou d’une variable numérique ayant moins de 10 valeurs différentes.\nUne variable sera considérée comme dichotomique (variable catégorielle à seulement deux modalités) s’il s’agit d’un vecteur logique (TRUE/FALSE), d’une variable textuelle codée yes/no ou d’une variable numérique codée 0/1.\nDans les autres cas, une variable numérique sera considérée comme continue.\nSi vous utilisez des vecteurs labellisés (cf. Chapitre 12), vous devez les convertir, en amont, en facteurs ou en variables numériques. Voir l’extension labelled et les fonctions labelled::to_factor(), labelled::unlabelled() et unclass().\nAu besoin, il est possible de forcer le type d’une variable avec l’argument type de gtsummary::tbl_summary().\ngtsummary fournit des sélecteurs qui peuvent être utilisés dans les options des différentes fonctions, en particulier gtsummary::all_continuous() pour les variables continues, gtsummary::all_dichotolous() pour les variables dichotomiques et gtsummary::all_categorical() pour les variables catégorielles. Cela inclue les variables dichotomiques. Il faut utiliser all_categorical(dichotomous = FALSE) pour sélectionner les variables catégorielles en excluant les variables dichotomiques.\n\n\n\n18.2.1 Thème du tableau\ngtsummary fournit plusieurs fonctions préfixées theme_gtsummary_*() permettant de modifier l’affichage par défaut des tableaux. Vous aurez notez que, par défaut, gtsummary est anglophone.\nLa fonction gtsummary::theme_gtsummary_journal() permets d’adopter les standards de certaines grandes revues scientifiques telles que JAMA (Journal of the American Medical Association), The Lancet ou encore le NEJM (New England Journal of Medicine).\nLa fonction gtsummary::theme_gtsummary_language() permet de modifier la langue utilisée par défaut dans les tableaux. Les options decimal.mark et big.mark permettent de définir respectivement le séparateur de décimales et le séparateur des milliers. Ainsi, pour présenter un tableau en français, on appliquera en début de script :\n\ntheme_gtsummary_language(\n  language = \"fr\", \n  decimal.mark = \",\", \n  big.mark = \" \"\n)\n\nSetting theme `language: fr`\n\n\nCe thème sera appliqué à tous les tableaux ultérieurs.\n\nhdv2003 |> \n  tbl_summary(include = c(age, occup))\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nage\n48 (35 – 60)\n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\n\n1 Médiane (EI); n (%)\n    \n\nTable 18.2:  un tableau simple en français \n\n\n\n\n18.2.2 Étiquettes des variables\ngtsummary, par défaut, prends en compte les étiquettes de variables (cf. Chapitre 11), si elles existent, et sinon utilisera le nom de chaque variable dans le tableau. Pour rappel, les étiquettes de variables peuvent être manipulées avec l’extension labelled et les fonctions labelled::var_label() et labelled::set_variable_labels().\nIl est aussi possible d’utiliser l’option label de gtsummary::tbl_summary() pour indiquer des étiquettes personnalisées.\n\nhdv2003 |> \n  labelled::set_variable_labels(\n    occup = \"Occupation actuelle\"\n  ) |> \n  tbl_summary(\n    include = c(age, occup, heures.tv),\n    label = list(age ~ \"Âge médian\")\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nÂge médian\n48 (35 – 60)\n\n\nOccupation actuelle\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n\n\n    Manquant\n5\n\n\n\n\n1 Médiane (EI); n (%)\n    \n\nTable 18.3:  un tableau étiquetté \n\n\n\nPour modifier les modalités d’une variable catégorielle, il faut modifier en amont les niveaux du facteur correspondant.\n\n\n\n\n\n\nRemarque sur la syntaxe des options\n\n\n\nDe nombreuses options des fonctions de gtsummary peuvent s’appliquer seulement à une ou certaines variables. Pour ces options-là, gtsummary attends une formule de la forme variables concernées ~ valeur de l'option ou bien une liste de formules ayant cette forme.\nPar exemple, pour modifier l’étiquette associée à une certaine variable, on peut utiliser l’option label de gtsummary::tbl_summary().\n\ntrial |> \n  tbl_summary(label = age ~ \"Âge\")\n\nLorsque l’on souhaite passer plusieurs options pour plusieurs variables différentes, on utilisera une list().\n\ntrial |> \n  tbl_summary(label = list(age ~ \"Âge\", trt ~ \"Traitement\"))\n\ngtsummary est très flexible sur la manière d’indiquer la ou les variables concernées. Il peut s’agir du nom de la variable, d’une chaîne de caractères contenant le nom de la variable, ou d’un vecteur contenant le nom de la variable. Les syntaxes ci-dessous sont ainsi équivalentes.\n\ntrial |> \n  tbl_summary(label = age ~ \"Âge\")\ntrial |> \n  tbl_summary(label = \"age\" ~ \"Âge\")\nv <- \"age\"\ntrial |> \n  tbl_summary(label = v ~ \"Âge\")\n\nPour appliquer le même changement à plusieurs variables, plusieurs syntaxes sont acceptées pour lister plusieurs variables.\n\ntrial |> \n  tbl_summary(label = c(\"age\", \"trt\") ~ \"Une même étiquette\")\ntrial |> \n  tbl_summary(label = c(age, trt) ~ \"Une même étiquette\")\n\nIl est également possible d’utiliser la syntaxe tidyselect et les sélecteurs de tidyselect comme tidyselect::everything(), tidyselect::starts_with(), tidyselect::contains() ou tidyselect::all_of(). Ces différents sélecteurs peuvent être combinés au sein d’un c().\n\ntrial |> \n  tbl_summary(\n    label = everything() ~ \"Une même étiquette\"\n  )\ntrial |> \n  tbl_summary(\n    label = starts_with(\"a\") ~ \"Une même étiquette\"\n  )\ntrial |> \n  tbl_summary(\n    label = c(everything(), -age, -trt) ~ \"Une même étiquette\"\n  )\ntrial |> \n  tbl_summary(\n    label = age:trt ~ \"Une même étiquette\"\n  )\n\nBien sûr, il est possible d’utiliser les sélecteurs propres à gtsummary.\n\ntrial |> \n  tbl_summary(\n    label = all_continuous() ~ \"Une même étiquette\"\n  )\ntrial |> \n  tbl_summary(\n    label = list(\n      all_continuous() ~ \"Variable continue\",\n      all_dichotomous() ~ \"Variable dichotomique\",\n      all_categorical(dichotomous = FALSE) ~ \"Variable catégorielle\"\n    )\n  )\n\nEnfin, si l’on ne précise rien à gauche du ~, ce sera considéré comme équivalent à everything(). Les deux syntaxes ci-dessous sont donc équivalentes.\n\ntrial |> \n  tbl_summary(label = ~ \"Une même étiquette\")\ntrial |> \n  tbl_summary(\n    label = everything() ~ \"Une même étiquette\"\n  )\n\n\n\n\n18.2.3 Statistiques affichées\nLe paramètre statistic permets de sélectionner les statistiques à afficher pour chaque variable. On indiquera une chaîne de caractères dont les différentes statistiques seront indiquées entre accolades ({}).\nPour une variable continue, on pourra utiliser {median} pour la médiane, {mean} pour la moyenne, {sd} pour l’écart type, {var} pour la variance, {min} pour le minimum, {max} pour le maximum, ou encore {p##} (en remplacant ## par un nombre entier entre 00 et 100) pour le percentile correspondant (par exemple p25 et p75 pour le premier et le troisième quartile). Utilisez gtsummary::all_continous() pour sélectionner toutes les variables continues.\n\nhdv2003 |>\n  tbl_summary(\n    include = c(age, heures.tv),\n    statistic = \n      all_continuous() ~ \"Moy. : {mean} [min-max : {min} - {max}]\"\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nage\nMoy. : 48 [min-max : 18 - 97]\n\n\nheures.tv\nMoy. : 2,25 [min-max : 0,00 - 12,00]\n\n\n    Manquant\n5\n\n\n\n\n1 Moy. : Moyenne [min-max : Étendue]\n    \n\nTable 18.4:  statisques personnalisées pour une variable continue \n\n\n\nIl est possible d’afficher des statistiques différentes pour chaque variable.\n\nhdv2003 |>\n  tbl_summary(\n    include = c(age, heures.tv),\n    statistic = list(\n      age ~ \"Méd. : {median} [{p25} - {p75}]\",\n      heures.tv ~ \"Moy. : {mean} ({sd})\"\n    )\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nage\nMéd. : 48 [35 - 60]\n\n\nheures.tv\nMoy. : 2,25 (1,78)\n\n\n    Manquant\n5\n\n\n\n\n1 Méd. : Médiane [EI]; Moy. : Moyenne (ET)\n    \n\nTable 18.5:  statisques personnalisées pour une variable continue (2) \n\n\n\nPour les variables continues, il est également possible d’indiquer le nom d’une fonction personnalisée qui prends un vecteur et renvoie une valeur résumée. Par exemple, pour afficher la moyenne des carrés :\n\nmoy_carres <- function(x) {\n  mean(x^2, na.rm = TRUE)\n}\nhdv2003 |>\n  tbl_summary(\n    include = heures.tv,\n    statistic = ~ \"MC : {moy_carres}\"\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nheures.tv\nMC : 8,20\n\n\n    Manquant\n5\n\n\n\n\n1 MC : moy_carres\n    \n\nTable 18.6:  statisques personnalisées pour une variable continue (3) \n\n\n\nPour une variable catégorielle, les statistiques possibles sont {n} le nombre d’observations, {N} le nombre total d’observations, et {p} le pourcentage correspondant. Utilisez gtsummary::all_categorical() pour sélectionner toutes les variables catégorielles.\n\nhdv2003 |>\n  tbl_summary(\n    include = occup,\n    statistic = all_categorical() ~ \"{p} % ({n}/{N})\"\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\noccup\n\n\n\n    Exerce une profession\n52 % (1 049/2 000)\n\n\n    Chomeur\n6,7 % (134/2 000)\n\n\n    Etudiant, eleve\n4,7 % (94/2 000)\n\n\n    Retraite\n20 % (392/2 000)\n\n\n    Retire des affaires\n3,9 % (77/2 000)\n\n\n    Au foyer\n8,6 % (171/2 000)\n\n\n    Autre inactif\n4,2 % (83/2 000)\n\n\n\n\n1 % % (n/N)\n    \n\nTable 18.7:  statisques personnalisées pour une variable catégorielle \n\n\n\nIl est possible, pour une variable catégorielle, de trier les modalités de la plus fréquente à la moins fréquente avec le paramètre sort.\n\nhdv2003 |>\n  tbl_summary(\n    include = occup,\n    sort = all_categorical() ~ \"frequency\"\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Retraite\n392 (20%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n\n\n1 n (%)\n    \n\nTable 18.8:  variable catégorielle triée par fréquence \n\n\n\nPour toutes les variables (catégorielles et continues), les statistiques suivantes sont également disponibles :\n\n\n{N_obs} le nombre total d’observations,\n\n{N_miss} le nombre d’observations manquantes (NA),\n\n{N_nonmiss} le nombre d’observations non manquantes,\n\n{p_miss} le pourcentage d’observations manquantes (i.e. N_miss / N_obs) et\n\n{p_nonmiss} le pourcentage d’observations non manquantes (i.e. N_nonmiss / N_obs).\n\n18.2.4 Affichage du nom des statistiques\nLorsque l’on affiche de multiples statistiques, la liste des statistiques est regroupée dans une note de tableau qui peut vite devenir un peu confuse.\n\ntbl <- hdv2003 |>\n  tbl_summary(\n    include = c(age, heures.tv, occup),\n    statistic = list(\n      age ~ \"{mean} ({sd})\",\n      heures.tv ~ \"{median} [{p25} - {p75}]\"\n    )\n  )\ntbl\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nage\n48 (17)\n\n\nheures.tv\n2,00 [1,00 - 3,00]\n\n\n    Manquant\n5\n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\n\n1 Moyenne (ET); Médiane [EI]; n (%)\n    \n\nTable 18.9:  tableau par défaut \n\n\n\nLa fonction gtsummary::add_stat_label() permets d’indiquer le type de statistique à côté du nom des variables ou bien dans une colonne dédiée, plutôt qu’en note de tableau.\n\ntbl |> \n  add_stat_label()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      N = 2 000\n    \n\n\nage, Moyenne (ET)\n48 (17)\n\n\nheures.tv, Médiane [EI]\n2,00 [1,00 - 3,00]\n\n\n    Manquant\n5\n\n\noccup, n (%)\n\n\n\n    Exerce une profession\n1 049 (52%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (20%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\nTable 18.10:  ajout du nom des statistiques \n\n\n\n\ntbl |> \n  add_stat_label(location = \"column\")\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      Statistique\n      N = 2 000\n    \n\n\nage\nMoyenne (ET)\n48 (17)\n\n\nheures.tv\nMédiane [EI]\n2,00 [1,00 - 3,00]\n\n\n    Manquant\nn\n5\n\n\noccup\n\n\n\n\n    Exerce une profession\nn (%)\n1 049 (52%)\n\n\n    Chomeur\nn (%)\n134 (6,7%)\n\n\n    Etudiant, eleve\nn (%)\n94 (4,7%)\n\n\n    Retraite\nn (%)\n392 (20%)\n\n\n    Retire des affaires\nn (%)\n77 (3,9%)\n\n\n    Au foyer\nn (%)\n171 (8,6%)\n\n\n    Autre inactif\nn (%)\n83 (4,2%)\n\n\n\nTable 18.11:  ajout du nom des statistiques dans une colonne séparée \n\n\n\n\n18.2.5 Forcer le type de variable\nComme évoqué plus haut, gtsummary détermine automatiquement le type de chaque variable. Par défaut, la variabe age du tableau de données trial est traitée comme variable continue, death comme dichotomique (seule la valeur 1 est affichée) et grade comme variable catégorielle.\n\ntrial |>\n  tbl_summary(\n    include = c(grade, age, death)\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2001\n\n    \n\n\nGrade\n\n\n\n    I\n68 (34%)\n\n\n    II\n68 (34%)\n\n\n    III\n64 (32%)\n\n\nAge\n47 (38 – 57)\n\n\n    Manquant\n11\n\n\nPatient Died\n112 (56%)\n\n\n\n\n1 n (%); Médiane (EI)\n    \n\nTable 18.12:  types de variable par défaut \n\n\n\nIl est cependant possible de forcer un certain type avec l’argument type. Précision : lorsque l’on force une variable en dichotomique, il faut indiquer avec value la valeur à afficher (les autres sont alors masquées).\n\ntrial |>\n  tbl_summary(\n    include = c(grade, death),\n    type = list(\n      grade ~ \"dichotomous\",\n      death ~ \"categorical\"\n    ),\n    value = grade ~ \"III\",\n    label = grade ~ \"Grade III\"\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2001\n\n    \n\n\nGrade III\n64 (32%)\n\n\nPatient Died\n\n\n\n    0\n88 (44%)\n\n\n    1\n112 (56%)\n\n\n\n\n1 n (%)\n    \n\nTable 18.13:  types de variable personnalisés \n\n\n\n\n18.2.6 Afficher des statistiques sur plusieurs lignes (variables continues)\nPour les variables continues, gtsummary a introduit un type de variable \"continuous2\", qui doit être attribué manuellement via type, et qui permets d’afficher plusieurs lignes de statistiques (en indiquant plusieurs chaînes de caractères dans statistic). À noter le sélecteur dédié gtsummary::all_continuous2().\n\nhdv2003 |>\n  tbl_summary(\n    include = c(age, heures.tv),\n    type = age ~ \"continuous2\",\n    statistic = \n      all_continuous2() ~ c(\n        \"{median} ({p25} - {p75})\", \n        \"{mean} ({sd})\",\n        \"{min} - {max}\"\n      )\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nage\n\n\n\n    Médiane (EI)\n48 (35 - 60)\n\n\n    Moyenne (ET)\n48 (17)\n\n\n    Étendue\n18 - 97\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n\n\n    Manquant\n5\n\n\n\n\n1 Médiane (EI)\n    \n\nTable 18.14:  des statistiques sur plusieurs lignes (variables continues) \n\n\n\n\n18.2.7 Mise en forme des statistiques\nL’argument digits permet de spécifier comment mettre en forme les différentes statistiques. Le plus simple est d’indiquer le nombre de décimales à afficher. Il est important de tenir compte que plusieurs statistiques peuvent être affichées pour une même variable. On peut alors indiquer une valeur différente pour chaque statistique.\n\nhdv2003 |>\n  tbl_summary(\n    include = c(age, occup),\n    digits = list(\n      all_continuous() ~ 1,\n      all_categorical() ~ c(0, 1)\n    )\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nage\n48,0 (35,0 – 60,0)\n\n\noccup\n\n\n\n    Exerce une profession\n1 049 (52,4%)\n\n\n    Chomeur\n134 (6,7%)\n\n\n    Etudiant, eleve\n94 (4,7%)\n\n\n    Retraite\n392 (19,6%)\n\n\n    Retire des affaires\n77 (3,9%)\n\n\n    Au foyer\n171 (8,6%)\n\n\n    Autre inactif\n83 (4,2%)\n\n\n\n\n1 Médiane (EI); n (%)\n    \n\nTable 18.15:  personnalisation du nombre de décimales \n\n\n\nAu lieu d’un nombre de décimales, on peut indiquer plutôt une fonction à appliquer pour mettre en forme le résultat. Par exemple, gtsummary fournit les fonctions suivantes : gtsummary::style_number() pour les nombres de manière générale, gtsummary::style_percent() pour les pourcentages (les valeurs sont multipliées par 100, mais le symbole % n’est pas ajouté), gtsummary::style_pvalue() pour les p-valeurs, gtsummary::style_sigfig() qui n’affiche, par défaut, que deux chiffres significatifs, ou encore gtsummary::style_ratio() qui est une variante de gtsummary::``style_sigfig() pour les ratios (comme les odds ratios) que l’on compare à 1.\nIl faiut bien noter que ce qui est attendu par digits, c’est une fonction et non le résultat d’une fonction. On indiquera donc le nom de la fonction sans parenthèse, comme dans l’exemple ci-dessous (même si pas forcément pertinent ;-)).\n\nhdv2003 |>\n  tbl_summary(\n    include = age,\n    digits = \n      all_continuous() ~ c(style_percent, style_sigfig, style_ratio)\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\nage\n4 800 (35 – 60,0)\n\n\n\n1 Médiane (EI)\n    \n\nTable 18.16:  personnalisation de la mise en forme des nombres \n\n\n\nComme digits s’attends à recevoir une fonction (et non le résultat) d’une fonction, on ne peut pas passer directement des arguments aux fonctions style_*() de gtsummary. Pour cela il faut créer une fonction à la levée :\n\ntrial |>\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean} pour 100\",\n    digits = ~ function(x){style_percent(x, digits = 1)}\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2001\n\n    \n\n\nMarker Level (ng/mL)\n91,6 pour 100\n\n\n    Manquant\n10\n\n\n\n\n1 Moyenne pour 100\n    \n\nTable 18.17:  passer une fonction personnalisée à digits (syntaxe 1) \n\n\n\nDepuis R 4.1, il existe une syntaxe raccourcie équivalente, avec le symbole \\ à la place de function.\n\ntrial |>\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean} pour 100\",\n    digits = ~ \\(x){style_percent(x, digits = 1)}\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2001\n\n    \n\n\nMarker Level (ng/mL)\n91,6 pour 100\n\n\n    Manquant\n10\n\n\n\n\n1 Moyenne pour 100\n    \n\nTable 18.18:  passer une fonction personnalisée à digits (syntaxe 2) \n\n\n\nUne syntaxe alternative consiste à avoir recours à la fonction purrr::partial() qui permet d’appeler partiellement une fonction et de renvoyer une nouvelle fonction.\n\ntrial |>\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean} pour 100\",\n    digits = ~ purrr::partial(style_percent, digits = 1)\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2001\n\n    \n\n\nMarker Level (ng/mL)\n91,6 pour 100\n\n\n    Manquant\n10\n\n\n\n\n1 Moyenne pour 100\n    \n\nTable 18.19:  passer une fonction personnalisée à digits (syntaxe 3) \n\n\n\nÀ noter dans l’exemple précédent que les fonctions style_*() de gtsummary tiennent compte du thème défini (ici la virgule comme séparateur de décimale).\nPour une mise en forme plus avancée des nombres, il faut se tourner vers l’extension scales et ses diverses fonctions de mise en forme comme scales::label_number() ou scales::label_percent().\nATTENTION : les fonctions de scales n’héritent pas des paramètres du thème gtsummary actif. Il faut donc personnaliser le séparateur de décimal dans l’appel à la fonction.\n\ntrial |>\n  tbl_summary(\n    include = marker,\n    statistic = ~ \"{mean}\",\n    digits = ~ scales::label_number(\n      accuracy = .01, \n      suffix = \" ng/mL\", \n      decimal.mark = \",\"\n    )\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2001\n\n    \n\n\nMarker Level (ng/mL)\n0,92 ng/mL\n\n\n    Manquant\n10\n\n\n\n\n1 Moyenne\n    \n\nTable 18.20:  passer une fonction personnalisée à digits (syntaxe 4) \n\n\n\n\n18.2.8 Données manquantes\nLe paramètre missing permets d’indiquer s’il faut afficher le nombre d’observations manquantes (c’est-à-dire égales à NA) : \"ifany\" (valeur par défaut) affiche ce nombre seulement s’il y en a, \"no\" masque ce nombre et \"always\" force l’affichage de ce nombre même s’il n’y pas de valeur manquante. Le paramètre missing_text permets de personnaliser le texte affiché.\n\nhdv2003 |>\n  tbl_summary(\n    include = c(age, heures.tv),\n    missing = \"always\",\n    missing_text = \"Nbre observations manquantes\"\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\nage\n48 (35 – 60)\n\n\n    Nbre observations manquantes\n0\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n\n\n    Nbre observations manquantes\n5\n\n\n\n\n1 Médiane (EI)\n    \n\nTable 18.21:  forcer l’affichage des valeurs manquantes \n\n\n\nIl est à noter, pour les variables catégorielles, que les valeurs manquantes ne sont jamais pris en compte pour le calcul des pourcentages. Pour les inclure dans le calcul, il faut les transformer en valeurs explicites, par exemple avec forcats::fct_explicit_na() de forcats.\n\nhdv2003 |>\n  dplyr::mutate(\n    trav.imp.explicit = trav.imp |> \n      forcats::fct_explicit_na(\"(non renseigné)\")\n  ) |> \n  tbl_summary(\n    include = c(trav.imp, trav.imp.explicit)\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n    \n\n\ntrav.imp\n\n\n\n    Le plus important\n29 (2,8%)\n\n\n    Aussi important que le reste\n259 (25%)\n\n\n    Moins important que le reste\n708 (68%)\n\n\n    Peu important\n52 (5,0%)\n\n\n    Manquant\n952\n\n\ntrav.imp.explicit\n\n\n\n    Le plus important\n29 (1,5%)\n\n\n    Aussi important que le reste\n259 (13%)\n\n\n    Moins important que le reste\n708 (35%)\n\n\n    Peu important\n52 (2,6%)\n\n\n    (non renseigné)\n952 (48%)\n\n\n\n\n1 n (%)\n    \n\nTable 18.22:  valeurs manquantes explicites (variable catégorielle) \n\n\n\n\n18.2.9 Ajouter les effectifs observés\nLorsque l’on masque les manquants, il peut être pertinent d’ajouter une colonne avec les effectifs observés pour chaque variable à l’aide de la fonction gtsummary::add_n().\n\nhdv2003 |>\n  tbl_summary(\n    include = c(heures.tv, trav.imp),\n    missing = \"no\"\n  ) |> \n  add_n()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      N\n      \nN = 2 0001\n\n    \n\n\nheures.tv\n1 995\n2,00 (1,00 – 3,00)\n\n\ntrav.imp\n1 048\n\n\n\n    Le plus important\n\n29 (2,8%)\n\n\n    Aussi important que le reste\n\n259 (25%)\n\n\n    Moins important que le reste\n\n708 (68%)\n\n\n    Peu important\n\n52 (5,0%)\n\n\n\n\n1 Médiane (EI); n (%)\n    \n\nTable 18.23:  ajouter une colonne avec les effectifs observés"
  },
  {
    "objectID": "analyses/statistique-univariee.html#calcul-manuel",
    "href": "analyses/statistique-univariee.html#calcul-manuel",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.3 Calcul manuel",
    "text": "18.3 Calcul manuel\n\n18.3.1 Variable continue\nR fournit de base toutes les fonctions nécessaires pour le calcul des différentes statistiques descriptives :\n\n\nmean() pour la moyenne\n\nsd() pour l’écart-type\n\nmin() et max() pour le minimum et le maximum\n\nrange() pour l’étendue\n\nmedian() pour la médiane\n\nSi la variable contient des valeurs manquantes (NA), ces fonctions renverront une valeur manquante, sauf si on leur précise na.rm = TRUE.\n\nhdv2003$heures.tv |> mean()\n\n[1] NA\n\nhdv2003$heures.tv |> mean(na.rm = TRUE)\n\n[1] 2.246566\n\nhdv2003$heures.tv |> sd(na.rm = TRUE)\n\n[1] 1.775853\n\nhdv2003$heures.tv |> min(na.rm = TRUE)\n\n[1] 0\n\nhdv2003$heures.tv |> max(na.rm = TRUE)\n\n[1] 12\n\nhdv2003$heures.tv |> range(na.rm = TRUE)\n\n[1]  0 12\n\nhdv2003$heures.tv |> median(na.rm = TRUE)\n\n[1] 2\n\n\nLa fonction quantile() permets de calculer tous types de quantiles.\n\nhdv2003$heures.tv |> quantile(na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n   0    1    2    3   12 \n\nhdv2003$heures.tv |> \n  quantile(\n    probs = c(.2, .4, .6, .8),\n    na.rm = TRUE\n  )\n\n20% 40% 60% 80% \n  1   2   2   3 \n\n\nLa fonction summary() renvoie la plupart de ces indicateurs en une seule fois, ainsi que le nombre de valeurs manquantes.\n\nhdv2003$heures.tv |> summary()\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  0.000   1.000   2.000   2.247   3.000  12.000       5 \n\n\n\n18.3.2 Variable catégorielle\nLes fonctions de base pour le calcul d’un tri à plat sont les fonctions table() et xtabs(). Leur syntaxe est quelque peu différente. On passe un vecteur entier à table() alors que la syntaxe de xtabs() se rapproche de celle d’un modèle linéaire : on décrit le tableau attendu à l’aide d’une formule et on indique le tableau de données. Les deux fonctions renvoient le meme résultat.\n\ntbl <- hdv2003$trav.imp |> table()\ntbl <- xtabs(~ trav.imp, data = hdv2003)\ntbl <- hdv2003 |> xtabs(~ trav.imp, data = _)\ntbl\n\ntrav.imp\n           Le plus important Aussi important que le reste \n                          29                          259 \nMoins important que le reste                Peu important \n                         708                           52 \n\n\nComme on le voit, il s’agit du tableau brut des effectifs, sans les valeurs manquantes, et pas vraiment lisible dans la console de R.\nPour calculer les proportions, on appliquera prop.table() sur la table des effectifs bruts.\n\nprop.table(tbl)\n\ntrav.imp\n           Le plus important Aussi important que le reste \n                  0.02767176                   0.24713740 \nMoins important que le reste                Peu important \n                  0.67557252                   0.04961832 \n\n\nPour la réalisation rapide d’un tri à plat, on pourra donc préférer la fonction questionr::freq() qui affiche également le nombre de valeurs manquantes et les pourcentages, en un seul appel.\n\nhdv2003$trav.imp |> \n  questionr::freq(total = TRUE)\n\n                                n     %  val%\nLe plus important              29   1.5   2.8\nAussi important que le reste  259  13.0  24.7\nMoins important que le reste  708  35.4  67.6\nPeu important                  52   2.6   5.0\nNA                            952  47.6    NA\nTotal                        2000 100.0 100.0"
  },
  {
    "objectID": "analyses/statistique-univariee.html#intervalles-de-confiance",
    "href": "analyses/statistique-univariee.html#intervalles-de-confiance",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.4 Intervalles de confiance",
    "text": "18.4 Intervalles de confiance\n\n18.4.1 Avec gtsummary\nLa fonction gtsummary::add_ci() permet d’ajouter des intervalles de confiance à un tableau créé avec gtsummary::tbl_summary().\n\n\n\n\n\n\nAvertissement\n\n\n\nPar défaut, pour les variables continues, gtsummary::tbl_summary() affiche la médiane tandis que gtsummary::add_ci() calcule l’intervalle de confiance d’une moyenne !\nIl faut donc :\n\nsoit afficher la moyenne dans gtsummary::tbl_summary() à l’aide du paramètre statistic ;\nsoit calculer les intervalles de confiance d’une médiane (méthode \"wilcox.text\") via le paramètre method de gtsummary::add_ci().\n\n\n\n\nhdv2003 |>\n  tbl_summary(\n    include = c(age, heures.tv, trav.imp),\n    statistic = age ~ \"{mean} ({sd})\"\n  ) |> \n  add_ci(\n    method = heures.tv ~ \"wilcox.test\"\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n      \n95% CI2\n\n    \n\n\nage\n48 (17)\n47, 49\n\n\nheures.tv\n2,00 (1,00 – 3,00)\n2,5, 2,5\n\n\n    Manquant\n5\n\n\n\ntrav.imp\n\n\n\n\n    Le plus important\n29 (2,8%)\n1,9%, 4,0%\n\n\n    Aussi important que le reste\n259 (25%)\n22%, 27%\n\n\n    Moins important que le reste\n708 (68%)\n65%, 70%\n\n\n    Peu important\n52 (5,0%)\n3,8%, 6,5%\n\n\n    Manquant\n952\n\n\n\n\n\n\n1 Moyenne (ET); Médiane (EI); n (%)\n    \n\n\n2 IC = intervalle de confiance\n    \n\n\nTable 18.24:  ajouter les intervalles de confiance \n\n\n\nL’argument statistic permet de personnaliser la présentation de l’intervalle ; conf.level de changer le niveau de confiance et style_fun de modifier la mise en forme des nombres de l’intervalle.\n\nhdv2003 |>\n  tbl_summary(\n    include = c(age, heures.tv),\n    statistic = ~ \"{mean}\"\n  ) |> \n  add_ci(\n    statistic = ~ \"entre {conf.low} et {conf.high}\",\n    conf.level = .9,\n    style_fun = ~ purrr::partial(style_number, digits = 1)\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nN = 2 0001\n\n      \n90% CI2\n\n    \n\n\nage\n48\nentre 47,5 et 48,8\n\n\nheures.tv\n2,25\nentre 2,2 et 2,3\n\n\n    Manquant\n5\n\n\n\n\n\n\n1 Moyenne\n    \n\n\n2 IC = intervalle de confiance\n    \n\n\nTable 18.25:  des intervalles de confiance personnalisés \n\n\n\n\n18.4.2 Calcul manuel\nLe calcul de l’intervalle de confiance d’une moyenne s’effectue avec la fonction t.test().\n\nhdv2003$age |> t.test()\n\n\n    One Sample t-test\n\ndata:  hdv2003$age\nt = 127.12, df = 1999, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 47.41406 48.89994\nsample estimates:\nmean of x \n   48.157 \n\n\nLe résultat renvoyé est une liste contenant de multiples informations.\n\nhdv2003$age |> t.test() |> str()\n\nList of 10\n $ statistic  : Named num 127\n  ..- attr(*, \"names\")= chr \"t\"\n $ parameter  : Named num 1999\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value    : num 0\n $ conf.int   : num [1:2] 47.4 48.9\n  ..- attr(*, \"conf.level\")= num 0.95\n $ estimate   : Named num 48.2\n  ..- attr(*, \"names\")= chr \"mean of x\"\n $ null.value : Named num 0\n  ..- attr(*, \"names\")= chr \"mean\"\n $ stderr     : num 0.379\n $ alternative: chr \"two.sided\"\n $ method     : chr \"One Sample t-test\"\n $ data.name  : chr \"hdv2003$age\"\n - attr(*, \"class\")= chr \"htest\"\n\n\nSi l’on a besoin d’accéder spécifiquement à l’intervalle de confiance calculé :\n\nhdv2003$age |> t.test() |> purrr::pluck(\"conf.int\")\n\n[1] 47.41406 48.89994\nattr(,\"conf.level\")\n[1] 0.95\n\n\nPour celui d’une médiane, on utilisera wilcox.test() en précisant conf.int = TRUE.\n\nhdv2003$age |> wilcox.test(conf.int = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  hdv2003$age\nV = 2001000, p-value < 2.2e-16\nalternative hypothesis: true location is not equal to 0\n95 percent confidence interval:\n 47.00001 48.50007\nsample estimates:\n(pseudo)median \n      47.99996 \n\nhdv2003$age |> \n  wilcox.test(conf.int = TRUE) |>\n  purrr::pluck(\"conf.int\")\n\n[1] 47.00001 48.50007\nattr(,\"conf.level\")\n[1] 0.95\n\n\nPour une proportion, on utilisera prop.test() en lui transmettant le nombre de succès et le nombre d’observations, qu’il faudra donc avoir calculé au préalable. On peut également passer une table à deux entrées avec le nombre de succès puis le nombre d’échecs.\nAinsi, pour obtenir l’intervalle de confiance de la proportion des enquêtés qui considèrent leur travail comme peu important, en tenant compte des valeurs manquantes, le plus simple est d’effectuer le code suivant3 :3 Notez l’utilisation de rev() pour inverser le tableau créé avec xtabs() afin que le nombre de succès (TRUE) soit indiqués avant le nombre d’échecs (FALSE).\n\nxtabs(~ I(hdv2003$trav.imp == \"Peu important\"), data = hdv2003) |> \n  rev() |> \n  prop.test()\n\n\n    1-sample proportions test with continuity correction\n\ndata:  rev(xtabs(~I(hdv2003$trav.imp == \"Peu important\"), data = hdv2003)), null probability 0.5\nX-squared = 848.52, df = 1, p-value < 2.2e-16\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.03762112 0.06502346\nsample estimates:\n         p \n0.04961832 \n\n\nPar défaut, prop.test() produit un intervalle de confiance bilatéral en utilisant la méthode de Wilson avec correction de continuité. Pour plus d’information sur les différentes manières de calculer l’intervalle de confiance d’une proportion, on pourra se référer à ce billet de blog.\n\n\n\n\n\n\nAstuce\n\n\n\nComme on le voit, il n’est pas aisé, avec les fonctions de R base de calculer les intervalles de confiance pour toutes les modalités d’une variable catégorielle.\nOn pourra éventuellement avoir recours à la petite fonction suivante qui réalise le tri à plat d’une variable catégorielle, calcule les proprotions et leurs intervalles de confiance.\n\nprop_ci <- function(x, conf.level = .95, correct = TRUE) {\n  tbl <- as.data.frame(table(x), responseName = \"n\")\n  tbl$N <- sum(tbl$n)\n  tbl$prop <- tbl$n / tbl$N\n  tbl$conf.low <- NA_real_\n  tbl$conf.high <- NA_real_\n  for (i in 1:nrow(tbl)) {\n    test <- prop.test(\n      x = tbl$n[i],\n      n = tbl$N[i],\n      conf.level = conf.level,\n      correct = correct\n    )\n    tbl$conf.low[i] <- test$conf.int[1]\n    tbl$conf.high[i] <- test$conf.int[2]\n  }\n  tbl\n}\nprop_ci(hdv2003$trav.imp)\n\n                             x   n    N       prop   conf.low  conf.high\n1            Le plus important  29 1048 0.02767176 0.01894147 0.04001505\n2 Aussi important que le reste 259 1048 0.24713740 0.22151849 0.27463695\n3 Moins important que le reste 708 1048 0.67557252 0.64614566 0.70369541\n4                Peu important  52 1048 0.04961832 0.03762112 0.06502346"
  },
  {
    "objectID": "analyses/statistique-univariee.html#webin-r",
    "href": "analyses/statistique-univariee.html#webin-r",
    "title": "18  Statistique univariée & Intervalles de confiance",
    "section": "\n18.5 webin-R",
    "text": "18.5 webin-R\nLa statistique univariée est présentée dans le webin-R #03 (statistiques descriptives avec gtsummary et esquisse) sur YouTube."
  },
  {
    "objectID": "analyses/statistique-bivariee.html#deux-variables-catégorielles",
    "href": "analyses/statistique-bivariee.html#deux-variables-catégorielles",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.1 Deux variables catégorielles",
    "text": "19.1 Deux variables catégorielles\n\n19.1.1 Tableau croisé avec gtsummary\n\nPour regarder le lien entre deux variables catégorielles, l’approche la plus fréquente consiste à réaliser un tableau croisé, ce qui s’obtient très facilement avec l’argument by de la fonction gtsummary::tbl_summary() que nous avons déjà abordée dans le chapitre sur la statitstique univariée (cf. Section 18.2).\nPrenons pour exemple le jeu de données gtsummary::trial et croisons les variables stage et grade. On indique à by la variable à représenter en colonnes et à include celle à représenter en lignes.\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = ',')\n\nSetting theme `language: fr`\n\ntrial |> \n  tbl_summary(\n    include = stage,\n    by = grade\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n    \n\n\nT Stage\n\n\n\n\n\n    T1\n17 (25%)\n23 (34%)\n13 (20%)\n\n\n    T2\n18 (26%)\n17 (25%)\n19 (30%)\n\n\n    T3\n18 (26%)\n11 (16%)\n14 (22%)\n\n\n    T4\n15 (22%)\n17 (25%)\n18 (28%)\n\n\n\n\n1 n (%)\n    \n\nTable 19.1:  un tableau croisé avec des pourcentages en colonne \n\n\n\nPar défaut, les pourcentages affichés correspondent à des pourcentages en colonne. On peut demander des pourcentages en ligne avec percent = \"row\" ou des pourcentages du total avec percent = \"cell\".\nIl est possible de passer plusieurs variables à include mais une seule variable peut être transmise à by. La fonction gtsummary::add_overall() permet d’ajouter une colonne totale. Comme pour un tri à plat, on peut personnaliser les statistiques affichées avec statistic.\n\nlibrary(gtsummary)\ntrial |> \n  tbl_summary(\n    include = c(stage, trt),\n    by = grade,\n    statistic = ~ \"{p}% ({n}/{N})\",\n    percent = \"row\"\n  ) |> \n  add_overall(last = TRUE)\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n      \nTotal, N = 2001\n\n    \n\n\nT Stage\n\n\n\n\n\n\n    T1\n32% (17/53)\n43% (23/53)\n25% (13/53)\n100% (53/53)\n\n\n    T2\n33% (18/54)\n31% (17/54)\n35% (19/54)\n100% (54/54)\n\n\n    T3\n42% (18/43)\n26% (11/43)\n33% (14/43)\n100% (43/43)\n\n\n    T4\n30% (15/50)\n34% (17/50)\n36% (18/50)\n100% (50/50)\n\n\nChemotherapy Treatment\n\n\n\n\n\n\n    Drug A\n36% (35/98)\n33% (32/98)\n32% (31/98)\n100% (98/98)\n\n\n    Drug B\n32% (33/102)\n35% (36/102)\n32% (33/102)\n100% (102/102)\n\n\n\n\n1 % (n/N)\n    \n\nTable 19.2:  un tableau croisé avec des pourcentages en ligne \n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nChoisissez bien votre type de pourcentages (en lignes ou en colonnes). Si d’un point de vue purement statistique, ils permettent tous deux de décrire la relation entre les deux variables, ils ne correspondent au même story telling. Tout dépend donc du message que vous souhaitez faire passer, de l’histoire que vous souhaitez raconter.\n\n\ngtsummary::tbl_summary() est bien adaptée dans le cadre d’une analyse de facteurs afin de représenter un outcome donné avec by et une liste de facteurs avec include.\nLorsque l’on ne croise que deux variables et que l’on souhaite un affichage un peu plus traditionnel d’un tableau croisé, on peut utiliser gtsummary::tbl_cross() à laquelle on transmettra une et une seule variable à row et une et une seule variable à col. Pour afficher des pourcentages, il faudra indiquer le type de pourcentages voulus avec percent.\n\ntrial |> \n  tbl_cross(\n    row = stage,\n    col = grade,\n    percent = \"row\"\n  )\n\n\n\n\n\n\n\n  \n  \n\n\n      \n        Grade\n      \n      Total\n    \n\nI\n      II\n      III\n    \n\n\n\nT Stage\n\n\n\n\n\n\n    T1\n17 (32%)\n23 (43%)\n13 (25%)\n53 (100%)\n\n\n    T2\n18 (33%)\n17 (31%)\n19 (35%)\n54 (100%)\n\n\n    T3\n18 (42%)\n11 (26%)\n14 (33%)\n43 (100%)\n\n\n    T4\n15 (30%)\n17 (34%)\n18 (36%)\n50 (100%)\n\n\nTotal\n68 (34%)\n68 (34%)\n64 (32%)\n200 (100%)\n\n\n\nTable 19.3:  un tableau croisé avec tbl_cross() \n\n\n\n\n19.1.2 Représentations graphiques\nLa représentation graphique la plus commune pour le croisement de deux variables catégorielles est le diagramme en barres, que l’on réalise avec la géométrie ggplot2::geom_bar() et en utilisant les esthétiques x et fill pour représenter les deux variables.\n\nlibrary(ggplot2)\nggplot(trial) +\n  aes(x = stage, fill = grade) +\n  geom_bar() +\n  labs(x = \"T Stage\", fill = \"Grade\", y = \"Effectifs\")\n\n\n\nFigure 19.1: un graphique en barres croisant deux variables\n\n\n\n\nOn peut modifier la position des barres avec le paramètre position.\n\nlibrary(ggplot2)\nggplot(trial) +\n  aes(x = stage, fill = grade) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"T Stage\", fill = \"Grade\", y = \"Effectifs\")\n\n\n\nFigure 19.2: un graphique avec des barres côte à côte\n\n\n\n\nPour des barres cumulées, on aura recours à position = \"fill\". Pour que les étiquettes de l’axe des y soient représentées sous forme de pourcentages (i.e. 25% au lieu de 0.25), on aura recours à la fonction scales::percent() qui sera transmise à ggplot2::scale_y_continuous().\n\nlibrary(ggplot2)\nggplot(trial) +\n  aes(x = stage, fill = grade) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"T Stage\", fill = \"Grade\", y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent)\n\n\n\nFigure 19.3: un graphique en barres cumulées\n\n\n\n\n\n\n\n\n\n\nAjouter des étiquettes sur un diagramme en barres\n\n\n\nIl est facile d’ajouter des étiquettes en ayant recours à ggplot2::geom_text(), à condition de lui passer les bons paramètres.\nTout d’abord, il faudra préciser stat = \"count\" pour indiquer que l’on souhaite utiliser la statistique ggplot2::stat_count() qui est celle utilisé par défaut par ggplot2::geom_bar(). C’est elle qui permets de compter le nombre d’observations.\nIl faut ensuite utiliser l’esthétique label pour indiquer ce que l’on souhaite afficher comme étiquettes. La fonction after_stat(count) permet d’accéder à la variable count calculée par ggplot2::stat_count().\nEnfin, il faut indiquer la position verticale avec ggplot2::position_stack(). En précisant un ajustement de vertical de 0.5, on indique que l’on souhaite positionner l’étiquette au milieu.\n\nggplot(trial) +\n  aes(\n    x = stage, fill = grade, \n    label = after_stat(count)\n  ) +\n  geom_bar() +\n  geom_text(\n    stat = \"count\", \n    position = position_stack(.5)\n  )\n\n\n\n\n\n\n\nPour un graphique en barres cumulées, on peut utiliser de manière similaire ggplot2::position_fill(). On ne peut afficher directement les proportions avec ggplot2::stat_count(). Cependant, nous pouvons avoir recours à ggstats::stat_prop(), déjà évoquée dans le chapitre sur la statistique univariée (cf. Section 18.1.2) et dont le dénominateur doit être précisé via l’esthétique by.\n\nlibrary(ggstats)\nggplot(trial) +\n  aes(\n    x = stage, \n    fill = grade, \n    by = stage,\n    label = scales::percent(after_stat(prop), accuracy = .1)\n  ) +\n  geom_bar(position = \"fill\") +\n  geom_text(\n    stat = \"prop\", \n    position = position_fill(.5)\n  ) +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\nOn peut aussi comparer facilement deux distributions, ici la proportion de chaque niveau de qualification au sein chaque sexe.\n\np <- ggplot(trial) +\n  aes(\n    x = stage,\n    y = after_stat(prop),\n    fill = grade, \n    by = grade,\n    label = scales::percent(after_stat(prop), accuracy = 1)\n  ) +\n  geom_bar(\n    stat = \"prop\", \n    position = position_dodge(.9)\n  ) +\n  geom_text(\n    aes(y = after_stat(prop) - 0.01),\n    stat = \"prop\", \n    position = position_dodge(.9),\n    vjust = \"top\"\n  ) +\n  scale_y_continuous(labels = scales::percent)\np\n\n\n\n\n\n\n\nIl est possible d’alléger le graphique en retirant des éléments superflus.\n\np + \n  theme_light() +\n  xlab(\"\") +\n  ylab(\"\") +\n  labs(fill = \"\") +\n  ggtitle(\"Distribution selon le niveau, par grade\") +\n  theme(\n    panel.grid = element_blank(),\n    panel.border = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank(),\n    legend.position = \"top\"\n  ) +\n  scale_fill_brewer()\n\n\n\n\n\n\n\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code correspondant au graphique précédent.\n\n\n\n\n\n\n19.1.3 Calcul manuel\nLes deux fonctions de base permettant le calcul d’un tri à plat sont table() et xtabs() (cf. Section 18.3.2). Ces mêmes fonctions permettent le calcul du tri croisé de deux variables (ou plus). Pour table(), on passera les deux vecteurs à croisés, tandis que pour xtabs() on décrira le tableau attendu à l’aide d’une formule.\n\ntable(trial$stage, trial$grade)\n\n    \n      I II III\n  T1 17 23  13\n  T2 18 17  19\n  T3 18 11  14\n  T4 15 17  18\n\ntab <- xtabs(~ stage + grade, data = trial)\ntab\n\n     grade\nstage  I II III\n   T1 17 23  13\n   T2 18 17  19\n   T3 18 11  14\n   T4 15 17  18\n\n\nLe tableau obtenu est basique et ne contient que les effectifs. La fonction addmargins() permet d’ajouter les totaux par ligne et par colonne.\n\ntab |> addmargins()\n\n     grade\nstage   I  II III Sum\n  T1   17  23  13  53\n  T2   18  17  19  54\n  T3   18  11  14  43\n  T4   15  17  18  50\n  Sum  68  68  64 200\n\n\nPour le calcul des pourcentages, le plus simple est d’avoir recours au package questionr qui fournit les fonctions questionr::cprop(), questionr::rprop() et questionr::prop() qui permettent de calculer, respectivement, les pourcentages en colonne, en ligne et totaux.\n\nquestionr::cprop(tab)\n\n       grade\nstage   I     II    III   Ensemble\n  T1     25.0  33.8  20.3  26.5   \n  T2     26.5  25.0  29.7  27.0   \n  T3     26.5  16.2  21.9  21.5   \n  T4     22.1  25.0  28.1  25.0   \n  Total 100.0 100.0 100.0 100.0   \n\nquestionr::rprop(tab)\n\n          grade\nstage      I     II    III   Total\n  T1        32.1  43.4  24.5 100.0\n  T2        33.3  31.5  35.2 100.0\n  T3        41.9  25.6  32.6 100.0\n  T4        30.0  34.0  36.0 100.0\n  Ensemble  34.0  34.0  32.0 100.0\n\nquestionr::prop(tab)\n\n       grade\nstage   I     II    III   Total\n  T1      8.5  11.5   6.5  26.5\n  T2      9.0   8.5   9.5  27.0\n  T3      9.0   5.5   7.0  21.5\n  T4      7.5   8.5   9.0  25.0\n  Total  34.0  34.0  32.0 100.0\n\n\n\n19.1.4 Test du Chi² et dérivés\nDans le cadre d’un tableau croisé, on peut tester l’existence d’un lien entre les modalités de deux variables, avec le très classique test du Chi² (parfois écrit χ² ou Chi²). Pour une présentation plus détaillée du test, on pourra se référer à ce cours de Julien Barnier.\nLe test du Chi² peut se calculer très facilement avec la fonction chisq.test() appliquée au tableau obtenu avec table() ou xtabs().\n\ntab <- xtabs(~ stage + grade, data = trial)\ntab\n\n     grade\nstage  I II III\n   T1 17 23  13\n   T2 18 17  19\n   T3 18 11  14\n   T4 15 17  18\n\nchisq.test(tab)\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 4.8049, df = 6, p-value = 0.5691\n\n\nSi l’on est adepte de gtsummary, il suffit d’appliquer gtsummary::add_p() au tableau produit avec gtsummary::tbl_summary().\n\ntrial |> \n  tbl_summary(\n    include = stage,\n    by = grade\n  ) |> \n  add_p()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n      \np-valeur2\n\n    \n\n\nT Stage\n\n\n\n0,6\n\n\n    T1\n17 (25%)\n23 (34%)\n13 (20%)\n\n\n\n    T2\n18 (26%)\n17 (25%)\n19 (30%)\n\n\n\n    T3\n18 (26%)\n11 (16%)\n14 (22%)\n\n\n\n    T4\n15 (22%)\n17 (25%)\n18 (28%)\n\n\n\n\n\n\n1 n (%)\n    \n\n\n2 test du khi-deux d'indépendance\n    \n\n\nTable 19.4:  un tableau croisé avec test du khi² \n\n\n\nDans notre exemple, les deux variables stage et grade ne sont clairement pas corrélées.\nUn test alternatif est le test exact de Fisher. Il s’obtient aisément avec fisher.test() ou bien en le spécifiant via l’argument test de gtsummary::add_p().\n\ntab <- xtabs(~ stage + grade, data = trial)\nfisher.test(tab)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tab\np-value = 0.5801\nalternative hypothesis: two.sided\n\n\n\ntrial |> \n  tbl_summary(\n    include = stage,\n    by = grade\n  ) |> \n  add_p(test = all_categorical() ~ \"fisher.test\")\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n      \np-valeur2\n\n    \n\n\nT Stage\n\n\n\n0,6\n\n\n    T1\n17 (25%)\n23 (34%)\n13 (20%)\n\n\n\n    T2\n18 (26%)\n17 (25%)\n19 (30%)\n\n\n\n    T3\n18 (26%)\n11 (16%)\n14 (22%)\n\n\n\n    T4\n15 (22%)\n17 (25%)\n18 (28%)\n\n\n\n\n\n\n1 n (%)\n    \n\n\n2 test exact de Fisher\n    \n\n\nTable 19.5:  un tableau croisé avec test exact de Fisher \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFormellement, le test de Fisher suppose que les marges du tableau (totaux lignes et colonnes) sont fixées, puisqu’il repose sur une loi hypergéométrique, et donc celui-ci se prête plus au cas des situations expérimentales (plans d’expérience, essais cliniques) qu’au cas des données tirées d’études observationnelles.\nEn pratique, le test du Chi² étant assez robuste quant aux déviations par rapport aux hypothèses d’applications du test (effectifs théoriques supérieurs ou égaux à 5), le test de Fisher présente en général peu d’intérêt dans le cas de l’analyse des tableaux de contingence.\n\n\n\n19.1.5 Comparaison de deux proportions\nPour comparer deux proportions, la fonction de base est prop.test() à laquelle on passera un tableau à 2×2 dimensions.\n\ntab <- xtabs(~ I(stage == \"T1\") + trt, data = trial)\ntab |> questionr::cprop()\n\n                trt\nI(stage == \"T1\") Drug A Drug B Ensemble\n           FALSE  71.4   75.5   73.5   \n           TRUE   28.6   24.5   26.5   \n           Total 100.0  100.0  100.0   \n\ntab |> prop.test()\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  tab\nX-squared = 0.24047, df = 1, p-value = 0.6239\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.2217278  0.1175050\nsample estimates:\n   prop 1    prop 2 \n0.4761905 0.5283019 \n\n\nIl est également envisageable d’avoir recours à un test exact de Fisher. Dans le cas d’un tableau à 2×2 dimensions, le test exact de Fisher ne teste pas si les deux proportions sont différents, mais plutôt si leur odds ratio (qui est d’ailleurs renvoyé par la fonction) est différent de 1.\n\nfisher.test(tab)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tab\np-value = 0.5263\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.4115109 1.5973635\nsample estimates:\nodds ratio \n 0.8125409 \n\n\nMais le plus simple reste encore d’avoir recours à gtsummary et à sa fonction gtsummary::add_difference() que l’on peut appliquer à un tableau où le paramètre by n’a que deux modalités. Pour la différence de proportions, il faut que les variables transmises à include soit dichotomiques.\n\ntrial |> \n  tbl_summary(\n    by = trt,\n    include = response\n  ) |> \n  add_difference()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nDrug A, N = 981\n\n      \nDrug B, N = 1021\n\n      \nDifference2\n\n      \n95% IC2,3\n\n      \np-valeur2\n\n    \n\n\nTumor Response\n28 (29%)\n33 (34%)\n-4,2%\n-18% – 9,9%\n0,6\n\n\n    Manquant\n3\n4\n\n\n\n\n\n\n\n\n1 n (%)\n    \n\n\n2 Two sample test for equality of proportions\n    \n\n\n3 IC = intervalle de confiance\n    \n\n\nTable 19.6:  différence entre deux proportions \n\n\n\nAttention : si l’on passe une variable catégorielle à trois modalités ou plus, c’est la différence des moyennes standardisées (globale pour la variable) qui sera calculée et non la différence des proportions dans chaque groupe.\n\ntrial |> \n  tbl_summary(\n    by = trt,\n    include = grade\n  ) |> \n  add_difference()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nDrug A, N = 981\n\n      \nDrug B, N = 1021\n\n      \nDifference2\n\n      \n95% IC2,3\n\n    \n\n\nGrade\n\n\n0,07\n-0,20 – 0,35\n\n\n    I\n35 (36%)\n33 (32%)\n\n\n\n\n    II\n32 (33%)\n36 (35%)\n\n\n\n\n    III\n31 (32%)\n33 (32%)\n\n\n\n\n\n\n\n1 n (%)\n    \n\n\n2 Standardized Mean Difference\n    \n\n\n3 IC = intervalle de confiance\n    \n\n\nTable 19.7:  différence moyenne standardisée \n\n\n\nPour calculer la différence des proportions pour chaque modalité de grade, il est nécessaire de transformer, en amont, la variable catégorielle grade en trois variables dichotomiques (de type oui/non, une par modalité), ce qui peut se faire facilement avec la fonction fastDummies::dummy_cols() de l’extension fastDummies.\n\ntrial |> \n  fastDummies::dummy_cols(\"grade\") |> \n  tbl_summary(\n    by = trt,\n    include = starts_with(\"grade_\"),\n    digits = ~ c(0, 1)\n  ) |> \n  add_difference()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nDrug A, N = 981\n\n      \nDrug B, N = 1021\n\n      \nDifference2\n\n      \n95% IC2,3\n\n      \np-valeur2\n\n    \n\n\ngrade_I\n35 (35,7%)\n33 (32,4%)\n3,4%\n-11% – 17%\n0,7\n\n\ngrade_II\n32 (32,7%)\n36 (35,3%)\n-2,6%\n-17% – 11%\n0,8\n\n\ngrade_III\n31 (31,6%)\n33 (32,4%)\n-0,72%\n-14% – 13%\n>0,9\n\n\n\n\n\n1 n (%)\n    \n\n\n2 Two sample test for equality of proportions\n    \n\n\n3 IC = intervalle de confiance\n    \n\n\nTable 19.8:  différence entre proportions avec création de variables dichotomiques"
  },
  {
    "objectID": "analyses/statistique-bivariee.html#une-variable-continue-selon-une-variable-catégorielle",
    "href": "analyses/statistique-bivariee.html#une-variable-continue-selon-une-variable-catégorielle",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.2 Une variable continue selon une variable catégorielle",
    "text": "19.2 Une variable continue selon une variable catégorielle\n\n19.2.1 Tableau comparatif avec gtsummary\n\nDans le chapitre sur la statitstique univariée (cf. Section 18.2), nous avons abordé comment afficher les statistiques descriptives d’une variable continue avec gtsummary::tbl_summary(). Pour comparer une variable continue selon plusieurs groupes définis par une variable catégorielle, il suffit d’utiliser le paramètre by :\n\ntrial |> \n  tbl_summary(\n    include = age,\n    by = grade\n  )\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n    \n\n\nAge\n47 (37 – 56)\n48 (37 – 57)\n47 (38 – 58)\n\n\n    Manquant\n2\n6\n3\n\n\n\n\n1 Médiane (EI)\n    \n\nTable 19.9:  âge médian et intervalle interquartile selon le grade \n\n\n\nLa fonction gtsummary::add_overall() permet d’ajouter une colonne total et gtsummary::modify_spanning_header() peut-être utilisé pour ajouter un en-tête de colonne.\n\ntrial |> \n  tbl_summary(\n    include = age,\n    by = grade\n  ) |> \n  add_overall(last = TRUE) |> \n  modify_spanning_header(\n    all_stat_cols(stat_0 = FALSE) ~ \"**Grade**\"\n  )\n\n\n\n\n\n\n\n  \n  \n\nCaractéristique\n      \n        Grade\n      \n      \nTotal, N = 2001\n\n    \n\n\nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n    \n\n\n\nAge\n47 (37 – 56)\n48 (37 – 57)\n47 (38 – 58)\n47 (38 – 57)\n\n\n    Manquant\n2\n6\n3\n11\n\n\n\n\n1 Médiane (EI)\n    \n\nTable 19.10:  âge médian et intervalle interquartile selon le grade \n\n\n\nComme pour un tri à plat, on peut personnaliser les statistiques à afficher avec statistic.\n\ntrial |> \n  tbl_summary(\n    include = age,\n    by = grade,\n    statistic = all_continuous() ~ \"{mean} ({sd})\",\n    digits = all_continuous() ~ c(1, 1)\n  ) |> \n  add_overall(last = TRUE)\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n      \nTotal, N = 2001\n\n    \n\n\nAge\n46,2 (15,2)\n47,5 (13,7)\n48,1 (14,1)\n47,2 (14,3)\n\n\n    Manquant\n2\n6\n3\n11\n\n\n\n\n1 Moyenne (ET)\n    \n\nTable 19.11:  âge moyen et écart-type selon le grade \n\n\n\n\n19.2.2 Représentations graphiques\nLa moyenne ou la médiane sont des indicateurs centraux et ne suffisent pas à rendre compte des différences de distribution d’une variable continue entre plusieurs sous-groupes.\nUne représentation usuelle pour comparer deux distributions consiste à avoir recours à des boîtes à moustaches que l’on obtient avec ggplot2::geom_boxplot().\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_boxplot(fill = \"lightblue\") +\n  theme_light()\n\n\n\nFigure 19.4: boîtes à moustache\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nLe trait central représente la médiane, le rectangle est délimité par le premier et le troisème quartiles (i.e. le 25e et le 75e percentiles). Les traits verticaux vont jusqu’aux extrêmes (minimum et maximum) ou jusqu’à 1,5 fois l’intervalle interquartile. Si des points sont situés à plus d’1,5 fois l’intervalle interquartile au-dessus du 3e quartile ou en-dessous du 1er quartile, ils sont considérés comme des valeurs atypiques et représentés par un point. Dans l’exemple précédent, c’est le cas des deux plus petites valeurs observées pour le grade I.\n\n\nAlternativement, on peut utiliser un graphique en violons qui représentent des courbes de densité dessinées en mirroir.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_violin(fill = \"lightblue\") +\n  theme_light()\n\n\n\nFigure 19.5: graphique en violons\n\n\n\n\nIl est toujours possible de représenter les observations inviduelles sous la forme d’un nuage de points. Le paramètre alpha permet de rendre les points transparents afin de mieux visualiser les supperpositions de points.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_point(alpha = .25, colour = \"blue\") +\n  theme_light()\n\n\n\nFigure 19.6: un nuage de points avec une variable continue et une variable catégorielle\n\n\n\n\nComme la variable grade est catégorielle, tous les points d’une meme modalité sont représentées sur une même ligne. La représentation peut être améliorée en ajoutant un décalage aléatoire sur l’axe horizontal. Cela s’obtient avec ggplot2::position_jitter() en précisant height = 0 pour ne pas ajouter de décalage vertical et width = .2 pour décaler horizontalement les points entre -20% et +20%.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_point(\n    alpha = .25,\n    colour = \"blue\",\n    position = position_jitter(height = 0, width = .2)\n  ) +\n  theme_light()\n\n\n\nFigure 19.7: un nuage de points avec une variable continue et une variable catégorielle et avec un décalage horizontal aléatoire\n\n\n\n\nLa statistique ggstats::stat_weighted_mean() de ggstats permets de calculer à la volée la moyenne du nuage de points.\n\nggplot(trial) +\n  aes(x = grade, y = age) +\n  geom_point(stat = \"weighted_mean\", colour = \"blue\") +\n  theme_light()\n\n\n\nFigure 19.8: âge moyen selon le grade\n\n\n\n\nCela peut être utile pour effectuer des comparaisons multiples.\n\nggplot(trial) +\n  aes(x = grade, y = age, colour = stage, group = stage) +\n  geom_line(stat = \"weighted_mean\") +\n  geom_point(stat = \"weighted_mean\") +\n  facet_grid(cols = vars(trt)) +\n  theme_light()\n\n\n\nFigure 19.9: âge moyen selon le grade, par traitement et état d’avancement de la maladie\n\n\n\n\n\n19.2.3 Calcul manuel\nLe plus simple pour calculer des indicateurs par sous-groupe est d’avoir recours à dplyr::summarise() avec dplyr::group_by().\n\nlibrary(dplyr)\ntrial |>\n  group_by(grade) |> \n  summarise(\n    age_moy = mean(age, na.rm = TRUE),\n    age_med = median(age, na.rm = TRUE)\n  )\n\n# A tibble: 3 × 3\n  grade age_moy age_med\n  <fct>   <dbl>   <dbl>\n1 I        46.2    47  \n2 II       47.5    48.5\n3 III      48.1    47  \n\n\nEn base R, on peut avoir recours à tapply(). On lui indique d’abord le vecteur sur lequel on souhaite réaliser le calcul, puis un facteur qui indiquera les sous-groupes, puis une fonction qui sera appliquée à chaque sous-groupe et enfin, optionnellement, des arguments additionnels qui seront transmis à cette fonction.\n\ntapply(trial$age, trial$grade, mean, na.rm = TRUE)\n\n       I       II      III \n46.15152 47.53226 48.11475 \n\n\n\n19.2.4 Tests de comparaison\nPour comparer des moyennes ou des médianes, le plus facile est encore d’avoir recours à gtsummary et sa fonction gtsummary::add_p().\n\ntrial |> \n  tbl_summary(\n    include = age,\n    by = grade\n  ) |> \n  add_p()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n      \np-valeur2\n\n    \n\n\nAge\n47 (37 – 56)\n48 (37 – 57)\n47 (38 – 58)\n0,8\n\n\n    Manquant\n2\n6\n3\n\n\n\n\n\n\n1 Médiane (EI)\n    \n\n\n2 Test de Kruskal-Wallis\n    \n\n\nTable 19.12:  test de comparaison sur la somme des rangs \n\n\n\nPar défaut, pour les variables continues, un test de Kruskal-Wallis calculé avec la fonction stats::kruskal.test() est utilisé lorsqu’il y a trois groupes ou plus, et un test de Wilcoxon-Mann-Whitney calculé avec stats::wilcox.test() (test de comparaison des rangs) lorsqu’il n’y a que deux groupes. Au sens strict, il ne s’agit pas de tests de comparaison des médianes mais de tests sur la somme des rangs. En pratique, ces tests sont appropriés lorsque l’on présente les médianes et les intervalles interquartiles.\nSi l’on affiche des moyennes, il serait plus juste d’utiliser un test t de Student (test de comparaison des moyennes) calculé avec stats::t.test(), valable seulement si l’on compare deux moyennes. Pour tester si trois moyennes ou plus sont égales, on aura plutôt recours à stats::oneway.test().\nOn peut indiquer à gtsummary::add_p() le test à utiliser avec le paramètre test.\n\ntrial |> \n  tbl_summary(\n    include = age,\n    by = grade,\n    statistic = all_continuous() ~ \"{mean} ({sd})\"\n  ) |> \n  add_p(\n    test = all_continuous() ~ \"oneway.test\"\n  )\n\nMultiple parameters; naming those columns num.df, den.df\n\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n      \np-valeur2\n\n    \n\n\nAge\n46 (15)\n48 (14)\n48 (14)\n0,7\n\n\n    Manquant\n2\n6\n3\n\n\n\n\n\n\n1 Moyenne (ET)\n    \n\n\n2 One-way analysis of means (not assuming equal variances)\n    \n\n\nTable 19.13:  test de comparaison des moyennes \n\n\n\n\n\n\n\n\n\nPrécision statistique\n\n\n\nClassiquement, le test t de Student présuppose l’égalité des variances entre les deux sous-groupes, ce qui permet de former une estimation commune de la variance des deux échantillons (on parle de pooled variance), qui revient à une moyenne pondérée des variances estimées à partir des deux échantillons. Pour tester l’égalité des variances de deux échantillons, on peut utiliser stats::var.test().\nDans le cas où l’on souhaite relaxer cette hypothèse d’égalité des variances, le test de Welch ou la correction de Satterthwaite reposent sur l’idée que l’on utilise les deux estimations de variance séparément, suivie d’une approximation des degrés de liberté pour la somme de ces deux variances.\nPar défaut, la fonction stats::t.test() réalise un test de Welch. Pour un test classique de Student, il faut lui préciser var.equal = TRUE.\nDe manière similaire, stats::oneway.test() ne présuppose pas, par défaut, l’égalité des variances et généralise donc le test de Welch au cas à trois modalités ou plus. Cependant, on peut là encore indiquer var.equal = TRUE, auquel cas une analyse de variance (ANOVA) classique sera réalisée, que l’on peut aussi obtenir avec stats::aov().\nIl est possible d’indiquer à gtsummary::add_p() des arguments additionnels à passer à la fonction utilisée pour réaliser le test :\n\ntrial |> \n  tbl_summary(\n    include = age,\n    by = trt,\n    statistic = all_continuous() ~ \"{mean} ({sd})\"\n  ) |> \n  add_p(\n    test = all_continuous() ~ \"t.test\",\n    test.args = all_continuous() ~ list(var.equal = TRUE)\n  )\n\n\n\n\n\n\nCaractéristique\n      \nDrug A, N = 981\n\n      \nDrug B, N = 1021\n\n      \np-valeur2\n\n    \n\n\nAge\n47 (15)\n47 (14)\n0,8\n\n\n    Manquant\n7\n4\n\n\n\n\n\n\n1 Moyenne (ET)\n    \n\n\n2 Two Sample t-test\n    \n\n\n\n\n\n\n\n\n19.2.5 Différence de deux moyennes\nLa fonctions gtsummary::add_difference() permet, pour une variable continue et si la variable catégorielle spécifiée via by n’a que deux modalités, de calculer la différence des deux moyennes, l’intervalle de confiance de cette différence et test si cette différence est significativement différente de 0 avec stats::t.test().\n\ntrial |> \n  tbl_summary(\n    include = age,\n    by = trt,\n    statistic = all_continuous() ~ \"{mean} ({sd})\"\n  ) |> \n  add_difference()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nDrug A, N = 981\n\n      \nDrug B, N = 1021\n\n      \nDifference2\n\n      \n95% IC2,3\n\n      \np-valeur2\n\n    \n\n\nAge\n47 (15)\n47 (14)\n-0,44\n-4,6 – 3,7\n0,8\n\n\n    Manquant\n7\n4\n\n\n\n\n\n\n\n\n1 Moyenne (ET)\n    \n\n\n2 test de Student\n    \n\n\n3 IC = intervalle de confiance\n    \n\n\nTable 19.14:  différence de deux moyennes"
  },
  {
    "objectID": "analyses/statistique-bivariee.html#sec-deux-variables-continues",
    "href": "analyses/statistique-bivariee.html#sec-deux-variables-continues",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.3 Deux variables continues",
    "text": "19.3 Deux variables continues\n\n19.3.1 Représentations graphiques\nLa comparaison de deux variables continues se fait en premier lieu graphique, en représentant, via un nuage de points, l’ensemble des couples de valeurs. Notez ici l’application d’un niveau de transparence (alpha) afin de faciliter la lecture des points superposés.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light()\n\n\n\nFigure 19.10: nuage de points\n\n\n\n\nLa géométrie ggplot2::geom_smooth() permets d’ajouter une courbe de tendance au graphique, avec son intervalle de confiance. Par défaut, il s’agit d’une régression polynomiale locale obtenue avec stats::loess().\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth() +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light()\n\n\n\nFigure 19.11: nuage de points avec une courbe de tendance\n\n\n\n\nPour afficher plutôt la droite de régression linéaire entre les deux variables, on précisera method = \"lm\".\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth(method = \"lm\") +\n  geom_point(colour = \"blue\", alpha = .25) +\n  theme_light()\n\n\n\nFigure 19.12: nuage de points avec droite de régression linéaire\n\n\n\n\nLa géométrie ggplot2::geom_rug() permet d’afficher une représentation synthétique de la densité de chaque variable sur les deux axes.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_smooth(method = \"lm\") +\n  geom_point(colour = \"blue\", alpha = .25) +\n  geom_rug() +\n  theme_light()\n\n\n\nFigure 19.13: nuage de points avec représentation synthétique des densités marginales\n\n\n\n\n\n19.3.2 Tester la relation entre les deux variables\nSi l’on a besoin de calculer le coefficient de corrélation de Pearson entre deux variables, on aura recours à stats::cor().\n\ncor(iris$Petal.Length, iris$Petal.Width)\n\n[1] 0.9628654\n\n\nPour aller plus loin, on peut calculer une régression linéaire entre les deux variables avec stats::lm().\n\nm <- lm(Petal.Length ~ Petal.Width, data = iris)\nsummary(m)\n\n\nCall:\nlm(formula = Petal.Length ~ Petal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.33542 -0.30347 -0.02955  0.25776  1.39453 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.08356    0.07297   14.85   <2e-16 ***\nPetal.Width  2.22994    0.05140   43.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4782 on 148 degrees of freedom\nMultiple R-squared:  0.9271,    Adjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: < 2.2e-16\n\n\nLes résultats montrent une corrélation positive et significative entre les deux variables.\nPour une présentation propre des résultats de la régression linéaire, on utilisera gtsummary::tbl_regression(). La fonction gtsummary::add_glance_source_note() permet d’ajouter différentes statistiques en notes du tableau de résultats.\n\nm |> \n  tbl_regression() |> \n  add_glance_source_note()\n\n\n\n\n\n\nCaractéristique\n      Beta\n      \n95% IC1\n\n      p-valeur\n    \n\nPetal.Width\n2,2\n2,1 – 2,3\n<0,001\n\n\nR² = 0,927; Adjusted R² = 0,927; Sigma = 0,478; Statistique = 1 882; p-valeur = <0,001; df = 1; Log-likelihood = -101; AIC = 208; BIC = 217; Deviance = 33,8; degrés de liberté des résidus = 148; No. Obs. = 150\n    \n\n\n1 IC = intervalle de confiance"
  },
  {
    "objectID": "analyses/statistique-bivariee.html#matrice-de-corrélations",
    "href": "analyses/statistique-bivariee.html#matrice-de-corrélations",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.4 Matrice de corrélations",
    "text": "19.4 Matrice de corrélations\nLe package GGally et sa fonction GGally::ggpairs() permettent de représenter facilement une matrice de corrélation entre plusieurs variables, tant quantitatives que qualitatives.\n\nlibrary(GGally)\nggpairs(iris)\n\n\n\nFigure 19.14: une matrice de corrélation avec ggpairs()\n\n\n\n\nGGally::ggpairs() et sa petite sœur GGally::ggduo() offrent de nombreuses options de personnalisation qui sont détaillées sur le site dédié du package.\n\nggpairs(trial, mapping = aes(colour = trt))\n\n\n\nFigure 19.15: un second example de matrice de corrélation"
  },
  {
    "objectID": "analyses/statistique-bivariee.html#webin-r",
    "href": "analyses/statistique-bivariee.html#webin-r",
    "title": "19  Statistique bivariée & Tests de comparaison",
    "section": "\n19.5 webin-R",
    "text": "19.5 webin-R\nLa statistique univariée est présentée dans le webin-R #03 (statistiques descriptives avec gtsummary et esquisse) sur YouTube."
  },
  {
    "objectID": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-continue",
    "href": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-continue",
    "title": "20  Régression linéaire",
    "section": "\n20.1 Modèle à une seule variable explicative continue",
    "text": "20.1 Modèle à une seule variable explicative continue\nNous avons déjà abordé très rapidement la régression linéaire dans le chapitre sur la statistique bivariée (cf. Section 19.3).\nReprenons le même exemple à partir du jeu de données iris qui comporte les caractéristiques de 150 fleurs de trois espèces différentes d’iris. Nous cherchons dans un premier temps à explorer la relation entre la largeur (Petal.Width) et la longueur des pétales (Petal.Length). Représentons cette relation sous la forme d’un nuage de points.\n\nlibrary(tidyverse)\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  labs(x = \"Longueur\", y = \"Largeur\") +\n  theme_light()\n\n\n\nFigure 20.1: Relation entre la largeur et la longueur des pétales (nuage de points)\n\n\n\n\nIl semble bien qu’il y a une relation linéaire entre ces deux variables, c’est-à-dire que la relation entre ces deux variables peut être représentée sous la forme d’une droite. Pour cela, on va rechercher la droite telle que la distance entre les points observés et la droite soit la plus petite possible. Cette droite peut être représentée graphique avec ggplot2::geom_smooth() et l’option method = \"lm\" :\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Longueur\", y = \"Largeur\") +\n  theme_light()\n\n\n\nFigure 20.2: Relation linéaire entre la largeur et la longueur des pétales\n\n\n\n\nLa fonction de base pour calculer une régression linéaire est la fonction stats::m(). On doit en premier lieu spécifier le modèle à l’aide d’une formule : on indique la variable à expliquer dans la partie gauche de la formule et la variable explicative dans la partie droite, les deux parties étant séparées par un tilde1 (~).1 Avec un clavier français, sous WIndows, le caracère tilde s’obtient en pressant simulténament les touches Alt Gr et 7.\nDans le cas présent, la variable Petal.Width fait office de variable à expliquer et Petal.Length de variable explicative. Le modèle s’écrit donc Petal.Width ~ Petal.Length.\n\nmod <- lm(Petal.Width ~ Petal.Length, data = iris)\nmod\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length, data = iris)\n\nCoefficients:\n (Intercept)  Petal.Length  \n     -0.3631        0.4158  \n\n\nLe résultat comporte deux coefficients. Le premier, d’une valeur de \\(0,4158\\), est associé à la variable Petal.Length et indique la pente de la courbe (on parle de slope en anglais). Le second, d’une valeur de \\(-0,3631\\), représente l’ordonnée à l’origine (intercept en anglais), c’est-à-dire la valeur estimée de Petal.Width lorsque Petal.Length vaut 0. Nous pouvons rendre cela plus visible en élargissant notre graphique.\n\nggplot(iris) +\n  aes(x = Petal.Length, y = Petal.Width) +\n  geom_point(colour = \"blue\", alpha = .25) +\n  geom_abline(\n    intercept = mod$coefficients[1],\n    slope = mod$coefficients[2],\n    linewidth = 1,\n    colour = \"red\"\n  ) +\n  geom_vline(xintercept = 0, linewidth = 1, linetype = \"dotted\") +\n  labs(x = \"Longueur\", y = \"Largeur\") +\n  expand_limits(x = 0, y = -1) +\n  theme_light()\n\n\n\nFigure 20.3: Relation linéaire entre la largeur et la longueur des pétales (représentation graphique de l’intercept)\n\n\n\n\nLe modèle linéaire calculé estime donc que le relation entre nos deux variables peut s’écrire sous la forme suivante :\n\\[\nPetal.Width = 0,4158 \\cdot Petal.Length - 0,3631\n\\]\nLe package gtsummary fournit gtsummary::tbl_regression(), une fonction bien pratique pour produire un tableau propre avec les coefficients du modèle, leur intervalle de confiance à 95% et leur p-valeurs2. On précisera intercept = TRUE pour forcer l’affichage de l’intercept qui est masqué par défaut.2 Si l’on a besoin de ces informations sous la forme d’un tableau de données classique, on pourra se référer à broom.helpers::tidy_plus_plus(), utilisée de manière sous-jacente par gtsummary::tbl_regression(), ainsi qu’à la méthode broom::tidy(). Ces fonctions sont génériques et peut être utilisées avec une très grande variété de modèles.\n\nlibrary(gtsummary)\n\n#StandWithUkraine\n\nmod %>%\n  tbl_regression(intercept = TRUE)\n\n\n\n\n\n\n\n  \n  \nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n-0.36\n-0.44, -0.28\n<0.001\n\n\nPetal.Length\n0.42\n0.40, 0.43\n<0.001\n\n\n\n\n1 CI = Confidence Interval\n    \n\nTable 20.1:  un tableau mis en forme des coefficients du modèle \n\n\n\nLes p-valeurs calculées nous indique si le coefficient est statistiquement différent de 0. En effet, pour la variable explicative, cela nous indique si la relation est statistiquement significative. Le signe du coefficient (positif ou négatif) nous indique le sens de la relation.\n\n\n\n\n\n\nAstuce\n\n\n\nDans certains cas, si l’on suppose que la relation entre les deux variables est proportionnelle, on peut souhaiter calculer un modèle sans intercept. Par défaut, R ajoute un intercept à ses modèles. Pour forcer le calcul d’un modèle sans intercept, on ajoutera - 1 à la formule défissant le modèle.\n\nlm(Petal.Width ~ Petal.Length - 1, data = iris)\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length - 1, data = iris)\n\nCoefficients:\nPetal.Length  \n      0.3365"
  },
  {
    "objectID": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-categorielle",
    "href": "analyses/regression-lineaire.html#sec-regression-lineaire-variable-explicative-categorielle",
    "title": "20  Régression linéaire",
    "section": "\n20.2 Modèle à une seule variable explicative catégorielle",
    "text": "20.2 Modèle à une seule variable explicative catégorielle\nSi dans un modèle linéaire la variable à expliquer est nécessairement continue, il est possible de définir une variable explicative catégorielle. Prenons la variable Species.\n\nlibrary(labelled)\niris %>% look_for(\"Species\")\n\n pos variable label col_type missing values    \n 5   Species  —     fct      0       setosa    \n                                     versicolor\n                                     virginica \n\n\nIl s’agit d’un facteur à trois modalités. Par défaut, la première valeur du facteur (ici setosa) va servir de modalité de référence.\n\nmod <- lm(Petal.Width ~ Species, data = iris)\nmod\n\n\nCall:\nlm(formula = Petal.Width ~ Species, data = iris)\n\nCoefficients:\n      (Intercept)  Speciesversicolor   Speciesvirginica  \n            0.246              1.080              1.780  \n\n\n\nmod %>%\n  tbl_regression(intercept = TRUE)\n\n\n\n\n\n\n\n  \n  \nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n0.25\n0.19, 0.30\n<0.001\n\n\nSpecies\n\n\n\n\n\n    setosa\n—\n—\n\n\n\n    versicolor\n1.1\n1.0, 1.2\n<0.001\n\n\n    virginica\n1.8\n1.7, 1.9\n<0.001\n\n\n\n\n1 CI = Confidence Interval\n    \n\nTable 20.2:  régression linaire avec une variable explicative catégorielle \n\n\n\nDans ce cas de figure, l’intercept représente la situation à la référence, donc pour l’espèce setosa.\nCalculons les moyennes par espèce :\n\niris %>%\n  group_by(Species) %>%\n  summarise(mean(Petal.Width))\n\n# A tibble: 3 × 2\n  Species    `mean(Petal.Width)`\n  <fct>                    <dbl>\n1 setosa                   0.246\n2 versicolor               1.33 \n3 virginica                2.03 \n\n\nComme on le voit, l’intercept nous indique donc la moyenne observée pour l’espèce de référence (\\(0,246\\)).\nLe coefficient associé à versicolor correspond à la différence par rapport à la référence (ici \\(+1,080\\)). Comme vous pouvez le constater, il s’agit de la différence entre la moyenne observée pour versicolor (\\(1,326\\)) et celle de la référence setosa (\\(0,246\\)) : \\(1,326-0,246=1,080\\).\nCe coefficient est significativement différent de 0 (p<0,001), indiquant que la largeur des pétales diffère significativement entre les deux espèces.\n\n\n\n\n\n\nAstuce\n\n\n\nLorsque l’on calcule le même modèle sans intercept, les coefficients s’interprètent un différement :\n\nlm(Petal.Width ~ Species - 1, data = iris)\n\n\nCall:\nlm(formula = Petal.Width ~ Species - 1, data = iris)\n\nCoefficients:\n    Speciessetosa  Speciesversicolor   Speciesvirginica  \n            0.246              1.326              2.026  \n\n\nEn l’absence d’intercept, trois coefficients sont calculés et il n’y a plus ici de modalité de référence. Chaque coefficient représente donc la moyenne observée pour chaque modalité.\nOn appelle contrastes les différents manières de coder des variables catégorielles dans un modèle. Nous y reviendrons plus en détail dans un chapitre dédié (cf. Chapitre 23)."
  },
  {
    "objectID": "analyses/regression-lineaire.html#sec-regression-lineaire-multivariee",
    "href": "analyses/regression-lineaire.html#sec-regression-lineaire-multivariee",
    "title": "20  Régression linéaire",
    "section": "\n20.3 Modèle à plusieurs variables explicatives",
    "text": "20.3 Modèle à plusieurs variables explicatives\nUn des intérêts de la régression linéaire est de pouvoir estimer un modèle multivarié, c’est-à-dire avec plusieurs variables explicatives. Pour cela, on listera les différentes variables explicatives dans la partioe droite de la formule, séparées par le symbole +.\n\nmod <- lm(\n  Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length + Species,\n  data = iris\n)\nmod\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length + \n    Species, data = iris)\n\nCoefficients:\n      (Intercept)       Petal.Length        Sepal.Width       Sepal.Length  \n         -0.47314            0.24220            0.24220           -0.09293  \nSpeciesversicolor   Speciesvirginica  \n          0.64811            1.04637  \n\n\n\nmod %>%\n  tbl_regression(intercept = TRUE)\n\n\n\n\n\n\n\n  \n  \nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n-0.47\n-0.82, -0.12\n0.008\n\n\nPetal.Length\n0.24\n0.15, 0.34\n<0.001\n\n\nSepal.Width\n0.24\n0.15, 0.34\n<0.001\n\n\nSepal.Length\n-0.09\n-0.18, 0.00\n0.039\n\n\nSpecies\n\n\n\n\n\n    setosa\n—\n—\n\n\n\n    versicolor\n0.65\n0.40, 0.89\n<0.001\n\n\n    virginica\n1.0\n0.72, 1.4\n<0.001\n\n\n\n\n1 CI = Confidence Interval\n    \n\nTable 20.3:  régression linaire avec plusieurs variables explicatives \n\n\n\nCe type de modèle permet d’estimer l’effet de chaque variable explicative, toutes choses égales par ailleurs. Dans le cas présent, on s’aperçoit que la largeur des pétales diffère significativement selon les espèces, est fortement corrélée positivement à la longueur du pétale et la largeur du sépale et qu’il y a, lorsque l’on ajuste sur l’ensemble des autres variables, une relation négative (faiblement significative) avec la longueur du sépale.\nLorsque le nombre de coefficients est élevé, une représentation graphique est souvent plus facile à lire qu’un tableau. On parle alors de graphique en forêt ou forest plot en anglais. Rien de plus facile ! Il suffit d’avoir recours à ggstats::ggcoef_model().\n\nlibrary(ggstats)\nggcoef_model(mod)\n\n\n\nFigure 20.4: un graphique en forêt des coefficients du modèle"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#préparation-des-données",
    "href": "analyses/regression-logistique-binaire.html#préparation-des-données",
    "title": "21  Régression logistique binaire",
    "section": "\n21.1 Préparation des données",
    "text": "21.1 Préparation des données\nDans ce chapite, nous allons encore une fois utiliser les données de l’enquête Histoire de vie, fournies avec l’extension questionr.\n\ndata(hdv2003, package = \"questionr\")\nd <- hdv2003\n\nÀ titre d’exemple, nous allons étudier l’effet de l’âge, du sexe, du niveau d’étude, de la pratique religieuse et du nombre moyen d’heures passées à regarder la télévision par jour sur la probabilité de pratiquer un sport.\nEn premier lieu, il importe de vérifier, par exemple avec labelled::look_for(), que notre variable d’intérêt (ici sport) est correctement codée, c’est-à-dire que la première modalité correspondent à la référence (soit ne pas avoir vécu l’événement d’intérêt) et que la seconde modalité corresponde au fait d’avoir vécu l’événement.\n\nlibrary(labelled)\nd |> look_for(\"sport\")\n\n pos variable label col_type missing values\n 19  sport    —     fct      0       Non   \n                                     Oui   \n\n\nDans notre exemple, la modalité Non est déjà la première modalité. Il n’y a donc pas besoin de modifier notre variable.\nIl faut également la présence éventuelle de données manquantes (NA)1. Les observations concernées seront tout simplement exclues du modèle lors de son calcul. Ce n’est pas notre cas ici.1 Pour visualiser le nombre de données manquantes (NA) de l’ensemble des variables d’un tableau, on pourra avoir recours à questionr::freq.na().\n\n\n\n\n\n\nAstuce\n\n\n\nAlternativement, on pourra aussi coder notre variable à expliquer sous forme booléenne (FALSE / TRUE) ou numériquement en 0/1.\nIl est possible d’indiquer un facteur à plus de deux modalités. Dans une telle situation, R considérera que tous les modalités, sauf la modalité de référence, est une réalisation de la variable d’intérêt. Cela serait correct, par exemple, si notre variable sport était codée ainsi : Non, Oui, de temps en temps, Oui, régulièrement. Cependant, afin d’éviter tout risque d’erreur ou de mauvaise interprétation, il est vivement conseillé de recoder au préalable sa variable d’intérêt en un facteur à deux modalités.\n\n\nLa notion de modalité de référence s’applique également aux variables explicatives catégorielles. En effet, dans un modèle, tous les coefficients sont calculés par rapport à la modalité de référence (cf. Section 20.2). Il importe donc de choisir une modalité de référence qui fasse sens afin de faciliter l’interprétation. Par ailleurs, ce choix doit dépendre de la manière dont on souhaite présenter les résultats (le data storytelling est essentiel). De manière générale on évitera de choisir comme référence une modalité peu représentée dans l’échantillon ou bien une modalité correspondant à une situation atypique.\nPrenons l’exemple de la variable sexe. Souhaite-t-on connaitre l’effet d’être une femme par rapport au fait d’être un homme ou bien l’effet d’être un homme par rapport au fait d’être une femme ? Si l’on opte pour le second, alors notre modalité de référence sera le sexe féminin. Comme est codée cette variable ?\n\nd |> look_for(\"sexe\")\n\n pos variable label col_type missing values\n 3   sexe     —     fct      0       Homme \n                                     Femme \n\n\nLa modalité Femme s’avère ne pas être la première modalité. Nous devons appliquer la fonction forcats::fct_relevel() ou la fonction stats::relevel() :\n\nlibrary(tidyverse)\nd <- d |> \n  mutate(sexe = sexe |> fct_relevel(\"Femme\"))\n\n\nd$sexe |> questionr::freq()\n\n         n  % val%\nFemme 1101 55   55\nHomme  899 45   45\n\n\n\nDonnées labellisées\nSi l’on utilise des données labellisées (voir Chapitre 12), nos variables catégorielles seront stockées sous la forme d’un vecteur numérique avec des étiquettes. Il sera donc nécessaire de convertir ces variables en facteurs, tout simplement avec labelled::to_factor() ou labelled::unlabelled().\n\nLes variables age et heures.tv sont des variables quantitatives. Il importe de vérifier qu’elles sont bien enregistrées en tant que variables numériques. En effet, il arrive parfois que dans le fichier source les variables quantitatives soient renseignées sous forme de valeur textuelle et non sous forme numérique.\n\nd |> look_for(\"age\", \"heures\")\n\n pos variable  label col_type missing values\n 2   age       —     int      0             \n 20  heures.tv —     dbl      5             \n\n\nNos deux variables sont bien renseignées sous forme numérique (respectivement des entiers et des nombres décimaux).\nCependant, l’effet de l’âge est rarement linéaire. Un exemple trivial est par exemple le fait d’occuper un emploi qui sera moins fréquent aux jeunes âges et aux âges élevés. Dès lors, on pourra transformer la variable age en groupe d’âges (et donc en variable catégorielle) avec la fonction cut() (cf. Section 9.4) :\n\nd <- d |> \n  mutate(\n    groupe_ages = age |>\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      )\n  )\nd$groupe_ages |> questionr::freq()\n\n                 n    % val%\n18-24 ans      169  8.5  8.5\n25-44 ans      706 35.3 35.3\n45-64 ans      745 37.2 37.2\n65 ans et plus 380 19.0 19.0\n\n\nJetons maintenant un oeil à la variable nivetud :\n\nd$nivetud |> questionr::freq()\n\n                                                                  n    % val%\nN'a jamais fait d'etudes                                         39  2.0  2.1\nA arrete ses etudes, avant la derniere annee d'etudes primaires  86  4.3  4.6\nDerniere annee d'etudes primaires                               341 17.0 18.1\n1er cycle                                                       204 10.2 10.8\n2eme cycle                                                      183  9.2  9.7\nEnseignement technique ou professionnel court                   463 23.2 24.5\nEnseignement technique ou professionnel long                    131  6.6  6.9\nEnseignement superieur y compris technique superieur            441 22.0 23.4\nNA                                                              112  5.6   NA\n\n\nEn premier lieu, cette variable est détaillée en pas moins de huit modalités dont certaines sont peu représentées (seulement 39 individus soit 2 % n’ont jamais fait d’études par exemple). Afin d’améliorier notre modèle logistique, il peut être pertinent de regrouper certaines modalités (cf. Section 9.3) :\n\nd <- d |> \n  mutate(\n    etudes = nivetud |> \n      fct_recode(\n      \"Primaire\" = \"N'a jamais fait d'etudes\",\n      \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n      \"Primaire\" = \"Derniere annee d'etudes primaires\",\n      \"Secondaire\" = \"1er cycle\",\n      \"Secondaire\" = \"2eme cycle\",\n      \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n      \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n      \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    )    \n  )\nd$etudes |> questionr::freq()\n\n                            n    % val%\nPrimaire                  466 23.3 24.7\nSecondaire                387 19.4 20.5\nTechnique / Professionnel 594 29.7 31.5\nSupérieur                 441 22.0 23.4\nNA                        112  5.6   NA\n\n\nNotre variable comporte également 112 individus avec une valeur manquante. Si nous conservons cette valeur manquante, ces 112 individus seront, par défaut, exclus de l’analyse. Ces valeurs manquantes n’étant pas négligeable (5,6 %), nous pouvons également faire le choix de considérer ces valeurs manquantes comme une modalité supplémentaire. Auquel cas, nous utiliserons la fonction forcats::fct_explicit_na()  :\n\nd$etudes <- d$etudes |> \n  fct_explicit_na(\"Non documenté\")\n\nEnfin, pour améliorer les différentes sorties (tableaux et figures), nous allons ajouter des étiquettes de variables (cf. Chapitre 11) avec labelled::set_variable_labels().\n\nd <- d |> \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    relig = \"Rapport à la religion\",\n    heures.tv = \"Heures de télévision / jour\"\n  )\n\n\n\n\n\n\n\nCode récapitulatif (préparation des données)\n\n\n\n\ndata(hdv2003, package = \"questionr\")\nd <-\n  hdv2003 |> \n  mutate(\n    sexe = sexe |> fct_relevel(\"Femme\"),\n    groupe_ages = age |>\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |> \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |> \n    fct_explicit_na(\"Non documenté\")  \n  ) |> \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    relig = \"Rapport à la religion\",\n    heures.tv = \"Heures de télévision / jour\"\n  )"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#statistiques-descriptives",
    "href": "analyses/regression-logistique-binaire.html#statistiques-descriptives",
    "title": "21  Régression logistique binaire",
    "section": "\n21.2 Statistiques descriptives",
    "text": "21.2 Statistiques descriptives\nAvant toute analyse multivariée, il est toujours bon de procéder à une analyse descriptive bivariée simple, tout simplement avec gtsummary::tbl_summary(). Ajoutons quelques tests de comparaison avec gtsummary::add_p(). Petite astuce : gtsummary::modify_spanning_header() permet de rajouter un en-tête sur plusieurs colonnes.\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\", big.mark = \" \")\n\n\nd |> \n  tbl_summary(\n    by = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv)\n  ) |>\n  add_overall(last = TRUE) |> \n  add_p() |> \n  bold_labels() |> \n  modify_spanning_header(\n    update = all_stat_cols() ~ \"**Pratique un sport ?**\"\n  )\n\n\n\n\n\n\n\n  \n  \n\nCaractéristique\n      \n        Pratique un sport ?\n      \n      \np-valeur2\n\n    \n\n\nNon, N = 1 2771\n\n      \nOui, N = 7231\n\n      \nTotal, N = 2 0001\n\n    \n\n\n\nSexe\n\n\n\n<0,001\n\n\n    Femme\n747 (58%)\n354 (49%)\n1 101 (55%)\n\n\n\n    Homme\n530 (42%)\n369 (51%)\n899 (45%)\n\n\n\nGroupe d'âges\n\n\n\n<0,001\n\n\n    18-24 ans\n58 (4,5%)\n111 (15%)\n169 (8,5%)\n\n\n\n    25-44 ans\n359 (28%)\n347 (48%)\n706 (35%)\n\n\n\n    45-64 ans\n541 (42%)\n204 (28%)\n745 (37%)\n\n\n\n    65 ans et plus\n319 (25%)\n61 (8,4%)\n380 (19%)\n\n\n\nNiveau d'études\n\n\n\n<0,001\n\n\n    Primaire\n416 (33%)\n50 (6,9%)\n466 (23%)\n\n\n\n    Secondaire\n270 (21%)\n117 (16%)\n387 (19%)\n\n\n\n    Technique / Professionnel\n378 (30%)\n216 (30%)\n594 (30%)\n\n\n\n    Supérieur\n186 (15%)\n255 (35%)\n441 (22%)\n\n\n\n    Non documenté\n27 (2,1%)\n85 (12%)\n112 (5,6%)\n\n\n\nRapport à la religion\n\n\n\n0,14\n\n\n    Pratiquant regulier\n182 (14%)\n84 (12%)\n266 (13%)\n\n\n\n    Pratiquant occasionnel\n295 (23%)\n147 (20%)\n442 (22%)\n\n\n\n    Appartenance sans pratique\n473 (37%)\n287 (40%)\n760 (38%)\n\n\n\n    Ni croyance ni appartenance\n239 (19%)\n160 (22%)\n399 (20%)\n\n\n\n    Rejet\n60 (4,7%)\n33 (4,6%)\n93 (4,7%)\n\n\n\n    NSP ou NVPR\n28 (2,2%)\n12 (1,7%)\n40 (2,0%)\n\n\n\nHeures de télévision / jour\n2,00 (1,00 – 3,00)\n2,00 (1,00 – 3,00)\n2,00 (1,00 – 3,00)\n<0,001\n\n\n    Manquant\n2\n3\n5\n\n\n\n\n\n\n1 n (%); Médiane (EI)\n    \n\n\n2 test du khi-deux d'indépendance; test de Wilcoxon-Mann-Whitney\n    \n\n\nTable 21.1:  Pratique d’un sport selon différentes variables explicatives (analyse bivariée)"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#calcul-de-la-régression-logistique-binaire",
    "href": "analyses/regression-logistique-binaire.html#calcul-de-la-régression-logistique-binaire",
    "title": "21  Régression logistique binaire",
    "section": "\n21.3 Calcul de la régression logistique binaire",
    "text": "21.3 Calcul de la régression logistique binaire\nLa spécification d’une régression logistique se fait avec stats::glm() et est très similaire à celle d’une régression linéaire simple (cf. Section 20.3) : on indique la variable à expliquer suivie d’un tilde (~) puis des variables explicatives séparées par un plus (+)2. Il faut indiquer à glm() la famille du modèle souhaité : on indiquera simplement family = binomial pour un modèle logit3.2 Il est possible de spécifier des modèles plus complexes, notamment avec des effets d’interaction, qui seront aborder plus loin (cf. Chapitre 24).3 Pour un modèle probit, on indiquera family = binomial(\"probit\").\n\nmod <- glm(\n  sport ~ sexe + groupe_ages + etudes + relig + heures.tv,\n  family = binomial,\n  data = d\n)\n\nPour afficher les résultats du modèle, le plus simple est d’avoir recours à gtsummary::tbl_regression().\n\nmod |> \n  tbl_regression(intercept = TRUE) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nlog(OR)1\n\n      \n95% IC1\n\n      p-valeur\n    \n\n\n(Intercept)\n-0,80\n-1,4 – -0,17\n0,014\n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n0,44\n0,23 – 0,65\n<0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n-0,42\n-0,87 – 0,03\n0,065\n\n\n    45-64 ans\n-1,1\n-1,6 – -0,62\n<0,001\n\n\n    65 ans et plus\n-1,4\n-1,9 – -0,85\n<0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n0,95\n0,57 – 1,3\n<0,001\n\n\n    Technique / Professionnel\n1,0\n0,68 – 1,4\n<0,001\n\n\n    Supérieur\n1,9\n1,5 – 2,3\n<0,001\n\n\n    Non documenté\n2,2\n1,5 – 2,8\n<0,001\n\n\nRapport à la religion\n\n\n\n\n\n    Pratiquant regulier\n—\n—\n\n\n\n    Pratiquant occasionnel\n-0,02\n-0,39 – 0,35\n>0,9\n\n\n    Appartenance sans pratique\n-0,01\n-0,35 – 0,34\n>0,9\n\n\n    Ni croyance ni appartenance\n-0,22\n-0,59 – 0,16\n0,3\n\n\n    Rejet\n-0,38\n-0,95 – 0,17\n0,2\n\n\n    NSP ou NVPR\n-0,08\n-0,92 – 0,70\n0,8\n\n\nHeures de télévision / jour\n-0,12\n-0,19 – -0,06\n<0,001\n\n\n\n\n1 OR = rapport de cotes, IC = intervalle de confiance\n    \n\nTable 21.2:  Facteurs associés à la pratique d’un sport (régression logistique binaire)"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#interpréter-les-coefficients",
    "href": "analyses/regression-logistique-binaire.html#interpréter-les-coefficients",
    "title": "21  Régression logistique binaire",
    "section": "\n21.4 Interpréter les coefficients",
    "text": "21.4 Interpréter les coefficients\nL’intercept traduit la situation à la référence (i.e. toutes les variables catégorielles à leur modalité de référence et les variables continues à 0), après transformation selon la fonction de lien (i.e. après la transformation logit).\nIllustrons cela. Supposons donc une personne de sexe féminin, âgée entre 18 et 24 ans, de niveau d’étude primaire, pratiquante régulière et ne regardant pas la télévision (situation de réference). Seul l’intercept s’applique dans le modèle, et donc le modèle prédit que sa probabilité de faire du sport est de \\(-0,80\\) selon l’échelle logit. Retraduisons cela en probabilité classique avec la fonction logit inverse.\n\nlogit_inverse <- binomial(\"logit\") |> purrr::pluck(\"linkinv\")\nlogit_inverse(-0.80)\n\n[1] 0.3100255\n\n\nSelon le modèle, la probabilité que cette personne fasse du sport est donc de \\(31\\%\\).\nPrenons maintenant une personne identique mais de sexe masculin. Nous devons donc considérer, en plus de l’intercept, le coefficient associé à la modalité Homme. Sa probabilité de faire du sport est donc :\n\nlogit_inverse(-0.80 + 0.44)\n\n[1] 0.4109596\n\n\nLe coefficient associé à Homme est donc un modificateur par rapport à la situation de référence.\nEnfin, considérons que cette dernière personne regarde également la télévision 2 heures en moyenne par jour. Nous devons alors considérer le coefficient associé à la variable heures.tv et, comme il s’agit d’une variable continue, multiplier ce coefficient par 2, car le coefficient représente le changement pour un incrément de 1 unité.\n\nlogit_inverse(-0.80 + 0.44 + 2 * -0.12)\n\n[1] 0.3543437\n\n\nIl est crucial de bien comprendre comment dans quels cas et comment chaque coefficient est utilisé par le modèle.\nLe package {breakdown} permet de mieux visualiser notre dernier exemple.\n\nindividu3 <- d[1, ]\nindividu3$sexe[1] <- \"Homme\"\nindividu3$groupe_ages[1] <- \"18-24 ans\"\nindividu3$etudes[1] <- \"Primaire\"\nindividu3$relig[1] <- \"Pratiquant regulier\"\nindividu3$heures.tv[1] <- 2\n\n\nlibrary(breakDown)\nlogit <- function(x) exp(x) / (1 + exp(x))\nplot(\n  broken(mod, individu3, predict.function = betas),\n  trans = logit\n) +\n  scale_y_continuous(\n    labels = scales::label_percent(),\n    breaks = 0:5/5,\n    limits = c(0, 1)\n  )\n\n\n\nDécomposition de la probabilité de faire du sport de l’individu 3"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#la-notion-dodds-ratio",
    "href": "analyses/regression-logistique-binaire.html#la-notion-dodds-ratio",
    "title": "21  Régression logistique binaire",
    "section": "\n21.5 La notion d’odds ratio\n",
    "text": "21.5 La notion d’odds ratio\n\nL’un des intérêts de la régression logistique logit réside dans le fait que l’exponentiel des coefficients correspond à des odds ratio ou rapport des côtes en français.\n\n\n\n\n\n\nAstuce\n\n\n\nPour comprendre la notion de côte (odd en anglais), on peut se référer aux paris sportifs. Par exemple, lorsque les trois quarts des parieurs parient que le cheval A va remporter la course, on dit alors que ce cheval à une côte de trois contre un (trois personnes parient qu’il va gagner contre une personne qu’il va perdre). Prenon un autre cheval : si les deux tiers pensent que le cheval B va perdre (donc un tiers pense qu’il va gagner), on dira alors que sa côte est de un contre deux (une personne pense qu’il va gagner contre deux qu’il va perdre).\nSi l’on connait la proportion ou probabilité p d’avoir vécu ou de vivre un événenement donné (ici gagner la course), la côte (l’odd) s’obtient avec la formule suivante : \\(p/(1-p)\\). La côte du cheval A est bien \\(0,75/(1-0,75)=0,75/0,25=3\\) est celle du cheval B \\((1/3)/(2/3)=1/2=0,5\\).\nPour comparer deux côtes (par exemple pour savoir si le cheval A a une probabilité plus élevée de remporter la course que le cheval B, selon les parieurs), on calculera tout simplement le rapport des côtes ou odds ratio (OR) : \\(OR_{A/B}=Odds_{A}/Odds_{B}=3/0,5=6\\).\nCe calcul peut se faire facilement dans R avec la fonction questionr::odds.ratio().\n\nquestionr::odds.ratio(.75, 1/3)\n\n[1] 6\n\n\nL’odds ratio est donc égal à 1 si les deux côtes sont identiques, est supérieur à 1 si le cheval A une probabilité supérieure à celle du cheval B, et inférieur à 1 si c’est probabilité est inférieure.\nOn le voit, par construction, l’odds ratio de B par rapport à A est l’inverse de celui de A par rapport à B : \\(OR_{B/A}=1/OR_{A/B}\\).\n\n\nPour afficher les odds ratio il suffit d’indiquer exponentiate = TRUE à gtsummary::tbl_regression().\n\nmod |> \n  tbl_regression(exponentiate = TRUE) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nOR1\n\n      \n95% IC1\n\n      p-valeur\n    \n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,55\n1,26 – 1,91\n<0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,66\n0,42 – 1,03\n0,065\n\n\n    45-64 ans\n0,34\n0,21 – 0,54\n<0,001\n\n\n    65 ans et plus\n0,25\n0,15 – 0,43\n<0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,59\n1,77 – 3,83\n<0,001\n\n\n    Technique / Professionnel\n2,86\n1,98 – 4,17\n<0,001\n\n\n    Supérieur\n6,63\n4,55 – 9,80\n<0,001\n\n\n    Non documenté\n8,59\n4,53 – 16,6\n<0,001\n\n\nRapport à la religion\n\n\n\n\n\n    Pratiquant regulier\n—\n—\n\n\n\n    Pratiquant occasionnel\n0,98\n0,68 – 1,42\n>0,9\n\n\n    Appartenance sans pratique\n0,99\n0,71 – 1,40\n>0,9\n\n\n    Ni croyance ni appartenance\n0,81\n0,55 – 1,18\n0,3\n\n\n    Rejet\n0,68\n0,39 – 1,19\n0,2\n\n\n    NSP ou NVPR\n0,92\n0,40 – 2,02\n0,8\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n<0,001\n\n\n\n\n1 OR = rapport de cotes, IC = intervalle de confiance\n    \n\nTable 21.3:  Facteurs associés à la pratique d’un sport (odds ratios) \n\n\n\nPour une représentation visuelle, graphique en forêt ou forest plot en anglais, on aura tout simplement recours à ggstats::ggcoef_model().\n\nmod |> \n  ggstats::ggcoef_model(exponentiate = TRUE)\n\n\n\nFigure 21.1: Facteurs associés à la pratique d’un sport (forest plot)\n\n\n\n\n\n\n\n\n\n\nMise en garde\n\n\n\nEn rédigeant les résultats de la régression, il faudra être vigilant à ne pas confondre les odds ratios avec des prevalence ratios. Avec un odds ratio de 1,55, il serait tentant d’écrire que les hommes ont une probabilité 55% supérieure de pratique un sport que les femmes (toutes choses égales par ailleurs). Une telle formulation correspond à un prevalence ratio (rapport des prévalences en français) ou risk ratio (rapport des risques), à savoir diviser la probabilité de faire du sport des hommes par celle des femmes, \\(p_{hommes}/p_{femmes}\\). Or, cela ne correspond pas à la formule de l’odds ratio, à savoir \\((p_{hommes}/(1-p_{hommes}))/(p_{femmes}/(1-p_{femmes}))\\).\nLorsque le phénomène étudié est rare et donc que les probabilités sont faibles (inférieures à quelques pourcents), alors il est vrai que les odds ratio sont approximativement égaux aux prevalence ratios. Mais ceci n’est plus du tout vrai pour des phénomènes plus fréquents."
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#afficher-toutes-les-comparaisons-pairwise-contrasts",
    "href": "analyses/regression-logistique-binaire.html#afficher-toutes-les-comparaisons-pairwise-contrasts",
    "title": "21  Régression logistique binaire",
    "section": "\n21.6 Afficher toutes les comparaisons (pairwise contrasts)",
    "text": "21.6 Afficher toutes les comparaisons (pairwise contrasts)\nDans le tableau des résultats (Table 21.3), pour les variables catégorielles, il importe de bien garder en mémoire que chaque odds ratio doit se comparer à la valeur de référence. Ainsi, les odds ratios affichés pour chaque classe d’âges correspondent à une comparaison avec la classe d’âges de références, les 18-24 ans. La p-valeur associée nous indique quant à elle si cet odds ratio est significativement de 1, donc si cette classe d’âges données se comporte différemment de celle de référence.\nMais cela ne nous dit nullement si les 65 ans et plus diffèrent des 45-64 ans. Il est tout à fait possible de recalculer l’odds ratio correspondant en rapport les odds ratio à la référence : \\(OR_{65+/45-64}=OR_{65+/18-24}/OR_{45-64/18-24}\\).\nLe package emmeans et sa fonction emmeans::emmeans() permettent de recalculer toutes les combinaisons d’odds ratio (on parle alors de pairwise contrasts) ainsi que leur intervalle de confiance et la p-valeur correspondante.\nOn peut ajouter facilement4 cela au tableau produit avec gtsummary::tbl_regression() en ajoutant l’option add_pairwise_contrasts = TRUE.4 Cela nécessite néanmoins au minimum la version 1.11.0 du package broom.helpers et la version 1.6.3 de gtsummary.\n\nmod |> \n  tbl_regression(\n    exponentiate = TRUE,\n    add_pairwise_contrasts = TRUE\n  ) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nOR1\n\n      \n95% IC1\n\n      p-valeur\n    \n\n\nSexe\n\n\n\n\n\n    Homme / Femme\n1,55\n1,26 – 1,91\n<0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    (25-44 ans) / (18-24 ans)\n0,66\n0,37 – 1,18\n0,3\n\n\n    (45-64 ans) / (18-24 ans)\n0,34\n0,18 – 0,62\n<0,001\n\n\n    (45-64 ans) / (25-44 ans)\n0,51\n0,38 – 0,70\n<0,001\n\n\n    65 ans et plus / (18-24 ans)\n0,25\n0,12 – 0,51\n<0,001\n\n\n    65 ans et plus / (25-44 ans)\n0,38\n0,24 – 0,61\n<0,001\n\n\n    65 ans et plus / (45-64 ans)\n0,74\n0,47 – 1,17\n0,3\n\n\nNiveau d'études\n\n\n\n\n\n    Secondaire / Primaire\n2,59\n1,51 – 4,43\n<0,001\n\n\n    (Technique / Professionnel) / Primaire\n2,86\n1,70 – 4,79\n<0,001\n\n\n    (Technique / Professionnel) / Secondaire\n1,10\n0,74 – 1,64\n>0,9\n\n\n    Supérieur / Primaire\n6,63\n3,89 – 11,3\n<0,001\n\n\n    Supérieur / Secondaire\n2,56\n1,69 – 3,88\n<0,001\n\n\n    Supérieur / (Technique / Professionnel)\n2,32\n1,61 – 3,36\n<0,001\n\n\n    Non documenté / Primaire\n8,59\n3,49 – 21,1\n<0,001\n\n\n    Non documenté / Secondaire\n3,32\n1,46 – 7,53\n<0,001\n\n\n    Non documenté / (Technique / Professionnel)\n3,01\n1,38 – 6,56\n0,001\n\n\n    Non documenté / Supérieur\n1,30\n0,58 – 2,90\n>0,9\n\n\nRapport à la religion\n\n\n\n\n\n    Pratiquant occasionnel / Pratiquant regulier\n0,98\n0,57 – 1,68\n>0,9\n\n\n    Appartenance sans pratique / Pratiquant regulier\n0,99\n0,60 – 1,63\n>0,9\n\n\n    Appartenance sans pratique / Pratiquant occasionnel\n1,02\n0,68 – 1,52\n>0,9\n\n\n    Ni croyance ni appartenance / Pratiquant regulier\n0,81\n0,47 – 1,40\n0,9\n\n\n    Ni croyance ni appartenance / Pratiquant occasionnel\n0,82\n0,52 – 1,31\n0,8\n\n\n    Ni croyance ni appartenance / Appartenance sans pratique\n0,81\n0,54 – 1,21\n0,7\n\n\n    Rejet / Pratiquant regulier\n0,68\n0,30 – 1,54\n0,8\n\n\n    Rejet / Pratiquant occasionnel\n0,70\n0,33 – 1,49\n0,8\n\n\n    Rejet / Appartenance sans pratique\n0,69\n0,33 – 1,41\n0,7\n\n\n    Rejet / Ni croyance ni appartenance\n0,85\n0,40 – 1,79\n>0,9\n\n\n    NSP ou NVPR / Pratiquant regulier\n0,92\n0,29 – 2,97\n>0,9\n\n\n    NSP ou NVPR / Pratiquant occasionnel\n0,94\n0,30 – 2,92\n>0,9\n\n\n    NSP ou NVPR / Appartenance sans pratique\n0,93\n0,30 – 2,82\n>0,9\n\n\n    NSP ou NVPR / Ni croyance ni appartenance\n1,14\n0,37 – 3,55\n>0,9\n\n\n    NSP ou NVPR / Rejet\n1,35\n0,37 – 4,88\n>0,9\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n<0,001\n\n\n\n\n1 OR = rapport de cotes, IC = intervalle de confiance\n    \n\nTable 21.4:  Facteurs associés à la pratique d’un sport (pairwise contrasts) \n\n\n\nDe même, on peur visualiser les coefficients avec la même option dans ggstats::ggcoef_model()5. On peut d’ailleurs choisir les variables concernées avec l’argument pairwise_variables.5 Cela nécessite néanmoins au minimum la version 1.11.0 du package broom.helpers et la version 0.2.0 de ggstats.\n\nmod |> \n  ggstats::ggcoef_model(\n    exponentiate = TRUE,\n    add_pairwise_contrasts = TRUE,\n    pairwise_variables = c(\"groupe_ages\", \"etudes\")\n  )\n\n\n\nFigure 21.2: Facteurs associés à la pratique d’un sport (pairwise contrasts)"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#identifier-les-variables-ayant-un-effet-significatif",
    "href": "analyses/regression-logistique-binaire.html#identifier-les-variables-ayant-un-effet-significatif",
    "title": "21  Régression logistique binaire",
    "section": "\n21.7 Identifier les variables ayant un effet significatif",
    "text": "21.7 Identifier les variables ayant un effet significatif\nPour les variables catégorielles à trois modalités ou plus, les p-values associées aux odds ratios nous indique si un odd ratio est significativement différent de 1, par rapport à la modalité de référence. Mais cela n’indique pas si globalement une variable a un effet significatif sur le modèle. Pour tester l’effet global d’une variable, on peut avoir recours à la fonction car::Anova(). Cette dernière va tour à tour supprimer chaque variable du modèle et réaliser une analyse de variance (ANOVA) pour voir si la variance change significativement.\n\ncar::Anova(mod)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: sport\n            LR Chisq Df Pr(>Chisq)    \nsexe          17.309  1  3.176e-05 ***\ngroupe_ages   52.803  3  2.020e-11 ***\netudes       123.826  4  < 2.2e-16 ***\nrelig          4.232  5  0.5165401    \nheures.tv     13.438  1  0.0002465 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAinsi, dans le cas présent, la suppression de la variable relig ne modifie significativement pas le modèle, indiquant l’absence d’effet de cette variable.\nSi l’on a recours à gtsummary::tbl_regression(), on peut facilement ajouter les p-valeurs globales avec gtsummary::add_global_p()6.6 Si l’on veut conserver les p-values individuelles associées à chaque odds ratio, on ajoutera l’option keep = TRUE.\n\nmod |>\n  tbl_regression(exponentiate = TRUE) |>\n  bold_labels() |> \n  add_global_p()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nOR1\n\n      \n95% IC1\n\n      p-valeur\n    \n\n\nSexe\n\n\n<0,001\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,55\n1,26 – 1,91\n\n\n\nGroupe d'âges\n\n\n<0,001\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,66\n0,42 – 1,03\n\n\n\n    45-64 ans\n0,34\n0,21 – 0,54\n\n\n\n    65 ans et plus\n0,25\n0,15 – 0,43\n\n\n\nNiveau d'études\n\n\n<0,001\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,59\n1,77 – 3,83\n\n\n\n    Technique / Professionnel\n2,86\n1,98 – 4,17\n\n\n\n    Supérieur\n6,63\n4,55 – 9,80\n\n\n\n    Non documenté\n8,59\n4,53 – 16,6\n\n\n\nRapport à la religion\n\n\n0,5\n\n\n    Pratiquant regulier\n—\n—\n\n\n\n    Pratiquant occasionnel\n0,98\n0,68 – 1,42\n\n\n\n    Appartenance sans pratique\n0,99\n0,71 – 1,40\n\n\n\n    Ni croyance ni appartenance\n0,81\n0,55 – 1,18\n\n\n\n    Rejet\n0,68\n0,39 – 1,19\n\n\n\n    NSP ou NVPR\n0,92\n0,40 – 2,02\n\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n<0,001\n\n\n\n\n1 OR = rapport de cotes, IC = intervalle de confiance\n    \n\nTable 21.5:  Ajout des p-valeurs globales \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nConcernant le test réalisé dans le cadre d’une Anova, il existe trois tests différents que l’on présente comme le type 1, le type 2 et le type 3 (ou I, II et III). Pour une explication sur ces différents types, on pourra se référer (en anglais) à https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/ ou encore http://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/lm_cat_unbal_ss_explained.html.\nLe type I n’est pas recommandé dans le cas présent car il dépend de l’ordre dans lequel les différentes variables sont testées.\nLorsqu’il n’y a pas d’interaction dans un modèle, le type II serait à privilégier car plus puissant (nous aborderons les interactions dans un prochain chapitre, cf. Chapitre 24).\nEn présence d’interactions, il est conseillé d’avoir plutôt recours au type III. Cependant, en toute rigueur, pour utiliser le type III, il faut que les variables catégorielles soient codées en utilisant un contrastes dont la somme est nulle (un contrast de type somme ou polynomial). Or, par défaut, les variables catégorielles sont codées avec un contraste de type traitement (nous aborderons les différents types de contrastes plus tard, cf. Chapitre 23).\nPar défaut, car::Anova() utilise le type II et gtsummary::add_global_p() le type III. Dans les deux cas, il est possible de préciser le type de test avec type = \"II\" ou type = \"III\".\nDans le cas de notre exemple, un modèle simple sans interaction, le type de test ne change pas les résultats."
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#sélection-pas-à-pas-dun-meilleur-modèle",
    "href": "analyses/regression-logistique-binaire.html#sélection-pas-à-pas-dun-meilleur-modèle",
    "title": "21  Régression logistique binaire",
    "section": "\n21.8 Sélection pas à pas d’un meilleur modèle",
    "text": "21.8 Sélection pas à pas d’un meilleur modèle\nIl est toujours tentant lorsque l’on recherche les facteurs associés à un phénomène d’inclure un nombre important de variables explicatives potentielles dans son modèle logistique. Cependant, un tel modèle n’est pas forcément le plus efficace et certaines variables n’auront probablement pas d’effet significatif sur la variable d’intérêt.\nPour une présentation didactique du cadre théorique de la sélection de modèle, vous pouvez consulter en ligne le cours de L. Rouvière sur la sélection/validation de modèles.\nLa technique de sélection descendante pas à pas est une approche visant à améliorer son modèle explicatif7. On réalise un premier modèle avec toutes les variables spécifiées, puis on regarde s’il est possible d’améliorer le modèle en supprimant une des variables du modèle. Si plusieurs variables permettent d’améliorer le modèle, on supprimera la variable dont la suppression améliorera le plus le modèle. Puis on recommence le même procédé pour voir si la suppression d’une seconde variable peut encore améliorer le modèle et ainsi de suite. Lorsque le modèle ne peut plus être amélioré par la suppresion d’une variable, on s’arrête.7 Il existe également des méthodes de sélection ascendante pas à pas, mais nous les aborderons pas ici.\nIl faut également définir un critère pour déterminer la qualité d’un modèle. L’un des plus utilisés est le Akaike Information Criterion ou AIC. Plus l’AIC sera faible, meilleure sera le modèle. Il s’agit d’un compromis entre le nombre de degrés de liberté (e.g. le nombre de coefficients dans le modèle) que l’on cherche à minimiser et la variance expliquée que l’on cherche à maximiser.\nLa fonction step() permet justement de sélectionner le meilleur modèle par une procédure pas à pas descendante basée sur la minimisation de l’AIC. La fonction affiche à l’écran les différentes étapes de la sélection et renvoie le modèle final.\n\nmod2 <- step(mod)\n\nStart:  AIC=2236.17\nsport ~ sexe + groupe_ages + etudes + relig + heures.tv\n\n              Df Deviance    AIC\n- relig        5   2210.4 2230.4\n<none>             2206.2 2236.2\n- heures.tv    1   2219.6 2247.6\n- sexe         1   2223.5 2251.5\n- groupe_ages  3   2259.0 2283.0\n- etudes       4   2330.0 2352.0\n\nStep:  AIC=2230.4\nsport ~ sexe + groupe_ages + etudes + heures.tv\n\n              Df Deviance    AIC\n<none>             2210.4 2230.4\n- heures.tv    1   2224.0 2242.0\n- sexe         1   2226.4 2244.4\n- groupe_ages  3   2260.6 2274.6\n- etudes       4   2334.3 2346.3\n\n\nLe modèle initial a un AIC de 2236,2. À la première étape, il apparait que la suppression de la variable religion permet diminuer l’AIC à 2210,4. Lors de la seconde étape, toute suppression d’une autre variable ferait augmenter l’AIC. La procédure s’arrête donc.\nPour obtenir directement l’AIC d’un modèle donné, on peut utiliser la fonction AIC().\n\nAIC(mod)\n\n[1] 2236.173\n\nAIC(mod2)\n\n[1] 2230.404\n\n\nOn peut effectuer une analyse de variance ou ANOVA pour comparer les deux modèles avec la fonction anova().\n\nanova(mod, mod2, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: sport ~ sexe + groupe_ages + etudes + relig + heures.tv\nModel 2: sport ~ sexe + groupe_ages + etudes + heures.tv\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      1980     2206.2                     \n2      1985     2210.4 -5  -4.2319   0.5165\n\n\nIl n’y a pas de différences significatives entre nos deux modèles (p=0,52). Autrement dit, notre second modèle explique tout autant de variance que notre premier modèle, tout en étant plus parcimonieux.\n\n\n\n\n\n\nAstuce\n\n\n\nUne alternative à la fonction stats::step() est la fonction MASS::stepAIC() du package MASS qui fonctionne de la même manière. Si cela ne change rien aux régressions logistiques classiques, il arrive que pour certains types de modèle la méthode stats::step() ne soit pas disponible, mais que MASS::stepAIC() puisse être utilisée à la place.\n\nlibrary(MASS)\n\n\nAttachement du package : 'MASS'\n\n\nL'objet suivant est masqué depuis 'package:gtsummary':\n\n    select\n\n\nL'objet suivant est masqué depuis 'package:dplyr':\n\n    select\n\nmod2bis <- stepAIC(mod)\n\nStart:  AIC=2236.17\nsport ~ sexe + groupe_ages + etudes + relig + heures.tv\n\n              Df Deviance    AIC\n- relig        5   2210.4 2230.4\n<none>             2206.2 2236.2\n- heures.tv    1   2219.6 2247.6\n- sexe         1   2223.5 2251.5\n- groupe_ages  3   2259.0 2283.0\n- etudes       4   2330.0 2352.0\n\nStep:  AIC=2230.4\nsport ~ sexe + groupe_ages + etudes + heures.tv\n\n              Df Deviance    AIC\n<none>             2210.4 2230.4\n- heures.tv    1   2224.0 2242.0\n- sexe         1   2226.4 2244.4\n- groupe_ages  3   2260.6 2274.6\n- etudes       4   2334.3 2346.3\n\n\nUn critère similaire à l’AIC est le critère BIC (Bayesian Information Criterion) appelé aussi SBC (Schwarz information criterion). Il s’obtient avec stats::step() en ajoutant l’argument k = log(n) où n est le nombre d’observations inclues dans le modèle que l’on peut obtenir avec nrow(model.matrix(reg)) (pour tenir compte des éventuelles observations manquantes retirées des données pour le calcul du modèle).\n\nmod2_bic <- step(mod, k = log(nrow(model.matrix(mod))))\n\nStart:  AIC=2320.15\nsport ~ sexe + groupe_ages + etudes + relig + heures.tv\n\n              Df Deviance    AIC\n- relig        5   2210.4 2286.4\n<none>             2206.2 2320.2\n- heures.tv    1   2219.6 2326.0\n- sexe         1   2223.5 2329.9\n- groupe_ages  3   2259.0 2350.2\n- etudes       4   2330.0 2413.6\n\nStep:  AIC=2286.39\nsport ~ sexe + groupe_ages + etudes + heures.tv\n\n              Df Deviance    AIC\n<none>             2210.4 2286.4\n- heures.tv    1   2224.0 2292.4\n- sexe         1   2226.4 2294.8\n- groupe_ages  3   2260.6 2313.8\n- etudes       4   2334.3 2379.8\n\n\n\n\nOn peut facilement comparer visuellement deux modèles avec ggstats::ggcoef_compare() de ggstats.\n\nlibrary(ggstats)\nggcoef_compare(\n  list(\"modèle complet\" = mod, \"modèle réduit\" = mod2), \n  exponentiate = TRUE\n)\n\n\n\nFigure 21.3: Comparaison visuelle des deux modèles (dodge)\n\n\n\n\n\nggcoef_compare(\n  list(\"modèle complet\" = mod, \"modèle réduit\" = mod2), \n  type = \"faceted\",\n  exponentiate = TRUE\n)\n\n\n\nFigure 21.4: Comparaison visuelle des deux modèles (faceted)\n\n\n\n\nSi l’on souhaite afficher l’AIC (ainsi que d’autres statistiques globales du modèle) en note du tableau des coefficients, on pourra utiliser gtsummary::add_glance_source_note().\n\nmod2 |> \n  tbl_regression(exponentiate = TRUE) |> \n  bold_labels() |> \n  add_glance_source_note()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nOR1\n\n      \n95% IC1\n\n      p-valeur\n    \n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,52\n1,24 – 1,87\n<0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,68\n0,43 – 1,06\n0,084\n\n\n    45-64 ans\n0,36\n0,23 – 0,57\n<0,001\n\n\n    65 ans et plus\n0,27\n0,16 – 0,46\n<0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,54\n1,73 – 3,75\n<0,001\n\n\n    Technique / Professionnel\n2,81\n1,95 – 4,10\n<0,001\n\n\n    Supérieur\n6,55\n4,50 – 9,66\n<0,001\n\n\n    Non documenté\n8,54\n4,51 – 16,5\n<0,001\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n<0,001\n\n\n\ndéviance nulle = 2 609; degrés de liberté du modèle nul = 1 994; Log-likelihood = -1 105; AIC = 2 230; BIC = 2 286; Deviance = 2 210; degrés de liberté des résidus = 1 985; No. Obs. = 1 995\n    \n\n\n1 OR = rapport de cotes, IC = intervalle de confiance\n    \n\nTable 21.6:  Modèle obtenu après réduction du nombre de variables"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#régressions-logistiques-univariées",
    "href": "analyses/regression-logistique-binaire.html#régressions-logistiques-univariées",
    "title": "21  Régression logistique binaire",
    "section": "\n21.9 Régressions logistiques univariées",
    "text": "21.9 Régressions logistiques univariées\nLes usages varient selon les disciplines et les revues scientifiques, mais il n’est pas rare de présenter, avant le modèle logistique multivarié, une succession de modèles logistiques univariés (i.e. avec une seule variable explicative à la fois) afin de présenter les odds ratios et leur intervalle de confiance et p-valeur associés avant l’ajustement multiniveau.\nAfin d’éviter le code fastidieux consistant à réaliser chaque modèle un par un (par exemple glm(sport ~ sexe, family = binomial, data = d)) puis à en fusionner les résultats, on pourra tirer partie de gtsummary::tbl_uvregression() qui permet de réaliser toutes ces régressions individuelles en une fois et de les présenter dans un tableau synthétique.\n\nd |>\n  tbl_uvregression(\n    y = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv),\n    method = glm,\n    method.args = list(family = binomial),\n    exponentiate = TRUE\n  ) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      N\n      \nOR1\n\n      \n95% IC1\n\n      p-valeur\n    \n\n\nSexe\n2 000\n\n\n\n\n\n    Femme\n\n—\n—\n\n\n\n    Homme\n\n1,47\n1,22 – 1,77\n<0,001\n\n\nRapport à la religion\n2 000\n\n\n\n\n\n    Pratiquant regulier\n\n—\n—\n\n\n\n    Pratiquant occasionnel\n\n1,08\n0,78 – 1,50\n0,6\n\n\n    Appartenance sans pratique\n\n1,31\n0,98 – 1,78\n0,071\n\n\n    Ni croyance ni appartenance\n\n1,45\n1,05 – 2,02\n0,026\n\n\n    Rejet\n\n1,19\n0,72 – 1,95\n0,5\n\n\n    NSP ou NVPR\n\n0,93\n0,44 – 1,88\n0,8\n\n\nHeures de télévision / jour\n1 995\n0,79\n0,74 – 0,84\n<0,001\n\n\nGroupe d'âges\n2 000\n\n\n\n\n\n    18-24 ans\n\n—\n—\n\n\n\n    25-44 ans\n\n0,51\n0,35 – 0,71\n<0,001\n\n\n    45-64 ans\n\n0,20\n0,14 – 0,28\n<0,001\n\n\n    65 ans et plus\n\n0,10\n0,07 – 0,15\n<0,001\n\n\nNiveau d'études\n2 000\n\n\n\n\n\n    Primaire\n\n—\n—\n\n\n\n    Secondaire\n\n3,61\n2,52 – 5,23\n<0,001\n\n\n    Technique / Professionnel\n\n4,75\n3,42 – 6,72\n<0,001\n\n\n    Supérieur\n\n11,4\n8,11 – 16,3\n<0,001\n\n\n    Non documenté\n\n26,2\n15,7 – 44,9\n<0,001\n\n\n\n\n1 OR = rapport de cotes, IC = intervalle de confiance\n    \n\nTable 21.7:  Régressions logistiques univariées"
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#présenter-lensemble-des-résultats-dans-un-même-tableau",
    "href": "analyses/regression-logistique-binaire.html#présenter-lensemble-des-résultats-dans-un-même-tableau",
    "title": "21  Régression logistique binaire",
    "section": "\n21.10 Présenter l’ensemble des résultats dans un même tableau",
    "text": "21.10 Présenter l’ensemble des résultats dans un même tableau\nLa fonction gtsummary::tbl_merge() permet de fusionner plusieurs tableaux (en tenant compte du nom des variables) et donc de présenter les différents résultats de l’analyse descriptive, univariée et multivariée dans un seul et même tableau.\n\ntbl_desc <-\n  d |> \n  tbl_summary(\n    by = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv),\n    statistic = all_categorical() ~ \"{p}% ({n}/{N})\",\n    digits = all_categorical() ~ c(1, 0, 0)\n  ) |> \n  modify_column_hide(\"stat_1\") |> \n  modify_header(\"stat_2\" ~ \"**Pratique d'un sport**\")\n\ntbl_uni <-\n  d |>\n  tbl_uvregression(\n    y = sport,\n    include = c(sexe, groupe_ages, etudes, relig, heures.tv),\n    method = glm,\n    method.args = list(family = binomial),\n    exponentiate = TRUE\n  ) |> \n  modify_column_hide(\"stat_n\")\n\ntbl_multi <-\n  mod2 |> \n  tbl_regression(exponentiate = TRUE)\n\nlist(tbl_desc, tbl_uni, tbl_multi) |> \n  tbl_merge(\n    tab_spanner = c(\n      NA,\n      \"**Régressions univariées**\",\n      \"**Régression multivariée**\"\n    )\n  ) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \n\nCaractéristique\n      \nPratique d'un sport1\n\n      \n        Régressions univariées\n      \n      \n        Régression multivariée\n      \n    \n\n\nOR2\n\n      \n95% IC2\n\n      p-valeur\n      \nOR2\n\n      \n95% IC2\n\n      p-valeur\n    \n\n\n\nSexe\n\n\n\n\n\n\n\n\n\n    Femme\n49,0% (354/723)\n—\n—\n\n—\n—\n\n\n\n    Homme\n51,0% (369/723)\n1,47\n1,22 – 1,77\n<0,001\n1,52\n1,24 – 1,87\n<0,001\n\n\nGroupe d'âges\n\n\n\n\n\n\n\n\n\n    18-24 ans\n15,4% (111/723)\n—\n—\n\n—\n—\n\n\n\n    25-44 ans\n48,0% (347/723)\n0,51\n0,35 – 0,71\n<0,001\n0,68\n0,43 – 1,06\n0,084\n\n\n    45-64 ans\n28,2% (204/723)\n0,20\n0,14 – 0,28\n<0,001\n0,36\n0,23 – 0,57\n<0,001\n\n\n    65 ans et plus\n8,4% (61/723)\n0,10\n0,07 – 0,15\n<0,001\n0,27\n0,16 – 0,46\n<0,001\n\n\nNiveau d'études\n\n\n\n\n\n\n\n\n\n    Primaire\n6,9% (50/723)\n—\n—\n\n—\n—\n\n\n\n    Secondaire\n16,2% (117/723)\n3,61\n2,52 – 5,23\n<0,001\n2,54\n1,73 – 3,75\n<0,001\n\n\n    Technique / Professionnel\n29,9% (216/723)\n4,75\n3,42 – 6,72\n<0,001\n2,81\n1,95 – 4,10\n<0,001\n\n\n    Supérieur\n35,3% (255/723)\n11,4\n8,11 – 16,3\n<0,001\n6,55\n4,50 – 9,66\n<0,001\n\n\n    Non documenté\n11,8% (85/723)\n26,2\n15,7 – 44,9\n<0,001\n8,54\n4,51 – 16,5\n<0,001\n\n\nRapport à la religion\n\n\n\n\n\n\n\n\n\n    Pratiquant regulier\n11,6% (84/723)\n—\n—\n\n\n\n\n\n\n    Pratiquant occasionnel\n20,3% (147/723)\n1,08\n0,78 – 1,50\n0,6\n\n\n\n\n\n    Appartenance sans pratique\n39,7% (287/723)\n1,31\n0,98 – 1,78\n0,071\n\n\n\n\n\n    Ni croyance ni appartenance\n22,1% (160/723)\n1,45\n1,05 – 2,02\n0,026\n\n\n\n\n\n    Rejet\n4,6% (33/723)\n1,19\n0,72 – 1,95\n0,5\n\n\n\n\n\n    NSP ou NVPR\n1,7% (12/723)\n0,93\n0,44 – 1,88\n0,8\n\n\n\n\n\nHeures de télévision / jour\n2,00 (1,00 – 3,00)\n0,79\n0,74 – 0,84\n<0,001\n0,89\n0,83 – 0,95\n<0,001\n\n\n    Manquant\n3\n\n\n\n\n\n\n\n\n\n\n\n1 % (n/N); Médiane (EI)\n    \n\n\n2 OR = rapport de cotes, IC = intervalle de confiance\n    \n\n\nTable 21.8:  tableau synthétique de l’analyse \n\n\n\n\nLe diaporama ci-dessous vous permet de visualiser chaque étape du code correspondant au graphique précédent."
  },
  {
    "objectID": "analyses/regression-logistique-binaire.html#webin-r",
    "href": "analyses/regression-logistique-binaire.html#webin-r",
    "title": "21  Régression logistique binaire",
    "section": "\n21.11 webin-R",
    "text": "21.11 webin-R\nLa régression logistique est présentée sur YouTube dans le webin-R #06 (régression logistique (partie 1) et le le webin-R #07 (régression logistique (partie 2)."
  },
  {
    "objectID": "analyses/effets-marginaux.html#données-dillustration",
    "href": "analyses/effets-marginaux.html#données-dillustration",
    "title": "22  Effets marginaux",
    "section": "\n22.1 Données d’illustration",
    "text": "22.1 Données d’illustration\nPour illustrer ce chapitre, nous allons reprendre le modèle réduit utilisé dans le chapitre sur la régression logistique binaire (cf. Chapitre 21).\n\nlibrary(tidyverse)\nlibrary(labelled)\nlibrary(gtsummary)\ntheme_gtsummary_language(\n  \"fr\",\n  decimal.mark = \",\",\n  big.mark = \" \"\n)\n\ndata(hdv2003, package = \"questionr\")\n\nd <-\n  hdv2003 |> \n  mutate(\n    sexe = sexe |> fct_relevel(\"Femme\"),\n    groupe_ages = age |>\n      cut(\n        c(18, 25, 45, 65, 99),\n        right = FALSE,\n        include.lowest = TRUE,\n        labels = c(\"18-24 ans\", \"25-44 ans\",\n                   \"45-64 ans\", \"65 ans et plus\")\n      ),\n    etudes = nivetud |> \n      fct_recode(\n        \"Primaire\" = \"N'a jamais fait d'etudes\",\n        \"Primaire\" = \"A arrete ses etudes, avant la derniere annee d'etudes primaires\",\n        \"Primaire\" = \"Derniere annee d'etudes primaires\",\n        \"Secondaire\" = \"1er cycle\",\n        \"Secondaire\" = \"2eme cycle\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel court\",\n        \"Technique / Professionnel\" = \"Enseignement technique ou professionnel long\",\n        \"Supérieur\" = \"Enseignement superieur y compris technique superieur\"\n    ) |> \n    fct_explicit_na(\"Non documenté\")  \n  ) |> \n  set_variable_labels(\n    sport = \"Pratique un sport ?\",\n    sexe = \"Sexe\",\n    groupe_ages = \"Groupe d'âges\",\n    etudes = \"Niveau d'études\",\n    heures.tv = \"Heures de télévision / jour\"\n  )\n\nmod <- glm(\n  sport ~ sexe + groupe_ages + etudes + heures.tv,\n  family = binomial,\n  data = d\n)\n\n\nmod |> \n  tbl_regression(exponentiate = TRUE) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      \nOR1\n\n      \n95% IC1\n\n      p-valeur\n    \n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n1,52\n1,24 – 1,87\n<0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n0,68\n0,43 – 1,06\n0,084\n\n\n    45-64 ans\n0,36\n0,23 – 0,57\n<0,001\n\n\n    65 ans et plus\n0,27\n0,16 – 0,46\n<0,001\n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Secondaire\n2,54\n1,73 – 3,75\n<0,001\n\n\n    Technique / Professionnel\n2,81\n1,95 – 4,10\n<0,001\n\n\n    Supérieur\n6,55\n4,50 – 9,66\n<0,001\n\n\n    Non documenté\n8,54\n4,51 – 16,5\n<0,001\n\n\nHeures de télévision / jour\n0,89\n0,83 – 0,95\n<0,001\n\n\n\n\n1 OR = rapport de cotes, IC = intervalle de confiance\n    \n\nTable 22.1:  Odds Ratio du modèle logistique"
  },
  {
    "objectID": "analyses/effets-marginaux.html#effets-marginaux-moyens",
    "href": "analyses/effets-marginaux.html#effets-marginaux-moyens",
    "title": "22  Effets marginaux",
    "section": "\n22.2 Effets marginaux moyens",
    "text": "22.2 Effets marginaux moyens\nL’approche la plus commune en économétrie est celle implémentée dans la commande margins du logiciel Stata et dont l’équivalent est disponible sous R dans le package margins et sa fonction margins::margins().\nPrenons directement un exemple. Pour bénéficier d’une mise en forme des résultats, le plus simple reste encore d’utiliser la fonction broom.helpers::tidy_margins()2 avec gtsummary::tbl_regression().2 Nécessite au minimum la version 1.11.0 de broom.helpers.\n\nmod |> \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_margins,\n    estimate_fun = scales::label_percent(\n      accuracy = 0.1,\n      style_positive = \"plus\"\n    )\n  ) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      Average Marginal Effects\n      \n95% IC1\n\n      p-valeur\n    \n\n\nNiveau d'études\n\n\n\n\n\n    Primaire\n—\n—\n\n\n\n    Non documenté\n+43.1%\n+29.5% – +56.6%\n<0,001\n\n\n    Secondaire\n+15.7%\n+9.5% – +21.8%\n<0,001\n\n\n    Supérieur\n+37.0%\n+30.4% – +43.6%\n<0,001\n\n\n    Technique / Professionnel\n+17.8%\n+12.0% – +23.6%\n<0,001\n\n\nGroupe d'âges\n\n\n\n\n\n    18-24 ans\n—\n—\n\n\n\n    25-44 ans\n-8.4%\n-18.1% – +1.2%\n0,086\n\n\n    45-64 ans\n-21.3%\n-31.2% – -11.3%\n<0,001\n\n\n    65 ans et plus\n-26.3%\n-37.2% – -15.4%\n<0,001\n\n\nHeures de télévision / jour\n-2.3%\n-3.5% – -1.1%\n<0,001\n\n\nSexe\n\n\n\n\n\n    Femme\n—\n—\n\n\n\n    Homme\n+7.9%\n+4.0% – +11.7%\n<0,001\n\n\n\n\n1 IC = intervalle de confiance\n    \n\nTable 22.2:  Effets marginaux moyens \n\n\n\nL’idée générale est d’estimer l’écart dans l’échelle de la variable d’intérêt (ici l’écart de probabilités comme il s’agit d’une régression logistique) à la moyenne des autres variables.\nAinsi, la probabilité de faire du sport des hommes est supérieure de 8 points de pourcentage (pp) à celle des femmes, toutes choses étant égales par ailleurs, et diminue de 2,3 pp pour chaque heure additionnelle de télévision quotidienne.\nPar rapport aux odds ratios, les effets marginaux moyens sont plus faciles à appréhender car ils s’interprètent ici directement comme des différences de probabilités.\nOn peut également les représenter graphiquement avec ggstats::ggcoef_model().\n\nmod |> \n  ggstats::ggcoef_model(\n    tidy_fun = broom.helpers::tidy_margins\n  ) +\n  scale_x_continuous(labels = scales::label_percent())\n\n\n\nFigure 22.1: Effets marginaux moyens"
  },
  {
    "objectID": "analyses/effets-marginaux.html#effets-marginaux-ou-moyennes-marginales",
    "href": "analyses/effets-marginaux.html#effets-marginaux-ou-moyennes-marginales",
    "title": "22  Effets marginaux",
    "section": "\n22.3 Effets marginaux ou Moyennes marginales",
    "text": "22.3 Effets marginaux ou Moyennes marginales\nComme les odds ratios, les effets marginaux moyens sont dépendants de la modalité de réference choisie pour les variables catégorielles. De plus, ils ne permettent pas de visualiser la probabilité de faire du sport d’un groupe donné. Ils ne donnent que l’écart de probabilité entre deux groupes.\nUne approche alternative consiste à calculer des effets marginaux de chaque sous-groupe, à la moyenne des autres variables. Il s’agit de conserver l’approche toutes choses égales par ailleurs. Si l’on ne fait varier que le sexe, ayant ajusté sur l’âge, le niveau d’étude et le nombre d’heures quotidiennes de télévision, quelle est la probabilité de faire du sport, telle que prédite par le modèle, pour les femmes ? pour les hommes ?\nOn parle alors, selon les packages et les auteurs, d’effets marginaux (marginal effects) ou de moyennes marginales (marginal mean).\nPour cela, on aura recours au package effects. Pour calculer les effets de l’ensemble des variables d’un modèle et les représenter graphiquement, on utilisera effects::allEffects() :\n\nmod |> \n  effects::allEffects() |> \n  plot()\n\n\n\nFigure 22.2: Représentation des effets marginaux avec effects\n\n\n\n\nPour des graphiques un peu plus propres, on pourra privilégier ggeffects::ggeffect().\n\nmod |> \n  ggeffects::ggeffect() |> \n  plot() |> \n  patchwork::wrap_plots()\n\n\n\nFigure 22.3: Représentation des effets marginaux avec ggeffects\n\n\n\n\nDernière possibilité, la fonction broom.helpers::tidy_all_effects()3 avec ggstats::ggcoef_model().3 Nécessite au minimum la version 1.11.0 de broom.helpers.\n\nmod |> \n  ggstats::ggcoef_model(\n    tidy_fun = broom.helpers::tidy_all_effects,\n    vline = FALSE\n  ) +\n  scale_x_continuous(labels = scales::label_percent())\n\n\n\nFigure 22.4: Représentation des effets marginaux avec ggstats\n\n\n\n\nDe même, on peut produire un tableau avec gtsummary::tbl_regression().\n\nmod |> \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_all_effects,\n    estimate_fun = scales::label_percent(accuracy = 0.1)\n  ) |> \n  bold_labels()\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      Marginal Effects\n      \n95% IC1\n\n    \n\n\nSexe\n\n\n\n\n    Femme\n28.7%\n25.8% – 31.8%\n\n\n    Homme\n37.9%\n34.4% – 41.6%\n\n\nGroupe d'âges\n\n\n\n\n    18-24 ans\n51.2%\n41.0% – 61.3%\n\n\n    25-44 ans\n41.5%\n37.4% – 45.7%\n\n\n    45-64 ans\n27.3%\n23.9% – 30.9%\n\n\n    65 ans et plus\n22.0%\n17.4% – 27.5%\n\n\nNiveau d'études\n\n\n\n\n    Primaire\n14.9%\n11.3% – 19.3%\n\n\n    Secondaire\n30.7%\n26.2% – 35.7%\n\n\n    Technique / Professionnel\n32.9%\n29.1% – 37.0%\n\n\n    Supérieur\n53.4%\n48.3% – 58.4%\n\n\n    Non documenté\n59.9%\n46.6% – 71.8%\n\n\nHeures de télévision / jour\n\n\n\n\n    0\n38.9%\n34.8% – 43.2%\n\n\n    3\n30.7%\n28.1% – 33.4%\n\n\n    6\n23.6%\n18.9% – 28.9%\n\n\n    9\n17.7%\n11.9% – 25.4%\n\n\n    10\n16.0%\n10.1% – 24.4%\n\n\n\n\n1 IC = intervalle de confiance\n    \n\nTable 22.3:  Effets marginaux \n\n\n\nAvec cette représentation, nous pouvons dire que, toutes choses étant égales par ailleurs, la probabilité de faire du sport des femmes est de 28,7% et celle des hommes de 37,9%. Ces proportions sont différentes de celles observées dans l’échantillon. Elles sont prédites par le modèle, à la moyenne des autres variables, et donc ne varient pas selon l’âge, le niveau d’éducation ou le nombre d’heures quotidiennes de télévision. Il s’agit bien de probabilités prédites et ajustées sur les autres variables. L’objectif est bien d’isoler l’effet du sexe, indépendamment des autres variables du modèle.\nIci, peu importe la modalité choisie comme modalité de référence, les effets marginaux calculés seront rigoureusement identiques !\n\n\n\n\n\n\nNote\n\n\n\nL’écart entre les femmes et les hommes obtenus avec effects n’est pas tout à fait égal à celui obtenu avec margins, les deux packages n’ayant pas exactement la même approche pour se situer à la moyenne des autres variables. Cependant, l’ordre de grandeur est identique."
  },
  {
    "objectID": "analyses/effets-marginaux.html#effets-conditionnels-à-la-référence",
    "href": "analyses/effets-marginaux.html#effets-conditionnels-à-la-référence",
    "title": "22  Effets marginaux",
    "section": "\n22.4 Effets conditionnels à la référence",
    "text": "22.4 Effets conditionnels à la référence\nUne autre possibilité consiste à prédire les probabilités pour chaque modalité en considérant les autres variables à leur référence (pour les variables catégorielles) ou à leur moyenne (pour les variables continues). Il s’agit d’une transcription plus directe des coefficients du modèle, mais n’a vraiment de sens que si la référence du modèle correspond également à une référence sociale du point de vue sociologique. Sinon, il est préférable d’avoir plutôt recours aux effets marginaux.\nPour cela, on aura recours à la fonction ggeffects::ggpredict().\n\nmod |> \n  ggeffects::ggpredict() |> \n  plot() |> \n  patchwork::wrap_plots()\n\nData were 'prettified'. Consider using `terms=\"heures.tv [all]\"` to get\n  smooth plots.\n\n\n\n\nFigure 22.5: Représentation des effets conditionnel à la référence avec ggeffects\n\n\n\n\nPour ggstats::ggcoef_model() et gtsummary::tbl_regression(), on fera appel à broom.helpers::tidy_ggpredict()4.4 Nécessite au minimum la version 1.11.0 de broom.helpers.\n\nmod |> \n  ggstats::ggcoef_model(\n    tidy_fun = broom.helpers::tidy_ggpredict,\n    vline = FALSE\n  ) +\n  scale_x_continuous(labels = scales::label_percent())\n\nData were 'prettified'. Consider using `terms=\"heures.tv [all]\"` to get\n  smooth plots.\n\n\n\n\nFigure 22.6: Représentation des effets conditionnels à la référence avec ggstats\n\n\n\n\n\nmod |> \n  tbl_regression(\n    tidy_fun = broom.helpers::tidy_ggpredict,\n    estimate_fun = scales::label_percent(accuracy = 0.1)\n  ) |> \n  bold_labels()\n\nData were 'prettified'. Consider using `terms=\"heures.tv [all]\"` to get\n  smooth plots.\n\n\n\n\n\n\n\n\n  \n  \nCaractéristique\n      Conditional Effects\n      \n95% IC1\n\n    \n\n\nSexe\n\n\n\n\n    Femme\n23.8%\n15.3% – 35.1%\n\n\n    Homme\n32.2%\n21.4% – 45.4%\n\n\nGroupe d'âges\n\n\n\n\n    18-24 ans\n23.8%\n15.3% – 35.1%\n\n\n    25-44 ans\n17.5%\n12.7% – 23.5%\n\n\n    45-64 ans\n10.1%\n7.3% – 13.7%\n\n\n    65 ans et plus\n7.8%\n5.5% – 10.9%\n\n\nNiveau d'études\n\n\n\n\n    Primaire\n23.8%\n15.3% – 35.1%\n\n\n    Secondaire\n44.2%\n33.0% – 56.1%\n\n\n    Technique / Professionnel\n46.8%\n36.1% – 57.8%\n\n\n    Supérieur\n67.2%\n56.2% – 76.6%\n\n\n    Non documenté\n72.8%\n62.8% – 80.9%\n\n\nHeures de télévision / jour\n\n\n\n\n    0\n29.1%\n18.7% – 42.3%\n\n\n    1\n26.7%\n17.2% – 38.9%\n\n\n    2\n24.4%\n15.7% – 35.8%\n\n\n    3\n22.2%\n14.2% – 33.0%\n\n\n    4\n20.2%\n12.8% – 30.4%\n\n\n    5\n18.3%\n11.4% – 28.2%\n\n\n    6\n16.6%\n10.0% – 26.1%\n\n\n    7\n15.0%\n8.8% – 24.3%\n\n\n    8\n13.5%\n7.7% – 22.7%\n\n\n    9\n12.1%\n6.6% – 21.2%\n\n\n    10\n10.9%\n5.7% – 19.9%\n\n\n    11\n9.8%\n4.9% – 18.7%\n\n\n    12\n8.8%\n4.2% – 17.6%\n\n\n\n\n1 IC = intervalle de confiance\n    \n\nTable 22.4:  Effets conditionnels à la référence \n\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nLors de l’interprétation des résultats, il faut bien garder en tête qu’ils sont dépendants des références choisies pour chaque variable. Si l’on modifie la référence, les effets conditionnels à la référence seront eux aussi modifiés.\nOn utilisera donc cette fonctionallité en toute connaissance de cause."
  },
  {
    "objectID": "analyses/contrastes.html#contrastes-de-type-traitement",
    "href": "analyses/contrastes.html#contrastes-de-type-traitement",
    "title": "23  Contrastes (variables catégorielles)",
    "section": "\n23.1 Contrastes de type traitement",
    "text": "23.1 Contrastes de type traitement\nPar défaut, R applique des contrastes de type traitement pour un facteur non ordonné. Il s’agit notamment des contrastes utilisés par défaut dans les chapitres précédents.\n\n23.1.1 Exemple 1 : un modèle linéaire avec une variable catégorielle\nCommençons avec un premier exemple que nous allons calculer avec le jeu de données trial chargé en mémoire lorsque l’on appelle l’extension gtsummary. Ce jeu de données contient les observations de 200 patients. Nous nous intéressons à deux variables en particulier : marker une variable numérique correspondant à un marqueur biologique et grade un facteur à trois modalités correspondant à différent groupes de patients.\nRegardons la moyenne de marker pour chaque valeur de grade.\n\nlibrary(tidyverse)\nlibrary(gtsummary)\ntrial |>\n  select(marker, grade) |>\n  tbl_summary(\n    by = grade,\n    statistic = marker ~ \"{mean}\",\n    digits = marker ~ 4\n  ) |>\n  add_overall(last = TRUE)\n\n\n\n\n\n\nCharacteristic\n      \nI, N = 681\n\n      \nII, N = 681\n\n      \nIII, N = 641\n\n      \nOverall, N = 2001\n\n    \n\n\nMarker Level (ng/mL)\n1.0669\n0.6805\n0.9958\n0.9160\n\n\n    Unknown\n2\n5\n3\n10\n\n\n\n\n1 Mean\n    \n\n\n\n\nUtilisons maintenant une régression linaire pour modéliser la valeur de marker en fonction de grade.\n\nmod1_trt <- lm(marker ~ grade, data = trial)\nmod1_trt\n\n\nCall:\nlm(formula = marker ~ grade, data = trial)\n\nCoefficients:\n(Intercept)      gradeII     gradeIII  \n     1.0669      -0.3864      -0.0711  \n\n\nLe modèle obtenu contient trois coefficients ou termes : un intercept et deux termes associés à la variable grade.\nPour bien interpréter ces coefficients, il faut comprendre comment la variable grade a été transformée avant d’être inclue dans le modèle. Nous pouvons voir cela avec la fonction contrasts().\n\ncontrasts(trial$grade)\n\n    II III\nI    0   0\nII   1   0\nIII  0   1\n\n\nCe que nous montre cette matrice, c’est que la variable catégorielle grade à 3 modalités a été transformée en 2 variables binaires que l’on retrouve sous les noms de gradeII et gradeIII dans le modèle : gradeII vaut 1 si grade est égal à II et 0 sinon; gradeIII vaut 1 si grade est égal à III et 0 sinon. Si grade est égal à I, alors gradeII et gradeIII valent 0.\nIl s’agit ici d’un contraste dit de traitement ou la première modalité joue ici le rôle de modalité de référence.\nDans ce modèle linéaire, la valeur de l’intercept correspond à la moyenne de marker lorsque nous nous trouvons à la référence, donc quand grade est égal à I dans cet exemple. Et nous pouvons le constater dans notre tableau précédent des moyennes, 1.0669 correspond bien à la moyenne de marker pour la modalité I.\nLa valeur du coefficient associé à markerII correspond à l’écart par rapport à la référence lorsque marker est égal à II. Autrement dit, la moyenne de marker pour la modalité II correspond à la somme de l’intercept et du coefficient markerII. Et nous retrouvons bien la relation suivante : 0.6805 = 1.0669 + -0.3864. De même, la moyenne de marker lorsque grade vaut III est égale à la somme de l’intercept et du terme markerIII.\nLorsqu’on utilise des contrastes de type traitement, chaque terme du modèle peut être associé à une et une seule modalité d’origine de la variable catégorielle. Dès lors, il est possible de rajouter la modalité de référence lorsque l’on présente les résultats et on peut même lui associer la valeurs 0, ce qui peut être fait avec gtsummary::tbl_regression() avec l’option add_estimate_to_reference_rows = TRUE.\n\nmod1_trt |>\n  tbl_regression(\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  )\n\n\n\n\n\n\nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n1.1\n0.86, 1.3\n<0.001\n\n\nGrade\n\n\n\n\n\n    I\n0.00\n—\n\n\n\n    II\n-0.39\n-0.68, -0.09\n0.010\n\n\n    III\n-0.07\n-0.37, 0.23\n0.6\n\n\n\n\n1 CI = Confidence Interval\n    \n\n\n\n\n\n23.1.2 Exemple 2 : une régression logistique avec deux variables catégorielles\nPour ce deuxième exemple, nous allons utiliser le jeu de données hdv2003 fourni par l’extension questionr et recoder la variable age en groupes d’âges à 4 modalités.\n\nlibrary(questionr)\ndata(\"hdv2003\")\n\nlibrary(tidyverse)\n\n\nhdv2003 <- hdv2003 |>\n  mutate(\n    groupe_ages = cut(\n      age, \n      c(16, 25, 45, 65, 99), \n      right = FALSE, \n      include.lowest = TRUE\n    ) |>\n      fct_recode(\n        \"16-24\" = \"[16,25)\",\n        \"25-44\" = \"[25,45)\",\n        \"45-64\" = \"[45,65)\",\n        \"65+\" = \"[65,99]\"\n      ) \n  ) |>\n  labelled::set_variable_labels(\n    groupe_ages = \"Groupe d'âges\",\n    sexe = \"Sexe\"\n  )\n\nNous allons faire une régression logistique binaire pour investiguer l’effet du sexe (variable à 2 modalités) et du groupe d’âges (variable à 4 modalités) sur la pratique du sport.\n\nmod2_trt <- glm(\n  sport ~ sexe + groupe_ages,\n  family = binomial,\n  data = hdv2003\n)\nmod2_trt\n\n\nCall:  glm(formula = sport ~ sexe + groupe_ages, family = binomial, \n    data = hdv2003)\n\nCoefficients:\n     (Intercept)         sexeFemme  groupe_ages25-44  groupe_ages45-64  \n          0.9021           -0.4455           -0.6845           -1.6535  \n  groupe_ages65+  \n         -2.3198  \n\nDegrees of Freedom: 1999 Total (i.e. Null);  1995 Residual\nNull Deviance:      2617 \nResidual Deviance: 2385     AIC: 2395\n\n\nLe modèle contient 5 termes : 1 intercept, 1 coefficient pour la variable sexe et 3 coefficients pour la variable groupe_ages. Comme précédemment, nous pouvons constater que les variables à n modalités sont remplacées par défaut (contrastes de type traitement) par n-1 variables binaires, la première modalité jouant à chaque fois le rôle de modalité de référence.\n\ncontrasts(hdv2003$sexe)\n\n      Femme\nHomme     0\nFemme     1\n\ncontrasts(hdv2003$groupe_ages)\n\n      25-44 45-64 65+\n16-24     0     0   0\n25-44     1     0   0\n45-64     0     1   0\n65+       0     0   1\n\n\nL’intercept correspond donc à la situation à la référence, c’est-à-dire à la prédiction du modèle pour les hommes (référence de sexe) âgés de 16 à 24 ans (référence de groupe_ages).\nIl est possible d’exprimer cela en termes de probabilité en utilisant l’inverse de la fonction logit (puisque nous avons utilisé un modèle logit).\n\ninv_logit <- binomial(\"logit\")$linkinv\ninv_logit(0.9021)\n\n[1] 0.7113809\n\n\nSelon le modèle, les hommes âgés de 16 à 24 ans ont donc 71% de chance de pratiquer du sport.\nRegardons maintenant le coefficient associé à sexeFemme (-0.4455) : il représente (pour la modalité de référence des autres variables, soit pour les 16-24 ans ici) la correction à appliquer à l’intercept pour obtenir la probabilité de faire du sport. Il s’agit donc de la différence entre les femmes et les hommes pour le groupe des 16-24 ans.\n\ninv_logit(0.9021 - 0.4455)\n\n[1] 0.6122073\n\n\nAutrement dit, selon le modèle, la probabilité de faire du sport pour une femme âgée de 16 à 24 ans est de 61%. On peut représenter cela avec la fonction ggeffects::ggpredict() de ggeffects, qui représente les prédictions d’une variable toutes les autres variables étant à la référence.\n\nlibrary(ggeffects)\nggpredict(mod2_trt, \"sexe\") |> plot()\n\n\n\n\n\n\n\nBien souvent, pour une régression logistique, on préfère représenter les exponentielles des coefficients qui correspondent à des odds ratios.\n\nmod2_trt |>\n  tbl_regression(\n    exponentiate = TRUE,\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  )\n\n\n\n\n\n\nCharacteristic\n      \nOR1\n\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n2.46\n1.76, 3.48\n<0.001\n\n\nSexe\n\n\n\n\n\n    Homme\n1.00\n—\n\n\n\n    Femme\n0.64\n0.53, 0.78\n<0.001\n\n\nGroupe d'âges\n\n\n\n\n\n    16-24\n1.00\n—\n\n\n\n    25-44\n0.50\n0.35, 0.71\n<0.001\n\n\n    45-64\n0.19\n0.13, 0.27\n<0.001\n\n\n    65+\n0.10\n0.06, 0.15\n<0.001\n\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n    \n\n\n\n\nOr, 0,64 correspond bien à l’odds ratio entre 61% et 71% (que l’on peut calculer avec questionr::odds.ratio()).\n\nquestionr::odds.ratio(0.6122, 0.7114)\n\n[1] 0.6404246\n\n\nDe la même manière, les différents coefficients associés à groupe_ages correspondent à la différence entre chaque groupe d’âges et sa modalité de référence (ici 16-24 ans), quand les autres variables (ici le sexe) sont à leur référence (ici les hommes).\nPour prédire la probabilité de faire du sport pour un profil particulier, il faut prendre en compte toutes les termes qui s’appliquent et qui s’ajoutent à l’intercept. Par exemple, pour une femme de 50 ans il faut considérer l’intercept (0.9021), le coefficient sexeFemme (-0.4455) et le coefficient groupe_ages45-64 (-1.6535). Sa probabilité de faire du sport est donc de 23%.\n\ninv_logit(0.9021 - 0.4455 - 1.6535)\n\n[1] 0.2320271\n\n\n\n23.1.3 Changer la modalité de référence\nIl est possible de personnaliser les contrastes à utiliser et avoir un recours à un contraste de type traitement mais en utilisant une autre modalité que la première comme référence, avec la fonction contr.treatment(). Le premier argument de la fonction corresponds au nombre de modalités de la variable et le paramètre base permets de spécifier la modalité de référence (1 par défaut).\n\ncontr.treatment(4, base = 2)\n\n  1 3 4\n1 1 0 0\n2 0 0 0\n3 0 1 0\n4 0 0 1\n\n\ncontr.SAS() permets de spécifier un contraste de type traitement dont la modalité de référence est la dernière.\n\ncontr.SAS(4)\n\n  1 2 3\n1 1 0 0\n2 0 1 0\n3 0 0 1\n4 0 0 0\n\n\nLes contrastes peuvent être modifiés de deux manières : au moment de la construction du modèle (via l’option contrasts) ou comme attribut des variables (via la fonction contrasts()).\n\ncontrasts(hdv2003$sexe) <- contr.SAS(2)\nmod2_trt_bis <- glm(\n  sport ~ sexe + groupe_ages, \n  family = binomial, \n  data = hdv2003,\n  contrasts = list(groupe_ages = contr.treatment(4, 3))\n)\nmod2_trt_bis |>\n  tbl_regression(exponentiate = TRUE, intercept = TRUE)\n\n\n\n\n\n\nCharacteristic\n      \nOR1\n\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n0.30\n0.25, 0.36\n<0.001\n\n\nSexe\n\n\n\n\n\n    Homme\n1.56\n1.29, 1.90\n<0.001\n\n\n    Femme\n—\n—\n\n\n\nGroupe d'âges\n\n\n\n\n\n    16-24\n5.23\n3.67, 7.52\n<0.001\n\n\n    25-44\n2.64\n2.12, 3.29\n<0.001\n\n\n    45-64\n—\n—\n\n\n\n    65+\n0.51\n0.37, 0.70\n<0.001\n\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n    \n\n\n\n\nComme les modalités de référence ont changé, l’intercept et les différents termes ont également changé (puisque l’on ne compare plus à la même référence).\n\nggstats::ggcoef_compare(\n  list(mod2_trt, mod2_trt_bis),\n  exponentiate = TRUE,\n  type = \"faceted\"\n)\n\n\n\n\n\n\n\nCependant, du point de vue explicatif et prédictif, les deux modèles sont rigoureusement identiques.\n\nanova(mod2_trt, mod2_trt_bis, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: sport ~ sexe + groupe_ages\nModel 2: sport ~ sexe + groupe_ages\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      1995     2385.2                     \n2      1995     2385.2  0        0         \n\n\nDe même, leurs effets marginaux (cf. Chapitre 22) sont identiques.\n\nggstats::ggcoef_compare(\n  list(mod2_trt, mod2_trt_bis),\n  tidy_fun = broom.helpers::tidy_all_effects,\n  type = \"dodge\",\n  vline = FALSE\n)"
  },
  {
    "objectID": "analyses/contrastes.html#contrastes-de-type-somme",
    "href": "analyses/contrastes.html#contrastes-de-type-somme",
    "title": "23  Contrastes (variables catégorielles)",
    "section": "\n23.2 Contrastes de type somme",
    "text": "23.2 Contrastes de type somme\nNous l’avons vu, les contrastes de type traitement nécessitent de définir une modalité de référence et toutes les autres modalités seront comparées à cette modalité de référence. Une alternative consiste à comparer toutes les modalités à la grande moyenne, ce qui s’obtient avec un contraste de type somme que l’on obtient avec contr.sum().\n\n23.2.1 Exemple 1 : un modèle linéaire avec une variable catégorielle\nReprenons notre premier exemple de tout à l’heure et modifions seulement le contraste.\n\ncontrasts(trial$grade) <- contr.sum\nmod1_sum <- lm(\n  marker ~ grade,\n  data = trial\n)\nmod1_sum\n\n\nCall:\nlm(formula = marker ~ grade, data = trial)\n\nCoefficients:\n(Intercept)       grade1       grade2  \n     0.9144       0.1525      -0.2339  \n\n\nL’intercept correspond à ce qu’on appelle parfois la grande moyenne (ou great average en anglais). Il ne s’agit pas de la moyenne observée de marker mais de la moyenne des moyennes de chaque sous-groupe. Cela va constituer la situation de référence de notre modèle, en quelque sorte indépendante des effets de la variable grade.\n\nmean(trial$marker, na.rm = TRUE)\n\n[1] 0.9159895\n\nmoy_groupe <-\n  trial |> \n  dplyr::group_by(grade) |> \n  dplyr::summarise(moyenne_marker = mean(marker, na.rm = TRUE))\nmoy_groupe\n\n# A tibble: 3 × 2\n  grade moyenne_marker\n  <fct>          <dbl>\n1 I              1.07 \n2 II             0.681\n3 III            0.996\n\nmean(moy_groupe$moyenne_marker)\n\n[1] 0.9144384\n\n\nLe terme grade1 correspond quant à lui au modificateur associé à la première modalité de la variable grade à savoir I. C’est l’écart, pour cette modalité, à la grande moyenne : 1.0669 - 0.9144 = 0.1525.\nDe même, le terme grade2 correspond à l’écart pour la modalité II par rapport à la grande moyenne : 0.6805 - 0.9144 = -0.2339.\nQu’en est-il de l’écart à la grande moyenne pour la modalité III ? Pour cela, voyons tout d’abord comment la variable grade a été codée :\n\ncontrasts(trial$grade)\n\n    [,1] [,2]\nI      1    0\nII     0    1\nIII   -1   -1\n\n\nComme précédemment, cette variable à trois modalités a été codée avec deux termes. Les deux premiers termes correspondent aux écarts à la grande moyenne des deux premières modalités. La troisième modalité est, quant à elle, codée systématiquement -1. C’est ce qui assure que la somme des contributions soit nulle et donc que l’intercept capture la grande moyenne.\nL’écart à la grande moyenne pour la troisième modalité s’obtient donc en faisant la somme des autres termes et en l’inversant : (0.1525 - 0.2339) * -1 = 0.0814 = 0.9958 - 0.9144.\nOn peut calculer / afficher la valeur associée à la dernière modalité en précisant add_estimate_to_reference_rows = TRUE lorsque l’on appelle gtsummary::tbl_regression().\n\nmod1_sum |>\n  tbl_regression(\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  )\n\n\n\n\n\n\nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n0.91\n0.79, 1.0\n<0.001\n\n\nGrade\n\n\n\n\n\n    I\n0.15\n-0.02, 0.32\n0.078\n\n\n    II\n-0.23\n-0.41, -0.06\n0.008\n\n\n    III\n0.08\n—\n\n\n\n\n\n1 CI = Confidence Interval\n    \n\n\n\n\nDe même, cette valeur est correctement affichée par ggstats::ggcoef_model().\n\nggstats::ggcoef_model(mod1_sum)\n\n\n\n\n\n\n\nLe fait d’utiliser des contrastes de type traitement ou somme n’a aucun impact sur la valeur prédictive du modèle. La quantité de variance expliquée, la somme des résidus ou encore l’AIC sont identiques. En un sens, il s’agit du même modèle. C’est seulement la manière d’interpréter les coefficients du modèle qui change.\n\nanova(mod1_trt, mod1_sum, test = \"Chisq\")\n\nAnalysis of Variance Table\n\nModel 1: marker ~ grade\nModel 2: marker ~ grade\n  Res.Df    RSS Df Sum of Sq Pr(>Chi)\n1    187 134.17                      \n2    187 134.17  0         0         \n\n\n\n23.2.2 Exemple 2 : une régression logistique avec deux variables catégorielles\nReprenons notre second exemple et codons les variables catégorielles avec un traitement de type somme.\n\nmod2_sum <- glm(\n  sport ~ sexe + groupe_ages,\n  family = binomial,\n  data = hdv2003,\n  contrasts = list(sexe = contr.sum, groupe_ages = contr.sum)\n)\nmod2_sum |>\n  tbl_regression(\n    exponentiate = TRUE,\n    intercept = TRUE, \n    add_estimate_to_reference_rows = TRUE\n  )\n\n\n\n\n\n\nCharacteristic\n      \nOR1\n\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n0.62\n0.55, 0.69\n<0.001\n\n\nSexe\n\n\n\n\n\n    Homme\n1.25\n1.13, 1.38\n<0.001\n\n\n    Femme\n0.80\n—\n\n\n\nGroupe d'âges\n\n\n\n\n\n    16-24\n3.20\n2.49, 4.15\n<0.001\n\n\n    25-44\n1.62\n1.38, 1.89\n<0.001\n\n\n    45-64\n0.61\n0.52, 0.72\n<0.001\n\n\n    65+\n0.31\n—\n\n\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n    \n\n\n\n\n\nggstats::ggcoef_model(mod2_sum, exponentiate = TRUE)\n\n\n\n\n\n\n\nCette fois-ci, l’intercept capture la situation à la grande moyenne à la fois du sexe et du groupe d’âges, et les coefficients s’interprètent donc comme modificateurs de chaque modalité par rapport à cette grande moyenne. En ce sens, les contrastes de type somme permettent donc de capturer l’effet de chaque modalité.\n\n\n\n\n\n\nEffets marginaux et contrastes de type somme\n\n\n\nDans le chapitre précédent (cf. Chapitre 22), nous avons abordé les effets marginaux.\nConcernant les effets marginaux moyens obtenus avec margins::margins(), ils ne tiennent pas compte du type de contrastes. Si on les calcule, on retombera sur la situation des contrastes de type traitement (écarts par rapport à la première modalité prise comme référence).\nConcernant les effets marginaux obtenus avec effects::allEffects(), ils sont indépendants du type de contrastes. Le résultat sera donc identique avec des contrastes de type traitement ou somme (d’où leur intérêt d’être indépendant du type de contrastes ou du choix d’une référence).\nConcernant les effets conditionnels à la référence obtenus avec ggeffects::ggpredict(), ils ne tiennent pas compte du contraste de type somme et restent calculés en considérant comme référence la première modalité de chaque variable catégorielle (contraste de type traitement)."
  },
  {
    "objectID": "analyses/contrastes.html#autres-types-de-contrastes",
    "href": "analyses/contrastes.html#autres-types-de-contrastes",
    "title": "23  Contrastes (variables catégorielles)",
    "section": "\n23.3 Autres types de contrastes",
    "text": "23.3 Autres types de contrastes\n\n23.3.1 Contrastes de type Helmert\nLes contrastes de Helmert sont un peu plus complexes : ils visent à comparer la seconde modalité à la première, la troisième à la moyenne des deux premières, la quatrième à la moyenne des trois premières, etc.\nPrenon un exemple avec une variable catégorielle à quatre modalités.\n\ncontrasts(trial$stage) <- contr.helmert\ncontrasts(trial$stage)\n\n   [,1] [,2] [,3]\nT1   -1   -1   -1\nT2    1   -1   -1\nT3    0    2   -1\nT4    0    0    3\n\nmod_helmert <- lm(\n  marker ~ stage,\n  data = trial\n)\nmod_helmert\n\n\nCall:\nlm(formula = marker ~ stage, data = trial)\n\nCoefficients:\n(Intercept)       stage1       stage2       stage3  \n    0.91661      0.19956      0.03294     -0.02085  \n\n\nPour bien comprendre comment interpréter ces coefficients, calculons déjà la grande moyenne.\n\nm <- trial |> \n  dplyr::group_by(stage) |> \n  dplyr::summarise(moy = mean(marker, na.rm = TRUE))\nmean(m$moy)\n\n[1] 0.9166073\n\n\nOn le voit, l’intercept (0.9166) capture ici cette grande moyenne, à savoir la moyenne des moyennes de chaque sous-groupe.\nMaintenant, pour interpréter les coefficients, regardons comment évolue la moyenne à chaque fois que l’on ajoute une modalité. La fonction dplyr::cummean() nous permet de calculer la moyenne cumulée, c’est-à-dire la moyenne de la valeur actuelle et des valeurs des lignes précédentes. Avec dplyr::lag() nous pouvons obtenir la moyenne cumulée de la ligne précédente. Il nous est alors possible de calculer l’écart entre les deux, et donc de voir comment la moyenne a changé avec l’ajout d’une modalité.\n\nm <- m |> \n  dplyr::mutate(\n    moy_cum = dplyr::cummean(moy),\n    moy_cum_prec = dplyr::lag(moy_cum),\n    ecart = moy_cum - moy_cum_prec\n  )\nm\n\n# A tibble: 4 × 5\n  stage   moy moy_cum moy_cum_prec   ecart\n  <fct> <dbl>   <dbl>        <dbl>   <dbl>\n1 T1    0.705   0.705       NA     NA     \n2 T2    1.10    0.905        0.705  0.200 \n3 T3    1.00    0.937        0.905  0.0329\n4 T4    0.854   0.917        0.937 -0.0208\n\n\nOn le voit, les valeurs de la colonne ecart correspondent aux coefficients du modèle.\nLe premier terme stage1 compare la deuxième modalité (T2) à la première (T1) et indique l’écart entre la moyenne des moyennes de T1 et T2 et la moyenne de T1.\nLe second terme stage2 compare la troisième modalité (T3) aux deux premières (T1 et T2) et indique l’écart entre la moyenne des moyennes de T1, T2 et T3 par rapport à la moyenne des moyennes de T1 et T2.\nLe troisième terme stage3 compare la quatrième modalité (T4) aux trois premières (T1, T2 et T3) et indique l’écart entre la moyenne des moyennes de T1, T2, T3 et T4 par rapport à la moyenne des moyennes de T1, T2 et T3.\nLes contrastes de Helmert sont ainsi un peu plus complexes à interpréter et à réserver à des cas particuliers où ils prennent tout leur sens.\n\n23.3.2 Contrastes polynomiaux\nLes contrastes polynomiaux, définis avec contr.poly(), sont utilisés par défaut pour les variables catégorielles ordonnées. Ils permettent de décomposer les effets selon une composante linéaire, une composante quadratique, une composante cubique, voire des composantes de degrés supérieurs.\n\ncontrasts(trial$stage) <- contr.poly\ncontrasts(trial$stage)\n\n           .L   .Q         .C\nT1 -0.6708204  0.5 -0.2236068\nT2 -0.2236068 -0.5  0.6708204\nT3  0.2236068 -0.5 -0.6708204\nT4  0.6708204  0.5  0.2236068\n\nmod_poly <- lm(\n  marker ~ stage,\n  data = trial\n)\nmod_poly\n\n\nCall:\nlm(formula = marker ~ stage, data = trial)\n\nCoefficients:\n(Intercept)      stage.L      stage.Q      stage.C  \n    0.91661      0.07749     -0.27419      0.10092  \n\n\nIci aussi, l’intercept correspond à la grande moyenne des moyennes. Il est par contre plus difficile de donner un sens interprétatif / sociologique aux différents coefficients."
  },
  {
    "objectID": "analyses/contrastes.html#lectures-additionnelles",
    "href": "analyses/contrastes.html#lectures-additionnelles",
    "title": "23  Contrastes (variables catégorielles)",
    "section": "\n23.4 Lectures additionnelles",
    "text": "23.4 Lectures additionnelles\n\n\nA (sort of) Complete Guide to Contrasts in R par Rose Maier\n\nAn introductory explanation of contrast coding in R linear models par Athanassios Protopapas\n\nUnderstanding Sum Contrasts for Regression Models: A Demonstration par Mona Zhu"
  },
  {
    "objectID": "analyses/interactions.html",
    "href": "analyses/interactions.html",
    "title": "24  Interactions",
    "section": "",
    "text": "à venir"
  }
]